{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('leader_stocks_data/KT&G_기타제조업.csv')\n",
    "df = df.set_index(keys=['Date'], inplace=False, drop=True)\n",
    "df = df.drop('Close', axis = 1)\n",
    "df.rename(columns ={'Adj Close':'Close'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "High      0\n",
       "Low       0\n",
       "Open      0\n",
       "Volume    0\n",
       "Close     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>24000.0</td>\n",
       "      <td>21350.0</td>\n",
       "      <td>21350.0</td>\n",
       "      <td>309700.0</td>\n",
       "      <td>7718.005371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>22950.0</td>\n",
       "      <td>21400.0</td>\n",
       "      <td>22200.0</td>\n",
       "      <td>431700.0</td>\n",
       "      <td>7577.678223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>22200.0</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>21650.0</td>\n",
       "      <td>379400.0</td>\n",
       "      <td>7349.646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>21500.0</td>\n",
       "      <td>20200.0</td>\n",
       "      <td>20450.0</td>\n",
       "      <td>356400.0</td>\n",
       "      <td>7156.696289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>21000.0</td>\n",
       "      <td>20300.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>327400.0</td>\n",
       "      <td>7156.696289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-20</th>\n",
       "      <td>83700.0</td>\n",
       "      <td>82100.0</td>\n",
       "      <td>83500.0</td>\n",
       "      <td>246936.0</td>\n",
       "      <td>82500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>83400.0</td>\n",
       "      <td>82600.0</td>\n",
       "      <td>83100.0</td>\n",
       "      <td>206625.0</td>\n",
       "      <td>83100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>83700.0</td>\n",
       "      <td>82100.0</td>\n",
       "      <td>83300.0</td>\n",
       "      <td>274579.0</td>\n",
       "      <td>82200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-23</th>\n",
       "      <td>83300.0</td>\n",
       "      <td>82200.0</td>\n",
       "      <td>82900.0</td>\n",
       "      <td>336657.0</td>\n",
       "      <td>82600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-24</th>\n",
       "      <td>83300.0</td>\n",
       "      <td>82100.0</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>280013.0</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5634 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               High      Low     Open    Volume         Close\n",
       "Date                                                         \n",
       "2000-01-04  24000.0  21350.0  21350.0  309700.0   7718.005371\n",
       "2000-01-05  22950.0  21400.0  22200.0  431700.0   7577.678223\n",
       "2000-01-06  22200.0  20800.0  21650.0  379400.0   7349.646484\n",
       "2000-01-07  21500.0  20200.0  20450.0  356400.0   7156.696289\n",
       "2000-01-10  21000.0  20300.0  20550.0  327400.0   7156.696289\n",
       "...             ...      ...      ...       ...           ...\n",
       "2022-06-20  83700.0  82100.0  83500.0  246936.0  82500.000000\n",
       "2022-06-21  83400.0  82600.0  83100.0  206625.0  83100.000000\n",
       "2022-06-22  83700.0  82100.0  83300.0  274579.0  82200.000000\n",
       "2022-06-23  83300.0  82200.0  82900.0  336657.0  82600.000000\n",
       "2022-06-24  83300.0  82100.0  83200.0  280013.0  83000.000000\n",
       "\n",
       "[5634 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-5700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.figure(figsize = (10,5))\n",
    "ax = plt.subplot()\n",
    "plt.title(\"KT&G_기타제조업\", fontsize=15, color = 'white')\n",
    "plt.plot(df['Close'], \"-\", label=\"Close\")\n",
    "plt.tick_params(axis='x', labelcolor='white')\n",
    "plt.tick_params(axis='y', labelcolor='white')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(200))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set 확인:  (160, 4) (160,) test set 확인:  (40, 4) (40,)\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 6s 340ms/step - loss: 0.0818 - mse: 0.1636 - val_loss: 0.3002 - val_mse: 0.6003\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0656 - mse: 0.1311 - val_loss: 0.2507 - val_mse: 0.5015\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0525 - mse: 0.1050 - val_loss: 0.2063 - val_mse: 0.4126\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0407 - mse: 0.0813 - val_loss: 0.1665 - val_mse: 0.3329\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0296 - mse: 0.0592 - val_loss: 0.1263 - val_mse: 0.2525\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0197 - mse: 0.0394 - val_loss: 0.0926 - val_mse: 0.1851\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0126 - mse: 0.0253 - val_loss: 0.0646 - val_mse: 0.1292\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0079 - mse: 0.0158 - val_loss: 0.0435 - val_mse: 0.0869\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0293 - val_mse: 0.0585\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0052 - mse: 0.0105 - val_loss: 0.0217 - val_mse: 0.0434\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0188 - val_mse: 0.0377\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0185 - val_mse: 0.0370\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0200 - val_mse: 0.0401\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0230 - val_mse: 0.0461\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0051 - mse: 0.0101 - val_loss: 0.0238 - val_mse: 0.0476\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0051 - mse: 0.0101 - val_loss: 0.0236 - val_mse: 0.0473\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0229 - val_mse: 0.0458\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0050 - mse: 0.0099 - val_loss: 0.0216 - val_mse: 0.0432\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0203 - val_mse: 0.0407\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0195 - val_mse: 0.0390\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0048 - mse: 0.0095 - val_loss: 0.0194 - val_mse: 0.0387\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0047 - mse: 0.0094 - val_loss: 0.0196 - val_mse: 0.0392\n",
      "pred.shape : (20, 1) , y_test.shape : (40,)\n",
      "200길이의 데이터 적용 완료\n",
      " 길이: 200, RMSE:2000.1874048673167\n",
      "train set 확인:  (240, 4) (240,) test set 확인:  (60, 4) (60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 233ms/step - loss: 0.0279 - mse: 0.0559 - val_loss: 0.1309 - val_mse: 0.2618\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0157 - mse: 0.0314 - val_loss: 0.0810 - val_mse: 0.1620\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0471 - val_mse: 0.0942\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0244 - val_mse: 0.0489\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0135 - val_mse: 0.0270\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0118 - val_mse: 0.0237\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0153 - val_mse: 0.0306\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0037 - mse: 0.0073 - val_loss: 0.0182 - val_mse: 0.0364\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0036 - mse: 0.0073 - val_loss: 0.0196 - val_mse: 0.0392\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0036 - mse: 0.0072 - val_loss: 0.0178 - val_mse: 0.0356\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0152 - val_mse: 0.0303\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0134 - val_mse: 0.0268\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0123 - val_mse: 0.0245\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0126 - val_mse: 0.0251\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0113 - val_mse: 0.0225\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0031 - mse: 0.0063 - val_loss: 0.0104 - val_mse: 0.0207\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0094 - val_mse: 0.0189\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0030 - mse: 0.0061 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0090 - val_mse: 0.0180\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0160\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0029 - mse: 0.0059 - val_loss: 0.0072 - val_mse: 0.0144\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0076 - val_mse: 0.0152\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0071 - val_mse: 0.0143\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0072 - val_mse: 0.0145\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0059 - val_mse: 0.0119\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0068 - val_mse: 0.0136\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0059 - val_mse: 0.0119\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0057 - val_mse: 0.0114\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0063 - val_mse: 0.0127\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0048 - val_mse: 0.0096\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0055 - val_mse: 0.0111\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0057 - val_mse: 0.0113\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0047 - val_mse: 0.0095\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0054 - val_mse: 0.0107\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0060 - val_mse: 0.0119\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0100\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0048 - val_mse: 0.0095\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0051 - val_mse: 0.0101\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0046 - val_mse: 0.0091\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0052 - val_mse: 0.0105\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0046 - val_mse: 0.0092\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0049 - val_mse: 0.0099\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0046 - val_mse: 0.0092\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0048 - val_mse: 0.0097\n",
      "pred.shape : (40, 1) , y_test.shape : (60,)\n",
      "300길이의 데이터 적용 완료\n",
      " 길이: 300, RMSE:992.6352116071897\n",
      "train set 확인:  (320, 4) (320,) test set 확인:  (80, 4) (80,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 141ms/step - loss: 0.0640 - mse: 0.1280 - val_loss: 0.2388 - val_mse: 0.4776\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0477 - mse: 0.0954 - val_loss: 0.1883 - val_mse: 0.3767\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0338 - mse: 0.0676 - val_loss: 0.1410 - val_mse: 0.2820\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0208 - mse: 0.0417 - val_loss: 0.0935 - val_mse: 0.1870\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0101 - mse: 0.0202 - val_loss: 0.0481 - val_mse: 0.0962\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0203 - val_mse: 0.0405\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0157 - val_mse: 0.0314\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0227 - val_mse: 0.0453\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0194 - val_mse: 0.0388\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0156 - val_mse: 0.0312\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0136 - val_mse: 0.0272\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0124 - val_mse: 0.0249\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0106 - val_mse: 0.0212\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0101 - val_mse: 0.0203\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0196\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0079 - val_mse: 0.0158\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0073 - val_mse: 0.0147\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0068 - val_mse: 0.0136\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0069 - val_mse: 0.0137\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0066 - val_mse: 0.0131\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0066 - val_mse: 0.0133\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0065 - val_mse: 0.0130\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0070 - val_mse: 0.0141\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0060 - val_mse: 0.0119\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0063 - val_mse: 0.0126\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0061 - val_mse: 0.0123\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0066 - val_mse: 0.0132\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0056 - val_mse: 0.0111\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0055 - val_mse: 0.0110\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0063 - val_mse: 0.0127\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0059 - val_mse: 0.0118\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0051 - val_mse: 0.0103\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0057 - val_mse: 0.0114\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0051 - val_mse: 0.0102\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0051 - val_mse: 0.0102\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0043 - val_mse: 0.0086\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0051 - val_mse: 0.0103\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0076\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0065 - val_mse: 0.0129\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0040 - val_mse: 0.0080\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0050 - val_mse: 0.0100\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0058 - val_mse: 0.0116\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0042 - val_mse: 0.0084\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0058 - val_mse: 0.0115\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0051 - val_mse: 0.0102\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0069\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0061 - val_mse: 0.0121\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0042 - val_mse: 0.0084\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0056 - val_mse: 0.0113\n",
      "pred.shape : (60, 1) , y_test.shape : (80,)\n",
      "400길이의 데이터 적용 완료\n",
      " 길이: 400, RMSE:1310.980702912059\n",
      "train set 확인:  (400, 4) (400,) test set 확인:  (100, 4) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 116ms/step - loss: 0.0901 - mse: 0.1803 - val_loss: 0.2022 - val_mse: 0.4044\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0592 - mse: 0.1184 - val_loss: 0.1390 - val_mse: 0.2781\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0341 - mse: 0.0682 - val_loss: 0.0802 - val_mse: 0.1603\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0123 - mse: 0.0245 - val_loss: 0.0286 - val_mse: 0.0571\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0157\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0112 - val_mse: 0.0224\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0135 - val_mse: 0.0271\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0108 - val_mse: 0.0215\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0103 - val_mse: 0.0205\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0092 - val_mse: 0.0184\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0195\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0078 - val_mse: 0.0156\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0074 - val_mse: 0.0147\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0071 - val_mse: 0.0142\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0068 - val_mse: 0.0135\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0060 - val_mse: 0.0120\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0053 - val_mse: 0.0105\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0052 - val_mse: 0.0105\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0040 - val_mse: 0.0080\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0046 - val_mse: 0.0091\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0040 - val_mse: 0.0081\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0032 - val_mse: 0.0064\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0040 - val_mse: 0.0079\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0039 - val_mse: 0.0079\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0029 - val_mse: 0.0058\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0033 - val_mse: 0.0066\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0025 - val_mse: 0.0049\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0054 - val_mse: 0.0109\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0022 - val_mse: 0.0044\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0023 - val_mse: 0.0045\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0029 - val_mse: 0.0058\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0029 - val_mse: 0.0058\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0042 - val_mse: 0.0085\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0010 - val_mse: 0.0020\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0024 - val_mse: 0.0049\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0035 - val_mse: 0.0070\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0020 - val_mse: 0.0041\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0012 - val_mse: 0.0025\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0022 - val_mse: 0.0045\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0031\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0014 - val_mse: 0.0029\n",
      "pred.shape : (80, 1) , y_test.shape : (100,)\n",
      "500길이의 데이터 적용 완료\n",
      " 길이: 500, RMSE:892.4851355080455\n",
      "train set 확인:  (480, 4) (480,) test set 확인:  (120, 4) (120,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 106ms/step - loss: 0.1200 - mse: 0.2400 - val_loss: 0.1244 - val_mse: 0.2487\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0307 - mse: 0.0614 - val_loss: 0.0209 - val_mse: 0.0417\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0036 - mse: 0.0073 - val_loss: 0.0024 - val_mse: 0.0049\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 1s 29ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0165\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0048 - val_mse: 0.0097\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 1s 26ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0058 - val_mse: 0.0116\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0046 - val_mse: 0.0091\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0045 - val_mse: 0.0091\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0097\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0037 - val_mse: 0.0074\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0034 - val_mse: 0.0069\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 1s 26ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0032 - val_mse: 0.0063\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0035 - val_mse: 0.0070\n",
      "pred.shape : (100, 1) , y_test.shape : (120,)\n",
      "600길이의 데이터 적용 완료\n",
      " 길이: 600, RMSE:2443.799214538378\n",
      "train set 확인:  (560, 4) (560,) test set 확인:  (140, 4) (140,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 85ms/step - loss: 0.0420 - mse: 0.0840 - val_loss: 0.0037 - val_mse: 0.0074\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0039 - mse: 0.0078 - val_loss: 5.2309e-04 - val_mse: 0.0010\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0024 - val_mse: 0.0048\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 6.1940e-04 - val_mse: 0.0012\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0010 - val_mse: 0.0020\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 1s 27ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 8.2016e-04 - val_mse: 0.0016\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 7.3246e-04 - val_mse: 0.0015\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 5.0927e-04 - val_mse: 0.0010\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 4.3944e-04 - val_mse: 8.7889e-04\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 1s 27ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 4.9140e-04 - val_mse: 9.8280e-04\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 5.0177e-04 - val_mse: 0.0010\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 1s 27ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 5.6627e-04 - val_mse: 0.0011\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 4.2523e-04 - val_mse: 8.5045e-04\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 3.6871e-04 - val_mse: 7.3741e-04\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 5.9350e-04 - val_mse: 0.0012\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 3.8346e-04 - val_mse: 7.6693e-04\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 2.9081e-04 - val_mse: 5.8162e-04\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 4.9174e-04 - val_mse: 9.8349e-04\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 2.7302e-04 - val_mse: 5.4605e-04\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 3.2513e-04 - val_mse: 6.5026e-04\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 5.0745e-04 - val_mse: 0.0010\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 6.8891e-04 - val_mse: 0.0014\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 4.3550e-04 - val_mse: 8.7101e-04\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 3.5276e-04 - val_mse: 7.0552e-04\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 3.6114e-04 - val_mse: 7.2229e-04\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 2.9932e-04 - val_mse: 5.9865e-04\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.2724e-04 - val_mse: 6.5449e-04\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 2.4906e-04 - val_mse: 4.9813e-04\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 1s 27ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 2.3109e-04 - val_mse: 4.6219e-04\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 2.3829e-04 - val_mse: 4.7658e-04\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 2.8635e-04 - val_mse: 5.7270e-04\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 9.8783e-04 - mse: 0.0020 - val_loss: 4.9980e-04 - val_mse: 9.9960e-04\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 1s 27ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 3.1965e-04 - val_mse: 6.3930e-04\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 9.4294e-04 - mse: 0.0019 - val_loss: 3.1272e-04 - val_mse: 6.2544e-04\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 9.3316e-04 - mse: 0.0019 - val_loss: 2.2203e-04 - val_mse: 4.4406e-04\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 9.0946e-04 - mse: 0.0018 - val_loss: 2.7126e-04 - val_mse: 5.4252e-04\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 1s 23ms/step - loss: 9.1226e-04 - mse: 0.0018 - val_loss: 4.4136e-04 - val_mse: 8.8272e-04\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 9.4752e-04 - mse: 0.0019 - val_loss: 2.0018e-04 - val_mse: 4.0037e-04\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 8.8238e-04 - mse: 0.0018 - val_loss: 2.3511e-04 - val_mse: 4.7022e-04\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 8.5275e-04 - mse: 0.0017 - val_loss: 2.0289e-04 - val_mse: 4.0577e-04\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 8.3672e-04 - mse: 0.0017 - val_loss: 2.7325e-04 - val_mse: 5.4650e-04\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.2859e-04 - mse: 0.0017 - val_loss: 4.0882e-04 - val_mse: 8.1763e-04\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 8.2318e-04 - mse: 0.0016 - val_loss: 1.8870e-04 - val_mse: 3.7741e-04\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 8.0203e-04 - mse: 0.0016 - val_loss: 2.1856e-04 - val_mse: 4.3712e-04\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 1s 24ms/step - loss: 7.9480e-04 - mse: 0.0016 - val_loss: 1.9969e-04 - val_mse: 3.9939e-04\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 7.9430e-04 - mse: 0.0016 - val_loss: 1.8255e-04 - val_mse: 3.6509e-04\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 1s 25ms/step - loss: 7.8448e-04 - mse: 0.0016 - val_loss: 3.2120e-04 - val_mse: 6.4240e-04\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 7.6499e-04 - mse: 0.0015 - val_loss: 1.8860e-04 - val_mse: 3.7721e-04\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 7.8093e-04 - mse: 0.0016 - val_loss: 3.2602e-04 - val_mse: 6.5205e-04\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 7.5657e-04 - mse: 0.0015 - val_loss: 2.4757e-04 - val_mse: 4.9513e-04\n",
      "pred.shape : (120, 1) , y_test.shape : (140,)\n",
      "700길이의 데이터 적용 완료\n",
      " 길이: 700, RMSE:746.4808251993071\n",
      "train set 확인:  (640, 4) (640,) test set 확인:  (160, 4) (160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 7s 96ms/step - loss: 0.1344 - mse: 0.2689 - val_loss: 0.0750 - val_mse: 0.1501\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0202 - mse: 0.0403 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0013 - val_mse: 0.0025\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 23ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 9.1908e-04 - val_mse: 0.0018\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 23ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 6.7668e-04 - val_mse: 0.0014\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 22ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 6.1561e-04 - val_mse: 0.0012\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 6.1444e-04 - val_mse: 0.0012\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 4.4595e-04 - val_mse: 8.9191e-04\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 4.8685e-04 - val_mse: 9.7371e-04\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 3.4750e-04 - val_mse: 6.9500e-04\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 3.2702e-04 - val_mse: 6.5405e-04\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 3.3537e-04 - val_mse: 6.7074e-04\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 3.4740e-04 - val_mse: 6.9479e-04\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.6566e-04 - val_mse: 7.3132e-04\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.0956e-04 - val_mse: 6.1911e-04\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 3.7784e-04 - val_mse: 7.5567e-04\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 2.8754e-04 - val_mse: 5.7508e-04\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.1448e-04 - val_mse: 6.2896e-04\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 3.8607e-04 - val_mse: 7.7214e-04\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 2.7256e-04 - val_mse: 5.4512e-04\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 3.7646e-04 - val_mse: 7.5292e-04\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 9.8273e-04 - mse: 0.0020 - val_loss: 2.6154e-04 - val_mse: 5.2307e-04\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 9.6129e-04 - mse: 0.0019 - val_loss: 3.1126e-04 - val_mse: 6.2252e-04\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 22ms/step - loss: 9.2540e-04 - mse: 0.0019 - val_loss: 2.7267e-04 - val_mse: 5.4533e-04\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 8.9326e-04 - mse: 0.0018 - val_loss: 3.3249e-04 - val_mse: 6.6499e-04\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 9.1433e-04 - mse: 0.0018 - val_loss: 2.4604e-04 - val_mse: 4.9208e-04\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 8.7178e-04 - mse: 0.0017 - val_loss: 2.4809e-04 - val_mse: 4.9619e-04\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 22ms/step - loss: 8.4638e-04 - mse: 0.0017 - val_loss: 2.5409e-04 - val_mse: 5.0818e-04\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 8.2371e-04 - mse: 0.0016 - val_loss: 2.6805e-04 - val_mse: 5.3610e-04\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 7.9009e-04 - mse: 0.0016 - val_loss: 2.9967e-04 - val_mse: 5.9935e-04\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 7.7200e-04 - mse: 0.0015 - val_loss: 4.4639e-04 - val_mse: 8.9279e-04\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 21ms/step - loss: 7.8744e-04 - mse: 0.0016 - val_loss: 2.4128e-04 - val_mse: 4.8256e-04\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 7.4674e-04 - mse: 0.0015 - val_loss: 2.1583e-04 - val_mse: 4.3166e-04\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 7.3840e-04 - mse: 0.0015 - val_loss: 2.4654e-04 - val_mse: 4.9308e-04\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 7.0726e-04 - mse: 0.0014 - val_loss: 2.1152e-04 - val_mse: 4.2304e-04\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 7.4701e-04 - mse: 0.0015 - val_loss: 2.6812e-04 - val_mse: 5.3625e-04\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 7.6916e-04 - mse: 0.0015 - val_loss: 2.1239e-04 - val_mse: 4.2478e-04\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 6.8270e-04 - mse: 0.0014 - val_loss: 2.1298e-04 - val_mse: 4.2595e-04\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 7.0622e-04 - mse: 0.0014 - val_loss: 2.0599e-04 - val_mse: 4.1197e-04\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 23ms/step - loss: 6.9821e-04 - mse: 0.0014 - val_loss: 2.4057e-04 - val_mse: 4.8115e-04\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 6.7668e-04 - mse: 0.0014 - val_loss: 2.1104e-04 - val_mse: 4.2208e-04\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 6.5179e-04 - mse: 0.0013 - val_loss: 2.0449e-04 - val_mse: 4.0898e-04\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 6.4173e-04 - mse: 0.0013 - val_loss: 4.7576e-04 - val_mse: 9.5153e-04\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 6.6614e-04 - mse: 0.0013 - val_loss: 2.0854e-04 - val_mse: 4.1708e-04\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 6.8867e-04 - mse: 0.0014 - val_loss: 3.0218e-04 - val_mse: 6.0436e-04\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 22ms/step - loss: 6.7891e-04 - mse: 0.0014 - val_loss: 2.5892e-04 - val_mse: 5.1784e-04\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 6.2871e-04 - mse: 0.0013 - val_loss: 1.9221e-04 - val_mse: 3.8442e-04\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 6.4642e-04 - mse: 0.0013 - val_loss: 1.9479e-04 - val_mse: 3.8957e-04\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 6.2669e-04 - mse: 0.0013 - val_loss: 1.9505e-04 - val_mse: 3.9010e-04\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 5.8163e-04 - mse: 0.0012 - val_loss: 2.9125e-04 - val_mse: 5.8250e-04\n",
      "pred.shape : (140, 1) , y_test.shape : (160,)\n",
      "800길이의 데이터 적용 완료\n",
      " 길이: 800, RMSE:809.669413453167\n",
      "train set 확인:  (720, 4) (720,) test set 확인:  (180, 4) (180,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 7s 73ms/step - loss: 0.0951 - mse: 0.1902 - val_loss: 0.0198 - val_mse: 0.0396\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0026 - val_mse: 0.0052\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 6.6624e-04 - val_mse: 0.0013\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 4.2046e-04 - val_mse: 8.4092e-04\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 4.1118e-04 - val_mse: 8.2236e-04\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 3.9610e-04 - val_mse: 7.9220e-04\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 3.7403e-04 - val_mse: 7.4807e-04\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 1s 22ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 3.4964e-04 - val_mse: 6.9929e-04\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 3.5336e-04 - val_mse: 7.0672e-04\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 3.3674e-04 - val_mse: 6.7347e-04\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.6657e-04 - val_mse: 7.3313e-04\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 3.1940e-04 - val_mse: 6.3879e-04\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.1177e-04 - val_mse: 6.2353e-04\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 3.0480e-04 - val_mse: 6.0960e-04\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 3.1705e-04 - val_mse: 6.3411e-04\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 3.0830e-04 - val_mse: 6.1661e-04\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 9.9242e-04 - mse: 0.0020 - val_loss: 2.9456e-04 - val_mse: 5.8912e-04\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 9.8169e-04 - mse: 0.0020 - val_loss: 2.9749e-04 - val_mse: 5.9499e-04\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 9.5398e-04 - mse: 0.0019 - val_loss: 2.9093e-04 - val_mse: 5.8185e-04\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 9.2866e-04 - mse: 0.0019 - val_loss: 3.2458e-04 - val_mse: 6.4916e-04\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 1s 20ms/step - loss: 9.1511e-04 - mse: 0.0018 - val_loss: 3.0986e-04 - val_mse: 6.1972e-04\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 9.1382e-04 - mse: 0.0018 - val_loss: 3.4729e-04 - val_mse: 6.9458e-04\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 8.8486e-04 - mse: 0.0018 - val_loss: 2.7191e-04 - val_mse: 5.4382e-04\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 8.7545e-04 - mse: 0.0018 - val_loss: 2.7201e-04 - val_mse: 5.4401e-04\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 8.5344e-04 - mse: 0.0017 - val_loss: 2.8320e-04 - val_mse: 5.6641e-04\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 8.4075e-04 - mse: 0.0017 - val_loss: 3.4082e-04 - val_mse: 6.8164e-04\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 8.2736e-04 - mse: 0.0017 - val_loss: 2.9041e-04 - val_mse: 5.8081e-04\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 8.0523e-04 - mse: 0.0016 - val_loss: 2.5235e-04 - val_mse: 5.0469e-04\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 7.7441e-04 - mse: 0.0015 - val_loss: 2.3647e-04 - val_mse: 4.7293e-04\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 7.5656e-04 - mse: 0.0015 - val_loss: 3.0697e-04 - val_mse: 6.1395e-04\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 7.4135e-04 - mse: 0.0015 - val_loss: 2.2858e-04 - val_mse: 4.5715e-04\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 7.1764e-04 - mse: 0.0014 - val_loss: 2.3032e-04 - val_mse: 4.6065e-04\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 7.0918e-04 - mse: 0.0014 - val_loss: 2.1984e-04 - val_mse: 4.3967e-04\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 6.7502e-04 - mse: 0.0014 - val_loss: 2.2692e-04 - val_mse: 4.5384e-04\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 6.5663e-04 - mse: 0.0013 - val_loss: 2.2675e-04 - val_mse: 4.5350e-04\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 6.3834e-04 - mse: 0.0013 - val_loss: 2.1133e-04 - val_mse: 4.2266e-04\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 6.1659e-04 - mse: 0.0012 - val_loss: 2.4588e-04 - val_mse: 4.9175e-04\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 6.0421e-04 - mse: 0.0012 - val_loss: 2.0255e-04 - val_mse: 4.0509e-04\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 6.2013e-04 - mse: 0.0012 - val_loss: 1.9896e-04 - val_mse: 3.9791e-04\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 5.8398e-04 - mse: 0.0012 - val_loss: 2.0080e-04 - val_mse: 4.0160e-04\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 1s 20ms/step - loss: 6.1503e-04 - mse: 0.0012 - val_loss: 2.6202e-04 - val_mse: 5.2405e-04\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 6.0115e-04 - mse: 0.0012 - val_loss: 1.8692e-04 - val_mse: 3.7383e-04\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 5.5519e-04 - mse: 0.0011 - val_loss: 2.3964e-04 - val_mse: 4.7928e-04\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 1s 20ms/step - loss: 5.3163e-04 - mse: 0.0011 - val_loss: 2.3508e-04 - val_mse: 4.7015e-04\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 1s 20ms/step - loss: 5.5372e-04 - mse: 0.0011 - val_loss: 1.9365e-04 - val_mse: 3.8730e-04\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 5.1844e-04 - mse: 0.0010 - val_loss: 2.0203e-04 - val_mse: 4.0405e-04\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 5.3136e-04 - mse: 0.0011 - val_loss: 1.8956e-04 - val_mse: 3.7912e-04\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 5.3048e-04 - mse: 0.0011 - val_loss: 1.9117e-04 - val_mse: 3.8234e-04\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 1s 19ms/step - loss: 4.9936e-04 - mse: 9.9872e-04 - val_loss: 1.8425e-04 - val_mse: 3.6850e-04\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 5.2022e-04 - mse: 0.0010 - val_loss: 1.7860e-04 - val_mse: 3.5719e-04\n",
      "pred.shape : (160, 1) , y_test.shape : (180,)\n",
      "900길이의 데이터 적용 완료\n",
      " 길이: 900, RMSE:690.354535421328\n",
      "train set 확인:  (800, 4) (800,) test set 확인:  (200, 4) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 6s 67ms/step - loss: 0.1632 - mse: 0.3265 - val_loss: 0.0600 - val_mse: 0.1200\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0239 - mse: 0.0477 - val_loss: 5.5558e-04 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0033 - mse: 0.0067 - val_loss: 5.3570e-04 - val_mse: 0.0011\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 5.2001e-04 - val_mse: 0.0010\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 4.5762e-04 - val_mse: 9.1523e-04\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 4.4562e-04 - val_mse: 8.9124e-04\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 4.2701e-04 - val_mse: 8.5401e-04\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 4.1556e-04 - val_mse: 8.3112e-04\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 4.0785e-04 - val_mse: 8.1570e-04\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 4.0136e-04 - val_mse: 8.0273e-04\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 3.9796e-04 - val_mse: 7.9591e-04\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 3.8593e-04 - val_mse: 7.7186e-04\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 3.9452e-04 - val_mse: 7.8903e-04\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 4.0850e-04 - val_mse: 8.1700e-04\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 3.7509e-04 - val_mse: 7.5017e-04\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 3.5642e-04 - val_mse: 7.1284e-04\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 4.2590e-04 - val_mse: 8.5179e-04\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.5932e-04 - val_mse: 7.1864e-04\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.4620e-04 - val_mse: 6.9241e-04\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.7365e-04 - val_mse: 7.4730e-04\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 3.3913e-04 - val_mse: 6.7826e-04\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.2790e-04 - val_mse: 6.5581e-04\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.1734e-04 - val_mse: 6.3468e-04\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 3.3056e-04 - val_mse: 6.6112e-04\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 3.7094e-04 - val_mse: 7.4187e-04\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 9.9312e-04 - mse: 0.0020 - val_loss: 3.2348e-04 - val_mse: 6.4696e-04\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 9.6478e-04 - mse: 0.0019 - val_loss: 3.4446e-04 - val_mse: 6.8892e-04\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 9.3642e-04 - mse: 0.0019 - val_loss: 2.8538e-04 - val_mse: 5.7076e-04\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 9.2165e-04 - mse: 0.0018 - val_loss: 3.9737e-04 - val_mse: 7.9474e-04\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 9.1213e-04 - mse: 0.0018 - val_loss: 2.9364e-04 - val_mse: 5.8729e-04\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 8.6949e-04 - mse: 0.0017 - val_loss: 2.8454e-04 - val_mse: 5.6907e-04\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 8.5162e-04 - mse: 0.0017 - val_loss: 2.8742e-04 - val_mse: 5.7484e-04\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 8.7812e-04 - mse: 0.0018 - val_loss: 2.9766e-04 - val_mse: 5.9533e-04\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 8.2471e-04 - mse: 0.0016 - val_loss: 2.5018e-04 - val_mse: 5.0037e-04\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 7.8970e-04 - mse: 0.0016 - val_loss: 3.6643e-04 - val_mse: 7.3286e-04\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 7.7635e-04 - mse: 0.0016 - val_loss: 2.8052e-04 - val_mse: 5.6104e-04\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 7.4974e-04 - mse: 0.0015 - val_loss: 2.4433e-04 - val_mse: 4.8866e-04\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 7.7511e-04 - mse: 0.0016 - val_loss: 2.4011e-04 - val_mse: 4.8021e-04\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 7.2755e-04 - mse: 0.0015 - val_loss: 3.1268e-04 - val_mse: 6.2536e-04\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 7.1012e-04 - mse: 0.0014 - val_loss: 2.2360e-04 - val_mse: 4.4720e-04\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 7.0942e-04 - mse: 0.0014 - val_loss: 2.1890e-04 - val_mse: 4.3781e-04\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 7.2301e-04 - mse: 0.0014 - val_loss: 2.7204e-04 - val_mse: 5.4408e-04\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 7.2020e-04 - mse: 0.0014 - val_loss: 2.8421e-04 - val_mse: 5.6843e-04\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 6.9554e-04 - mse: 0.0014 - val_loss: 2.7613e-04 - val_mse: 5.5226e-04\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 6.5977e-04 - mse: 0.0013 - val_loss: 3.1938e-04 - val_mse: 6.3876e-04\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 6.7409e-04 - mse: 0.0013 - val_loss: 2.4534e-04 - val_mse: 4.9068e-04\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 6.4103e-04 - mse: 0.0013 - val_loss: 2.0602e-04 - val_mse: 4.1204e-04\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 6.3385e-04 - mse: 0.0013 - val_loss: 2.0207e-04 - val_mse: 4.0414e-04\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 6.2260e-04 - mse: 0.0012 - val_loss: 2.7455e-04 - val_mse: 5.4910e-04\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 6.2980e-04 - mse: 0.0013 - val_loss: 2.0295e-04 - val_mse: 4.0590e-04\n",
      "pred.shape : (180, 1) , y_test.shape : (200,)\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:735.9243993092067\n",
      "train set 확인:  (880, 4) (880,) test set 확인:  (220, 4) (220,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 6s 62ms/step - loss: 0.1361 - mse: 0.2722 - val_loss: 0.0610 - val_mse: 0.1220\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.0254 - mse: 0.0509 - val_loss: 6.9495e-04 - val_mse: 0.0014\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 5.5408e-04 - val_mse: 0.0011\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 5.0204e-04 - val_mse: 0.0010\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 4.4691e-04 - val_mse: 8.9382e-04\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 4.0717e-04 - val_mse: 8.1434e-04\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 3.8452e-04 - val_mse: 7.6903e-04\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 4.3640e-04 - val_mse: 8.7279e-04\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 3.4614e-04 - val_mse: 6.9228e-04\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 3.3333e-04 - val_mse: 6.6667e-04\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 3.2935e-04 - val_mse: 6.5870e-04\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 4.2492e-04 - val_mse: 8.4983e-04\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 3.1194e-04 - val_mse: 6.2388e-04\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.2681e-04 - val_mse: 6.5361e-04\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 2.9926e-04 - val_mse: 5.9852e-04\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 3.9061e-04 - val_mse: 7.8121e-04\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 2.8071e-04 - val_mse: 5.6143e-04\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.1007e-04 - val_mse: 6.2014e-04\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 2.8687e-04 - val_mse: 5.7375e-04\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 9.9088e-04 - mse: 0.0020 - val_loss: 2.5467e-04 - val_mse: 5.0934e-04\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 9.6218e-04 - mse: 0.0019 - val_loss: 2.4914e-04 - val_mse: 4.9828e-04\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 9.8087e-04 - mse: 0.0020 - val_loss: 3.4867e-04 - val_mse: 6.9734e-04\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 9.4575e-04 - mse: 0.0019 - val_loss: 3.2000e-04 - val_mse: 6.4001e-04\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 9.2309e-04 - mse: 0.0018 - val_loss: 2.3748e-04 - val_mse: 4.7496e-04\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 9.2653e-04 - mse: 0.0019 - val_loss: 3.0075e-04 - val_mse: 6.0149e-04\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 8.5863e-04 - mse: 0.0017 - val_loss: 3.2477e-04 - val_mse: 6.4953e-04\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 8.5997e-04 - mse: 0.0017 - val_loss: 2.3414e-04 - val_mse: 4.6827e-04\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 8.4863e-04 - mse: 0.0017 - val_loss: 2.2031e-04 - val_mse: 4.4063e-04\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 7.9213e-04 - mse: 0.0016 - val_loss: 2.4993e-04 - val_mse: 4.9987e-04\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 7.7319e-04 - mse: 0.0015 - val_loss: 2.2868e-04 - val_mse: 4.5736e-04\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 7.7178e-04 - mse: 0.0015 - val_loss: 2.1294e-04 - val_mse: 4.2588e-04\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 7.5845e-04 - mse: 0.0015 - val_loss: 2.6818e-04 - val_mse: 5.3637e-04\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 7.6499e-04 - mse: 0.0015 - val_loss: 2.3095e-04 - val_mse: 4.6190e-04\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 7.3357e-04 - mse: 0.0015 - val_loss: 2.0775e-04 - val_mse: 4.1550e-04\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 17ms/step - loss: 7.2422e-04 - mse: 0.0014 - val_loss: 2.0781e-04 - val_mse: 4.1562e-04\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 7.1955e-04 - mse: 0.0014 - val_loss: 2.1336e-04 - val_mse: 4.2672e-04\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 7.1444e-04 - mse: 0.0014 - val_loss: 2.5392e-04 - val_mse: 5.0784e-04\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 7.2262e-04 - mse: 0.0014 - val_loss: 2.0503e-04 - val_mse: 4.1006e-04\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 7.0361e-04 - mse: 0.0014 - val_loss: 2.1265e-04 - val_mse: 4.2529e-04\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 7.0131e-04 - mse: 0.0014 - val_loss: 2.5867e-04 - val_mse: 5.1733e-04\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 6.9196e-04 - mse: 0.0014 - val_loss: 2.1346e-04 - val_mse: 4.2692e-04\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 6.9358e-04 - mse: 0.0014 - val_loss: 2.0047e-04 - val_mse: 4.0094e-04\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 6.9971e-04 - mse: 0.0014 - val_loss: 2.6936e-04 - val_mse: 5.3873e-04\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 6.8716e-04 - mse: 0.0014 - val_loss: 3.7940e-04 - val_mse: 7.5880e-04\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 6.8341e-04 - mse: 0.0014 - val_loss: 2.1565e-04 - val_mse: 4.3131e-04\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 6.7132e-04 - mse: 0.0013 - val_loss: 2.3185e-04 - val_mse: 4.6369e-04\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 6.6901e-04 - mse: 0.0013 - val_loss: 2.3902e-04 - val_mse: 4.7804e-04\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 6.4888e-04 - mse: 0.0013 - val_loss: 1.9372e-04 - val_mse: 3.8744e-04\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 6.4477e-04 - mse: 0.0013 - val_loss: 2.2735e-04 - val_mse: 4.5469e-04\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 6.5195e-04 - mse: 0.0013 - val_loss: 2.1640e-04 - val_mse: 4.3280e-04\n",
      "pred.shape : (200, 1) , y_test.shape : (220,)\n",
      "1100길이의 데이터 적용 완료\n",
      " 길이: 1100, RMSE:759.9160038522459\n",
      "train set 확인:  (960, 4) (960,) test set 확인:  (240, 4) (240,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 7s 63ms/step - loss: 0.1550 - mse: 0.3100 - val_loss: 0.0816 - val_mse: 0.1632\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0586 - mse: 0.1172 - val_loss: 0.0077 - val_mse: 0.0154\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0077 - mse: 0.0155 - val_loss: 0.0028 - val_mse: 0.0056\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0011 - val_mse: 0.0021\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0042 - mse: 0.0084 - val_loss: 9.2818e-04 - val_mse: 0.0019\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0034 - mse: 0.0069 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 6.4790e-04 - val_mse: 0.0013\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 5.6734e-04 - val_mse: 0.0011\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 3.3294e-04 - val_mse: 6.6589e-04\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 2.8772e-04 - val_mse: 5.7544e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 3.1898e-04 - val_mse: 6.3796e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 2.6050e-04 - val_mse: 5.2099e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.5528e-04 - val_mse: 5.1056e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 3.5546e-04 - val_mse: 7.1091e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 2.5379e-04 - val_mse: 5.0759e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 2.6180e-04 - val_mse: 5.2359e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 2.3521e-04 - val_mse: 4.7042e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 2.6693e-04 - val_mse: 5.3386e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 2.2433e-04 - val_mse: 4.4866e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 2.3325e-04 - val_mse: 4.6650e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 2.0824e-04 - val_mse: 4.1648e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 9.4984e-04 - mse: 0.0019 - val_loss: 2.4924e-04 - val_mse: 4.9847e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 9.1901e-04 - mse: 0.0018 - val_loss: 1.9003e-04 - val_mse: 3.8005e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 8.4835e-04 - mse: 0.0017 - val_loss: 2.4172e-04 - val_mse: 4.8343e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 8.2000e-04 - mse: 0.0016 - val_loss: 2.6566e-04 - val_mse: 5.3132e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 7.6489e-04 - mse: 0.0015 - val_loss: 1.5749e-04 - val_mse: 3.1499e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 6.8418e-04 - mse: 0.0014 - val_loss: 1.5360e-04 - val_mse: 3.0720e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 6.5466e-04 - mse: 0.0013 - val_loss: 1.4842e-04 - val_mse: 2.9685e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 6.2396e-04 - mse: 0.0012 - val_loss: 1.4409e-04 - val_mse: 2.8819e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 5.9942e-04 - mse: 0.0012 - val_loss: 1.4770e-04 - val_mse: 2.9541e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 6.2606e-04 - mse: 0.0013 - val_loss: 1.5295e-04 - val_mse: 3.0589e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 6.0342e-04 - mse: 0.0012 - val_loss: 1.4177e-04 - val_mse: 2.8353e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 5.3936e-04 - mse: 0.0011 - val_loss: 1.6543e-04 - val_mse: 3.3085e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 5.6133e-04 - mse: 0.0011 - val_loss: 1.2827e-04 - val_mse: 2.5655e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 5.3400e-04 - mse: 0.0011 - val_loss: 1.5180e-04 - val_mse: 3.0360e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 5.2872e-04 - mse: 0.0011 - val_loss: 1.2808e-04 - val_mse: 2.5616e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 5.0492e-04 - mse: 0.0010 - val_loss: 1.2439e-04 - val_mse: 2.4877e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 5.2496e-04 - mse: 0.0010 - val_loss: 2.1272e-04 - val_mse: 4.2545e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 5.2513e-04 - mse: 0.0011 - val_loss: 1.7005e-04 - val_mse: 3.4010e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 4.9148e-04 - mse: 9.8296e-04 - val_loss: 1.6778e-04 - val_mse: 3.3556e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 4.8138e-04 - mse: 9.6275e-04 - val_loss: 1.1709e-04 - val_mse: 2.3417e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 4.7937e-04 - mse: 9.5875e-04 - val_loss: 1.1477e-04 - val_mse: 2.2953e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 4.5427e-04 - mse: 9.0854e-04 - val_loss: 1.1772e-04 - val_mse: 2.3543e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 4.6239e-04 - mse: 9.2477e-04 - val_loss: 1.6162e-04 - val_mse: 3.2324e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 4.4190e-04 - mse: 8.8380e-04 - val_loss: 1.1172e-04 - val_mse: 2.2343e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 4.4950e-04 - mse: 8.9899e-04 - val_loss: 2.3272e-04 - val_mse: 4.6543e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 4.4624e-04 - mse: 8.9248e-04 - val_loss: 2.6792e-04 - val_mse: 5.3584e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 5.0345e-04 - mse: 0.0010 - val_loss: 1.0671e-04 - val_mse: 2.1342e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 4.5516e-04 - mse: 9.1032e-04 - val_loss: 1.1181e-04 - val_mse: 2.2362e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 4.5056e-04 - mse: 9.0111e-04 - val_loss: 1.0456e-04 - val_mse: 2.0911e-04\n",
      "pred.shape : (220, 1) , y_test.shape : (240,)\n",
      "1200길이의 데이터 적용 완료\n",
      " 길이: 1200, RMSE:611.1530732524569\n",
      "train set 확인:  (1040, 4) (1040,) test set 확인:  (260, 4) (260,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 8s 54ms/step - loss: 0.1758 - mse: 0.3516 - val_loss: 0.1152 - val_mse: 0.2304\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1189 - mse: 0.2379 - val_loss: 0.0478 - val_mse: 0.0955\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0198 - mse: 0.0395 - val_loss: 0.0045 - val_mse: 0.0090\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 3.2602e-04 - val_mse: 6.5203e-04\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 3.6955e-04 - val_mse: 7.3911e-04\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 3.4682e-04 - val_mse: 6.9364e-04\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 2.7005e-04 - val_mse: 5.4011e-04\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 2.7741e-04 - val_mse: 5.5483e-04\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 3.1040e-04 - val_mse: 6.2080e-04\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 2.7150e-04 - val_mse: 5.4300e-04\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.5654e-04 - val_mse: 5.1307e-04\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.9657e-04 - val_mse: 5.9313e-04\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 2.4848e-04 - val_mse: 4.9696e-04\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 2.7956e-04 - val_mse: 5.5912e-04\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 2.7976e-04 - val_mse: 5.5953e-04\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 2.3443e-04 - val_mse: 4.6886e-04\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 2.4540e-04 - val_mse: 4.9079e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 3.9432e-04 - val_mse: 7.8865e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 2.1334e-04 - val_mse: 4.2669e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 2.1428e-04 - val_mse: 4.2857e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 2.4610e-04 - val_mse: 4.9221e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 9.6751e-04 - mse: 0.0019 - val_loss: 2.4870e-04 - val_mse: 4.9741e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 9.3455e-04 - mse: 0.0019 - val_loss: 2.3763e-04 - val_mse: 4.7527e-04\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.7950e-04 - mse: 0.0018 - val_loss: 2.0626e-04 - val_mse: 4.1251e-04\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 8.7262e-04 - mse: 0.0017 - val_loss: 1.6873e-04 - val_mse: 3.3746e-04\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 8.5108e-04 - mse: 0.0017 - val_loss: 4.1593e-04 - val_mse: 8.3187e-04\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.3207e-04 - mse: 0.0017 - val_loss: 2.8557e-04 - val_mse: 5.7113e-04\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5380e-04 - mse: 0.0015 - val_loss: 1.7712e-04 - val_mse: 3.5423e-04\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.2625e-04 - mse: 0.0015 - val_loss: 1.8198e-04 - val_mse: 3.6396e-04\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.1155e-04 - mse: 0.0014 - val_loss: 1.5027e-04 - val_mse: 3.0055e-04\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.1530e-04 - mse: 0.0014 - val_loss: 1.4739e-04 - val_mse: 2.9477e-04\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 6.9646e-04 - mse: 0.0014 - val_loss: 2.5157e-04 - val_mse: 5.0314e-04\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.6526e-04 - mse: 0.0013 - val_loss: 1.6810e-04 - val_mse: 3.3620e-04\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.3824e-04 - mse: 0.0013 - val_loss: 1.8615e-04 - val_mse: 3.7231e-04\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.3085e-04 - mse: 0.0013 - val_loss: 1.5646e-04 - val_mse: 3.1292e-04\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 6.2643e-04 - mse: 0.0013 - val_loss: 1.6437e-04 - val_mse: 3.2875e-04\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.4957e-04 - mse: 0.0013 - val_loss: 3.1441e-04 - val_mse: 6.2881e-04\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 6.5870e-04 - mse: 0.0013 - val_loss: 1.3885e-04 - val_mse: 2.7770e-04\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 5.7472e-04 - mse: 0.0011 - val_loss: 1.5935e-04 - val_mse: 3.1869e-04\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 5.6974e-04 - mse: 0.0011 - val_loss: 1.4080e-04 - val_mse: 2.8159e-04\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 5.7930e-04 - mse: 0.0012 - val_loss: 1.9398e-04 - val_mse: 3.8797e-04\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 5.4089e-04 - mse: 0.0011 - val_loss: 1.3117e-04 - val_mse: 2.6234e-04\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 5.5066e-04 - mse: 0.0011 - val_loss: 1.4454e-04 - val_mse: 2.8908e-04\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 5.8865e-04 - mse: 0.0012 - val_loss: 1.5154e-04 - val_mse: 3.0307e-04\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 5.2137e-04 - mse: 0.0010 - val_loss: 1.1962e-04 - val_mse: 2.3924e-04\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 5.3784e-04 - mse: 0.0011 - val_loss: 1.5969e-04 - val_mse: 3.1938e-04\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 5.1231e-04 - mse: 0.0010 - val_loss: 1.1461e-04 - val_mse: 2.2922e-04\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 5.0872e-04 - mse: 0.0010 - val_loss: 2.7417e-04 - val_mse: 5.4834e-04\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 5.0394e-04 - mse: 0.0010 - val_loss: 1.1625e-04 - val_mse: 2.3251e-04\n",
      "pred.shape : (240, 1) , y_test.shape : (260,)\n",
      "1300길이의 데이터 적용 완료\n",
      " 길이: 1300, RMSE:644.4335079523909\n",
      "train set 확인:  (1120, 4) (1120,) test set 확인:  (280, 4) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 7s 62ms/step - loss: 0.0725 - mse: 0.1450 - val_loss: 6.5659e-04 - val_mse: 0.0013\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 1s 24ms/step - loss: 0.0034 - mse: 0.0067 - val_loss: 3.8100e-04 - val_mse: 7.6200e-04\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 4.8310e-04 - val_mse: 9.6620e-04\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 3.3399e-04 - val_mse: 6.6798e-04\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.1552e-04 - val_mse: 4.3104e-04\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 2.2052e-04 - val_mse: 4.4103e-04\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 9.5778e-04 - mse: 0.0019 - val_loss: 1.7479e-04 - val_mse: 3.4957e-04\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 8.9426e-04 - mse: 0.0018 - val_loss: 1.6730e-04 - val_mse: 3.3460e-04\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 8.4853e-04 - mse: 0.0017 - val_loss: 2.2931e-04 - val_mse: 4.5863e-04\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 8.2735e-04 - mse: 0.0017 - val_loss: 2.3097e-04 - val_mse: 4.6195e-04\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 8.2962e-04 - mse: 0.0017 - val_loss: 1.6697e-04 - val_mse: 3.3395e-04\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 7.3248e-04 - mse: 0.0015 - val_loss: 2.0823e-04 - val_mse: 4.1645e-04\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 7.5797e-04 - mse: 0.0015 - val_loss: 1.3683e-04 - val_mse: 2.7366e-04\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 6.8516e-04 - mse: 0.0014 - val_loss: 1.3132e-04 - val_mse: 2.6264e-04\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 6.4565e-04 - mse: 0.0013 - val_loss: 1.4717e-04 - val_mse: 2.9435e-04\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 6.2843e-04 - mse: 0.0013 - val_loss: 1.3997e-04 - val_mse: 2.7994e-04\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 6.2790e-04 - mse: 0.0013 - val_loss: 1.2873e-04 - val_mse: 2.5746e-04\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 5.8042e-04 - mse: 0.0012 - val_loss: 2.0723e-04 - val_mse: 4.1446e-04\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.6175e-04 - mse: 0.0011 - val_loss: 1.2925e-04 - val_mse: 2.5850e-04\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 5.7303e-04 - mse: 0.0011 - val_loss: 1.1612e-04 - val_mse: 2.3225e-04\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 5.6186e-04 - mse: 0.0011 - val_loss: 1.1666e-04 - val_mse: 2.3332e-04\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 5.6057e-04 - mse: 0.0011 - val_loss: 1.2661e-04 - val_mse: 2.5321e-04\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 5.2783e-04 - mse: 0.0011 - val_loss: 1.3504e-04 - val_mse: 2.7008e-04\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.5305e-04 - mse: 0.0011 - val_loss: 1.1600e-04 - val_mse: 2.3200e-04\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 5.2057e-04 - mse: 0.0010 - val_loss: 1.2308e-04 - val_mse: 2.4616e-04\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.1361e-04 - mse: 0.0010 - val_loss: 1.1284e-04 - val_mse: 2.2568e-04\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 5.4435e-04 - mse: 0.0011 - val_loss: 1.1300e-04 - val_mse: 2.2601e-04\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 5.0007e-04 - mse: 0.0010 - val_loss: 1.1186e-04 - val_mse: 2.2373e-04\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 4.9969e-04 - mse: 9.9938e-04 - val_loss: 1.1367e-04 - val_mse: 2.2734e-04\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 5.0027e-04 - mse: 0.0010 - val_loss: 1.2383e-04 - val_mse: 2.4766e-04\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.0393e-04 - mse: 0.0010 - val_loss: 1.1254e-04 - val_mse: 2.2508e-04\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 4.9866e-04 - mse: 9.9731e-04 - val_loss: 1.2967e-04 - val_mse: 2.5933e-04\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 5.0276e-04 - mse: 0.0010 - val_loss: 1.3065e-04 - val_mse: 2.6130e-04\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.3440e-04 - mse: 0.0011 - val_loss: 1.2498e-04 - val_mse: 2.4995e-04\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 5.4159e-04 - mse: 0.0011 - val_loss: 1.1288e-04 - val_mse: 2.2576e-04\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 4.9807e-04 - mse: 9.9613e-04 - val_loss: 1.1219e-04 - val_mse: 2.2437e-04\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 4.8552e-04 - mse: 9.7104e-04 - val_loss: 1.0884e-04 - val_mse: 2.1768e-04\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 5.1290e-04 - mse: 0.0010 - val_loss: 1.1688e-04 - val_mse: 2.3377e-04\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 4.7499e-04 - mse: 9.4998e-04 - val_loss: 1.7412e-04 - val_mse: 3.4824e-04\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 4.9324e-04 - mse: 9.8649e-04 - val_loss: 1.1210e-04 - val_mse: 2.2419e-04\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 4.8085e-04 - mse: 9.6170e-04 - val_loss: 1.0726e-04 - val_mse: 2.1453e-04\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 4.9227e-04 - mse: 9.8454e-04 - val_loss: 1.3226e-04 - val_mse: 2.6452e-04\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 4.7044e-04 - mse: 9.4088e-04 - val_loss: 1.0973e-04 - val_mse: 2.1946e-04\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 4.6193e-04 - mse: 9.2386e-04 - val_loss: 1.1822e-04 - val_mse: 2.3644e-04\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 4.7783e-04 - mse: 9.5565e-04 - val_loss: 1.0643e-04 - val_mse: 2.1287e-04\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 1s 24ms/step - loss: 4.7239e-04 - mse: 9.4478e-04 - val_loss: 1.0475e-04 - val_mse: 2.0949e-04\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 4.6361e-04 - mse: 9.2721e-04 - val_loss: 1.1773e-04 - val_mse: 2.3545e-04\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 4.6057e-04 - mse: 9.2113e-04 - val_loss: 1.0476e-04 - val_mse: 2.0951e-04\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 4.6197e-04 - mse: 9.2394e-04 - val_loss: 1.1046e-04 - val_mse: 2.2093e-04\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 4.7236e-04 - mse: 9.4473e-04 - val_loss: 1.0636e-04 - val_mse: 2.1273e-04\n",
      "pred.shape : (260, 1) , y_test.shape : (280,)\n",
      "1400길이의 데이터 적용 완료\n",
      " 길이: 1400, RMSE:616.4122345630259\n",
      "train set 확인:  (1200, 4) (1200,) test set 확인:  (300, 4) (300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 8s 76ms/step - loss: 0.0884 - mse: 0.1768 - val_loss: 0.0075 - val_mse: 0.0149\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.0052 - mse: 0.0103 - val_loss: 5.6647e-04 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 0.0026 - mse: 0.0051 - val_loss: 8.2532e-04 - val_mse: 0.0017\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 5.8623e-04 - val_mse: 0.0012\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 3.9336e-04 - val_mse: 7.8671e-04\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 2.9783e-04 - val_mse: 5.9565e-04\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 2.0381e-04 - val_mse: 4.0762e-04\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 1.9120e-04 - val_mse: 3.8240e-04\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.9240e-04 - val_mse: 3.8479e-04\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.9682e-04 - val_mse: 3.9364e-04\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 1.9189e-04 - val_mse: 3.8377e-04\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 1.7743e-04 - val_mse: 3.5486e-04\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 9.9973e-04 - mse: 0.0020 - val_loss: 1.7127e-04 - val_mse: 3.4254e-04\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 9.7562e-04 - mse: 0.0020 - val_loss: 1.6558e-04 - val_mse: 3.3116e-04\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.6825e-04 - mse: 0.0019 - val_loss: 1.6424e-04 - val_mse: 3.2849e-04\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.4846e-04 - mse: 0.0019 - val_loss: 1.7496e-04 - val_mse: 3.4992e-04\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 9.1376e-04 - mse: 0.0018 - val_loss: 1.8801e-04 - val_mse: 3.7602e-04\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.2142e-04 - mse: 0.0018 - val_loss: 2.3914e-04 - val_mse: 4.7828e-04\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.9998e-04 - mse: 0.0018 - val_loss: 1.4974e-04 - val_mse: 2.9948e-04\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 8.5640e-04 - mse: 0.0017 - val_loss: 1.5251e-04 - val_mse: 3.0502e-04\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 8.3490e-04 - mse: 0.0017 - val_loss: 1.4311e-04 - val_mse: 2.8622e-04\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 7.9094e-04 - mse: 0.0016 - val_loss: 1.5718e-04 - val_mse: 3.1436e-04\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.7359e-04 - mse: 0.0015 - val_loss: 1.4714e-04 - val_mse: 2.9427e-04\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.6143e-04 - mse: 0.0015 - val_loss: 1.3263e-04 - val_mse: 2.6525e-04\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 7.9823e-04 - mse: 0.0016 - val_loss: 2.1661e-04 - val_mse: 4.3321e-04\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.2790e-04 - mse: 0.0015 - val_loss: 1.2665e-04 - val_mse: 2.5330e-04\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.8623e-04 - mse: 0.0014 - val_loss: 1.3271e-04 - val_mse: 2.6542e-04\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 6.7421e-04 - mse: 0.0013 - val_loss: 1.2406e-04 - val_mse: 2.4813e-04\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 6.3854e-04 - mse: 0.0013 - val_loss: 1.1942e-04 - val_mse: 2.3885e-04\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.2603e-04 - mse: 0.0013 - val_loss: 1.1783e-04 - val_mse: 2.3567e-04\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.0590e-04 - mse: 0.0012 - val_loss: 1.1644e-04 - val_mse: 2.3289e-04\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9820e-04 - mse: 0.0012 - val_loss: 1.2054e-04 - val_mse: 2.4109e-04\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.1129e-04 - mse: 0.0012 - val_loss: 1.0855e-04 - val_mse: 2.1710e-04\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.7481e-04 - mse: 0.0011 - val_loss: 1.2352e-04 - val_mse: 2.4703e-04\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.6985e-04 - mse: 0.0011 - val_loss: 1.9537e-04 - val_mse: 3.9074e-04\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 5.4916e-04 - mse: 0.0011 - val_loss: 1.3564e-04 - val_mse: 2.7128e-04\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.4580e-04 - mse: 0.0011 - val_loss: 2.0904e-04 - val_mse: 4.1808e-04\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.2170e-04 - mse: 0.0012 - val_loss: 1.0702e-04 - val_mse: 2.1404e-04\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.2144e-04 - mse: 0.0010 - val_loss: 1.1330e-04 - val_mse: 2.2661e-04\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.1358e-04 - mse: 0.0010 - val_loss: 1.0351e-04 - val_mse: 2.0702e-04\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.3794e-04 - mse: 0.0011 - val_loss: 1.7448e-04 - val_mse: 3.4897e-04\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.8528e-04 - mse: 0.0012 - val_loss: 1.9707e-04 - val_mse: 3.9414e-04\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 5.8383e-04 - mse: 0.0012 - val_loss: 1.2747e-04 - val_mse: 2.5495e-04\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.1599e-04 - mse: 0.0010 - val_loss: 9.9155e-05 - val_mse: 1.9831e-04\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.0642e-04 - mse: 0.0010 - val_loss: 9.9371e-05 - val_mse: 1.9874e-04\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.8779e-04 - mse: 9.7559e-04 - val_loss: 9.9568e-05 - val_mse: 1.9914e-04\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.8215e-04 - mse: 9.6429e-04 - val_loss: 9.5859e-05 - val_mse: 1.9172e-04\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.7879e-04 - mse: 9.5758e-04 - val_loss: 9.7039e-05 - val_mse: 1.9408e-04\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 4.7278e-04 - mse: 9.4556e-04 - val_loss: 1.3048e-04 - val_mse: 2.6095e-04\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.6003e-04 - mse: 9.2007e-04 - val_loss: 1.0956e-04 - val_mse: 2.1912e-04\n",
      "pred.shape : (280, 1) , y_test.shape : (300,)\n",
      "1500길이의 데이터 적용 완료\n",
      " 길이: 1500, RMSE:711.715252716196\n",
      "train set 확인:  (1280, 4) (1280,) test set 확인:  (320, 4) (320,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 7s 48ms/step - loss: 0.0213 - mse: 0.0427 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 5.1828e-04 - val_mse: 0.0010\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 3.1840e-04 - val_mse: 6.3680e-04\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 2.9199e-04 - val_mse: 5.8399e-04\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.7648e-04 - val_mse: 3.5296e-04\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 9.7876e-04 - mse: 0.0020 - val_loss: 1.5463e-04 - val_mse: 3.0926e-04\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 9.2972e-04 - mse: 0.0019 - val_loss: 1.5663e-04 - val_mse: 3.1327e-04\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 9.2140e-04 - mse: 0.0018 - val_loss: 1.5371e-04 - val_mse: 3.0741e-04\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 8.8824e-04 - mse: 0.0018 - val_loss: 1.4427e-04 - val_mse: 2.8854e-04\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 8.7624e-04 - mse: 0.0018 - val_loss: 1.4396e-04 - val_mse: 2.8791e-04\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 8.7164e-04 - mse: 0.0017 - val_loss: 1.5155e-04 - val_mse: 3.0311e-04\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 8.5251e-04 - mse: 0.0017 - val_loss: 1.4031e-04 - val_mse: 2.8063e-04\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 8.1467e-04 - mse: 0.0016 - val_loss: 1.3771e-04 - val_mse: 2.7542e-04\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 7.9746e-04 - mse: 0.0016 - val_loss: 1.5440e-04 - val_mse: 3.0879e-04\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 8.0290e-04 - mse: 0.0016 - val_loss: 1.5053e-04 - val_mse: 3.0107e-04\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 7.6944e-04 - mse: 0.0015 - val_loss: 1.3379e-04 - val_mse: 2.6758e-04\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 7.4737e-04 - mse: 0.0015 - val_loss: 1.4010e-04 - val_mse: 2.8021e-04\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 7.3095e-04 - mse: 0.0015 - val_loss: 1.3864e-04 - val_mse: 2.7727e-04\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 7.0282e-04 - mse: 0.0014 - val_loss: 1.2350e-04 - val_mse: 2.4699e-04\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 6.9963e-04 - mse: 0.0014 - val_loss: 1.2112e-04 - val_mse: 2.4223e-04\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 6.8312e-04 - mse: 0.0014 - val_loss: 1.2029e-04 - val_mse: 2.4059e-04\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 6.4397e-04 - mse: 0.0013 - val_loss: 1.6573e-04 - val_mse: 3.3146e-04\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 6.5315e-04 - mse: 0.0013 - val_loss: 1.8611e-04 - val_mse: 3.7222e-04\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 6.4033e-04 - mse: 0.0013 - val_loss: 1.1438e-04 - val_mse: 2.2876e-04\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.9315e-04 - mse: 0.0012 - val_loss: 1.0425e-04 - val_mse: 2.0850e-04\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 5.9050e-04 - mse: 0.0012 - val_loss: 1.1515e-04 - val_mse: 2.3031e-04\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 5.7069e-04 - mse: 0.0011 - val_loss: 1.3420e-04 - val_mse: 2.6841e-04\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.7673e-04 - mse: 0.0012 - val_loss: 1.1140e-04 - val_mse: 2.2280e-04\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 5.5703e-04 - mse: 0.0011 - val_loss: 9.9133e-05 - val_mse: 1.9827e-04\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 5.3677e-04 - mse: 0.0011 - val_loss: 9.4225e-05 - val_mse: 1.8845e-04\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.3780e-04 - mse: 0.0011 - val_loss: 9.7095e-05 - val_mse: 1.9419e-04\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.0776e-04 - mse: 0.0010 - val_loss: 9.2893e-05 - val_mse: 1.8579e-04\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.1645e-04 - mse: 0.0010 - val_loss: 1.0232e-04 - val_mse: 2.0465e-04\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.0072e-04 - mse: 0.0010 - val_loss: 8.6384e-05 - val_mse: 1.7277e-04\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 4.7973e-04 - mse: 9.5947e-04 - val_loss: 1.7974e-04 - val_mse: 3.5947e-04\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 4.7999e-04 - mse: 9.5998e-04 - val_loss: 1.2740e-04 - val_mse: 2.5480e-04\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 4.7513e-04 - mse: 9.5025e-04 - val_loss: 9.0248e-05 - val_mse: 1.8050e-04\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 4.4871e-04 - mse: 8.9742e-04 - val_loss: 8.1801e-05 - val_mse: 1.6360e-04\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 4.4065e-04 - mse: 8.8130e-04 - val_loss: 8.0768e-05 - val_mse: 1.6154e-04\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 4.4899e-04 - mse: 8.9797e-04 - val_loss: 2.5532e-04 - val_mse: 5.1063e-04\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 4.4555e-04 - mse: 8.9110e-04 - val_loss: 1.1103e-04 - val_mse: 2.2206e-04\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 4.3833e-04 - mse: 8.7667e-04 - val_loss: 1.0937e-04 - val_mse: 2.1874e-04\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 4.4937e-04 - mse: 8.9873e-04 - val_loss: 7.7003e-05 - val_mse: 1.5401e-04\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 4.2608e-04 - mse: 8.5216e-04 - val_loss: 1.0677e-04 - val_mse: 2.1354e-04\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 4.3706e-04 - mse: 8.7412e-04 - val_loss: 7.6366e-05 - val_mse: 1.5273e-04\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 4.2343e-04 - mse: 8.4685e-04 - val_loss: 7.5113e-05 - val_mse: 1.5023e-04\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 4.3033e-04 - mse: 8.6066e-04 - val_loss: 8.3441e-05 - val_mse: 1.6688e-04\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 4.0451e-04 - mse: 8.0902e-04 - val_loss: 7.6087e-05 - val_mse: 1.5217e-04\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 4.0583e-04 - mse: 8.1166e-04 - val_loss: 7.3956e-05 - val_mse: 1.4791e-04\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 4.1589e-04 - mse: 8.3177e-04 - val_loss: 8.8869e-05 - val_mse: 1.7774e-04\n",
      "pred.shape : (300, 1) , y_test.shape : (320,)\n",
      "1600길이의 데이터 적용 완료\n",
      " 길이: 1600, RMSE:640.9997477265415\n",
      "train set 확인:  (1360, 4) (1360,) test set 확인:  (340, 4) (340,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 7s 50ms/step - loss: 0.1104 - mse: 0.2208 - val_loss: 0.0161 - val_mse: 0.0321\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 6.0136e-04 - val_mse: 0.0012\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 5.3061e-04 - val_mse: 0.0011\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 1.9465e-04 - val_mse: 3.8930e-04\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 1.5472e-04 - val_mse: 3.0944e-04\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 9.8647e-04 - mse: 0.0020 - val_loss: 1.6728e-04 - val_mse: 3.3455e-04\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 9.4561e-04 - mse: 0.0019 - val_loss: 1.5083e-04 - val_mse: 3.0166e-04\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 9.1909e-04 - mse: 0.0018 - val_loss: 1.5252e-04 - val_mse: 3.0505e-04\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 9.0956e-04 - mse: 0.0018 - val_loss: 1.6568e-04 - val_mse: 3.3135e-04\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 8.8027e-04 - mse: 0.0018 - val_loss: 1.4227e-04 - val_mse: 2.8453e-04\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 8.6999e-04 - mse: 0.0017 - val_loss: 1.4694e-04 - val_mse: 2.9388e-04\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 8.4486e-04 - mse: 0.0017 - val_loss: 1.3792e-04 - val_mse: 2.7584e-04\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 8.3997e-04 - mse: 0.0017 - val_loss: 1.7334e-04 - val_mse: 3.4668e-04\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 8.1006e-04 - mse: 0.0016 - val_loss: 1.3475e-04 - val_mse: 2.6950e-04\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 7.8760e-04 - mse: 0.0016 - val_loss: 1.3133e-04 - val_mse: 2.6266e-04\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 7.5284e-04 - mse: 0.0015 - val_loss: 1.8921e-04 - val_mse: 3.7843e-04\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 7.1949e-04 - mse: 0.0014 - val_loss: 1.2297e-04 - val_mse: 2.4594e-04\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 6.9700e-04 - mse: 0.0014 - val_loss: 1.2026e-04 - val_mse: 2.4052e-04\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 6.6077e-04 - mse: 0.0013 - val_loss: 1.1887e-04 - val_mse: 2.3775e-04\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 6.3784e-04 - mse: 0.0013 - val_loss: 1.1969e-04 - val_mse: 2.3938e-04\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 6.3192e-04 - mse: 0.0013 - val_loss: 1.3528e-04 - val_mse: 2.7056e-04\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 6.2238e-04 - mse: 0.0012 - val_loss: 1.2124e-04 - val_mse: 2.4249e-04\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 5.7751e-04 - mse: 0.0012 - val_loss: 1.0771e-04 - val_mse: 2.1542e-04\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 5.6432e-04 - mse: 0.0011 - val_loss: 1.0491e-04 - val_mse: 2.0981e-04\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 5.5471e-04 - mse: 0.0011 - val_loss: 1.1986e-04 - val_mse: 2.3973e-04\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 5.4858e-04 - mse: 0.0011 - val_loss: 1.0129e-04 - val_mse: 2.0257e-04\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 5.6409e-04 - mse: 0.0011 - val_loss: 9.5443e-05 - val_mse: 1.9089e-04\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 5.1838e-04 - mse: 0.0010 - val_loss: 1.1298e-04 - val_mse: 2.2596e-04\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 5.1430e-04 - mse: 0.0010 - val_loss: 9.4793e-05 - val_mse: 1.8959e-04\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 5.1797e-04 - mse: 0.0010 - val_loss: 9.6470e-05 - val_mse: 1.9294e-04\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.9651e-04 - mse: 9.9302e-04 - val_loss: 1.0180e-04 - val_mse: 2.0360e-04\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.8470e-04 - mse: 9.6940e-04 - val_loss: 1.1888e-04 - val_mse: 2.3776e-04\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.9216e-04 - mse: 9.8431e-04 - val_loss: 1.2212e-04 - val_mse: 2.4425e-04\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.9519e-04 - mse: 9.9037e-04 - val_loss: 1.0518e-04 - val_mse: 2.1036e-04\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.6401e-04 - mse: 9.2802e-04 - val_loss: 1.0834e-04 - val_mse: 2.1668e-04\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 4.8477e-04 - mse: 9.6955e-04 - val_loss: 1.0660e-04 - val_mse: 2.1320e-04\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.5424e-04 - mse: 9.0849e-04 - val_loss: 1.1920e-04 - val_mse: 2.3840e-04\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.5417e-04 - mse: 9.0834e-04 - val_loss: 8.5269e-05 - val_mse: 1.7054e-04\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.4681e-04 - mse: 8.9361e-04 - val_loss: 9.4319e-05 - val_mse: 1.8864e-04\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.4692e-04 - mse: 8.9385e-04 - val_loss: 9.0325e-05 - val_mse: 1.8065e-04\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.3727e-04 - mse: 8.7454e-04 - val_loss: 8.1243e-05 - val_mse: 1.6249e-04\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 4.4496e-04 - mse: 8.8991e-04 - val_loss: 8.2939e-05 - val_mse: 1.6588e-04\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.3415e-04 - mse: 8.6830e-04 - val_loss: 1.0250e-04 - val_mse: 2.0500e-04\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 4.2352e-04 - mse: 8.4704e-04 - val_loss: 8.2590e-05 - val_mse: 1.6518e-04\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 4.3223e-04 - mse: 8.6447e-04 - val_loss: 8.7816e-05 - val_mse: 1.7563e-04\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.2129e-04 - mse: 8.4258e-04 - val_loss: 8.3343e-05 - val_mse: 1.6669e-04\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.2170e-04 - mse: 8.4340e-04 - val_loss: 9.5133e-05 - val_mse: 1.9027e-04\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.1664e-04 - mse: 8.3328e-04 - val_loss: 8.2280e-05 - val_mse: 1.6456e-04\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 4.1187e-04 - mse: 8.2373e-04 - val_loss: 7.8630e-05 - val_mse: 1.5726e-04\n",
      "pred.shape : (320, 1) , y_test.shape : (340,)\n",
      "1700길이의 데이터 적용 완료\n",
      " 길이: 1700, RMSE:602.9435542442767\n",
      "train set 확인:  (1440, 4) (1440,) test set 확인:  (360, 4) (360,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 10s 63ms/step - loss: 0.1137 - mse: 0.2273 - val_loss: 0.0284 - val_mse: 0.0567\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.0156 - mse: 0.0312 - val_loss: 0.0017 - val_mse: 0.0034\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0014 - val_mse: 0.0029\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0037 - mse: 0.0073 - val_loss: 0.0013 - val_mse: 0.0026\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 7.3042e-04 - val_mse: 0.0015\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 3.5831e-04 - val_mse: 7.1661e-04\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 2.1993e-04 - val_mse: 4.3986e-04\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 3.2301e-04 - val_mse: 6.4602e-04\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 2.2000e-04 - val_mse: 4.4001e-04\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 2.0626e-04 - val_mse: 4.1252e-04\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 2.2593e-04 - val_mse: 4.5186e-04\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 1.8978e-04 - val_mse: 3.7956e-04\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 1.8264e-04 - val_mse: 3.6528e-04\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 1.7395e-04 - val_mse: 3.4789e-04\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 1.7249e-04 - val_mse: 3.4498e-04\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.7922e-04 - val_mse: 3.5843e-04\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 9.8915e-04 - mse: 0.0020 - val_loss: 1.5509e-04 - val_mse: 3.1018e-04\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 9.0510e-04 - mse: 0.0018 - val_loss: 1.3728e-04 - val_mse: 2.7455e-04\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 8.7186e-04 - mse: 0.0017 - val_loss: 1.3895e-04 - val_mse: 2.7790e-04\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 8.4533e-04 - mse: 0.0017 - val_loss: 1.2840e-04 - val_mse: 2.5679e-04\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 8.3083e-04 - mse: 0.0017 - val_loss: 2.7523e-04 - val_mse: 5.5047e-04\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 8.0799e-04 - mse: 0.0016 - val_loss: 1.2067e-04 - val_mse: 2.4135e-04\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 7.2600e-04 - mse: 0.0015 - val_loss: 2.2209e-04 - val_mse: 4.4419e-04\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 7.3249e-04 - mse: 0.0015 - val_loss: 1.4528e-04 - val_mse: 2.9056e-04\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 7.0349e-04 - mse: 0.0014 - val_loss: 1.2722e-04 - val_mse: 2.5444e-04\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 7.2652e-04 - mse: 0.0015 - val_loss: 2.4685e-04 - val_mse: 4.9369e-04\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 6.9475e-04 - mse: 0.0014 - val_loss: 1.2180e-04 - val_mse: 2.4361e-04\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 6.4434e-04 - mse: 0.0013 - val_loss: 1.1834e-04 - val_mse: 2.3669e-04\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 6.9041e-04 - mse: 0.0014 - val_loss: 1.1691e-04 - val_mse: 2.3383e-04\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 6.2588e-04 - mse: 0.0013 - val_loss: 1.1116e-04 - val_mse: 2.2233e-04\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 6.2562e-04 - mse: 0.0013 - val_loss: 1.4531e-04 - val_mse: 2.9062e-04\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 5.8765e-04 - mse: 0.0012 - val_loss: 1.0426e-04 - val_mse: 2.0852e-04\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 5.8510e-04 - mse: 0.0012 - val_loss: 1.2339e-04 - val_mse: 2.4678e-04\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 5.7755e-04 - mse: 0.0012 - val_loss: 1.5991e-04 - val_mse: 3.1981e-04\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 5.9294e-04 - mse: 0.0012 - val_loss: 1.3225e-04 - val_mse: 2.6451e-04\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 5.5953e-04 - mse: 0.0011 - val_loss: 9.7420e-05 - val_mse: 1.9484e-04\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 5.6356e-04 - mse: 0.0011 - val_loss: 9.8839e-05 - val_mse: 1.9768e-04\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 5.4140e-04 - mse: 0.0011 - val_loss: 2.2924e-04 - val_mse: 4.5848e-04\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 6.0850e-04 - mse: 0.0012 - val_loss: 1.4680e-04 - val_mse: 2.9359e-04\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 5.4569e-04 - mse: 0.0011 - val_loss: 9.3497e-05 - val_mse: 1.8699e-04\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 5.4607e-04 - mse: 0.0011 - val_loss: 9.6299e-05 - val_mse: 1.9260e-04\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 5.8142e-04 - mse: 0.0012 - val_loss: 1.5744e-04 - val_mse: 3.1488e-04\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 5.5300e-04 - mse: 0.0011 - val_loss: 1.3741e-04 - val_mse: 2.7482e-04\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 5.2669e-04 - mse: 0.0011 - val_loss: 9.0526e-05 - val_mse: 1.8105e-04\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 5.0727e-04 - mse: 0.0010 - val_loss: 1.0765e-04 - val_mse: 2.1531e-04\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 5.1877e-04 - mse: 0.0010 - val_loss: 9.6286e-05 - val_mse: 1.9257e-04\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 5.1343e-04 - mse: 0.0010 - val_loss: 1.5545e-04 - val_mse: 3.1089e-04\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 5.0950e-04 - mse: 0.0010 - val_loss: 1.0133e-04 - val_mse: 2.0267e-04\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 5.1494e-04 - mse: 0.0010 - val_loss: 1.5190e-04 - val_mse: 3.0379e-04\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 5.0905e-04 - mse: 0.0010 - val_loss: 1.0009e-04 - val_mse: 2.0017e-04\n",
      "pred.shape : (340, 1) , y_test.shape : (360,)\n",
      "1800길이의 데이터 적용 완료\n",
      " 길이: 1800, RMSE:680.2545695018231\n",
      "train set 확인:  (1520, 4) (1520,) test set 확인:  (380, 4) (380,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 7s 44ms/step - loss: 0.0657 - mse: 0.1313 - val_loss: 0.0030 - val_mse: 0.0060\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 7.2272e-04 - val_mse: 0.0014\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 2.0833e-04 - val_mse: 4.1666e-04\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.3387e-04 - val_mse: 4.6774e-04\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 2.1287e-04 - val_mse: 4.2574e-04\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.9879e-04 - val_mse: 3.9759e-04\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.5703e-04 - val_mse: 3.1406e-04\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 1.5357e-04 - val_mse: 3.0714e-04\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 9.6244e-04 - mse: 0.0019 - val_loss: 2.5356e-04 - val_mse: 5.0712e-04\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 9.4472e-04 - mse: 0.0019 - val_loss: 1.9852e-04 - val_mse: 3.9703e-04\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 8.6912e-04 - mse: 0.0017 - val_loss: 1.3329e-04 - val_mse: 2.6659e-04\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 8.3212e-04 - mse: 0.0017 - val_loss: 1.9534e-04 - val_mse: 3.9067e-04\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 8.2171e-04 - mse: 0.0016 - val_loss: 1.2984e-04 - val_mse: 2.5969e-04\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 7.4203e-04 - mse: 0.0015 - val_loss: 1.2352e-04 - val_mse: 2.4704e-04\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 7.0921e-04 - mse: 0.0014 - val_loss: 1.1949e-04 - val_mse: 2.3897e-04\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 6.7185e-04 - mse: 0.0013 - val_loss: 1.6480e-04 - val_mse: 3.2960e-04\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 6.2534e-04 - mse: 0.0013 - val_loss: 1.0819e-04 - val_mse: 2.1638e-04\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 6.1634e-04 - mse: 0.0012 - val_loss: 1.4159e-04 - val_mse: 2.8317e-04\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 6.0392e-04 - mse: 0.0012 - val_loss: 1.0376e-04 - val_mse: 2.0752e-04\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 6.0941e-04 - mse: 0.0012 - val_loss: 1.2484e-04 - val_mse: 2.4967e-04\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 5.8477e-04 - mse: 0.0012 - val_loss: 1.1780e-04 - val_mse: 2.3559e-04\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 6.0913e-04 - mse: 0.0012 - val_loss: 1.4467e-04 - val_mse: 2.8933e-04\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 5.6650e-04 - mse: 0.0011 - val_loss: 9.8533e-05 - val_mse: 1.9707e-04\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 5.4796e-04 - mse: 0.0011 - val_loss: 1.1008e-04 - val_mse: 2.2015e-04\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 5.4658e-04 - mse: 0.0011 - val_loss: 9.8080e-05 - val_mse: 1.9616e-04\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 5.5395e-04 - mse: 0.0011 - val_loss: 1.1735e-04 - val_mse: 2.3470e-04\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 6.3889e-04 - mse: 0.0013 - val_loss: 9.8264e-05 - val_mse: 1.9653e-04\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 5.2722e-04 - mse: 0.0011 - val_loss: 9.7264e-05 - val_mse: 1.9453e-04\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 5.1713e-04 - mse: 0.0010 - val_loss: 9.4436e-05 - val_mse: 1.8887e-04\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.9318e-04 - mse: 9.8635e-04 - val_loss: 8.7924e-05 - val_mse: 1.7585e-04\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 5.0114e-04 - mse: 0.0010 - val_loss: 1.2781e-04 - val_mse: 2.5563e-04\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 4.9921e-04 - mse: 9.9841e-04 - val_loss: 9.4207e-05 - val_mse: 1.8841e-04\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 4.9839e-04 - mse: 9.9678e-04 - val_loss: 1.5656e-04 - val_mse: 3.1312e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 4.8926e-04 - mse: 9.7852e-04 - val_loss: 9.8161e-05 - val_mse: 1.9632e-04\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 4.8762e-04 - mse: 9.7525e-04 - val_loss: 8.3608e-05 - val_mse: 1.6722e-04\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 4.6178e-04 - mse: 9.2355e-04 - val_loss: 8.3245e-05 - val_mse: 1.6649e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.6501e-04 - mse: 9.3002e-04 - val_loss: 1.4805e-04 - val_mse: 2.9611e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 4.7177e-04 - mse: 9.4353e-04 - val_loss: 8.2792e-05 - val_mse: 1.6558e-04\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 4.6284e-04 - mse: 9.2568e-04 - val_loss: 1.2381e-04 - val_mse: 2.4762e-04\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 4.5652e-04 - mse: 9.1304e-04 - val_loss: 1.0002e-04 - val_mse: 2.0005e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.6440e-04 - mse: 9.2880e-04 - val_loss: 1.3302e-04 - val_mse: 2.6604e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 4.7110e-04 - mse: 9.4219e-04 - val_loss: 1.6273e-04 - val_mse: 3.2546e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 4.9061e-04 - mse: 9.8122e-04 - val_loss: 8.4219e-05 - val_mse: 1.6844e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 4.6993e-04 - mse: 9.3986e-04 - val_loss: 7.9335e-05 - val_mse: 1.5867e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.6179e-04 - mse: 9.2358e-04 - val_loss: 9.1554e-05 - val_mse: 1.8311e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 4.3041e-04 - mse: 8.6082e-04 - val_loss: 1.0319e-04 - val_mse: 2.0639e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 4.4725e-04 - mse: 8.9450e-04 - val_loss: 7.6733e-05 - val_mse: 1.5347e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.2702e-04 - mse: 8.5404e-04 - val_loss: 8.4473e-05 - val_mse: 1.6895e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 4.2878e-04 - mse: 8.5757e-04 - val_loss: 7.5528e-05 - val_mse: 1.5106e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 4.2193e-04 - mse: 8.4387e-04 - val_loss: 7.5236e-05 - val_mse: 1.5047e-04\n",
      "pred.shape : (360, 1) , y_test.shape : (380,)\n",
      "1900길이의 데이터 적용 완료\n",
      " 길이: 1900, RMSE:594.4011921230186\n",
      "train set 확인:  (1600, 4) (1600,) test set 확인:  (400, 4) (400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 8s 44ms/step - loss: 0.0795 - mse: 0.1590 - val_loss: 6.1692e-04 - val_mse: 0.0012\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 3.9838e-04 - val_mse: 7.9675e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0019 - mse: 0.0039 - val_loss: 2.3373e-04 - val_mse: 4.6746e-04\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 1.6025e-04 - val_mse: 3.2050e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 9.1169e-04 - mse: 0.0018 - val_loss: 2.7998e-04 - val_mse: 5.5996e-04\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 8.8540e-04 - mse: 0.0018 - val_loss: 1.4712e-04 - val_mse: 2.9424e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 8.5491e-04 - mse: 0.0017 - val_loss: 1.5320e-04 - val_mse: 3.0640e-04\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 8.1526e-04 - mse: 0.0016 - val_loss: 1.4126e-04 - val_mse: 2.8252e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 7.8994e-04 - mse: 0.0016 - val_loss: 1.3818e-04 - val_mse: 2.7636e-04\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 7.5155e-04 - mse: 0.0015 - val_loss: 1.3764e-04 - val_mse: 2.7527e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 7.1887e-04 - mse: 0.0014 - val_loss: 1.2414e-04 - val_mse: 2.4829e-04\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 6.9928e-04 - mse: 0.0014 - val_loss: 1.6433e-04 - val_mse: 3.2866e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.5676e-04 - mse: 0.0013 - val_loss: 1.2167e-04 - val_mse: 2.4333e-04\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 6.2528e-04 - mse: 0.0013 - val_loss: 1.1131e-04 - val_mse: 2.2262e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 6.1115e-04 - mse: 0.0012 - val_loss: 1.1225e-04 - val_mse: 2.2450e-04\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.8597e-04 - mse: 0.0012 - val_loss: 1.1751e-04 - val_mse: 2.3503e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.7617e-04 - mse: 0.0012 - val_loss: 1.0732e-04 - val_mse: 2.1464e-04\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.5791e-04 - mse: 0.0011 - val_loss: 1.0099e-04 - val_mse: 2.0198e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 5.4367e-04 - mse: 0.0011 - val_loss: 1.4820e-04 - val_mse: 2.9640e-04\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 5.4644e-04 - mse: 0.0011 - val_loss: 9.9222e-05 - val_mse: 1.9844e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 5.1933e-04 - mse: 0.0010 - val_loss: 1.1161e-04 - val_mse: 2.2321e-04\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 5.1753e-04 - mse: 0.0010 - val_loss: 1.0384e-04 - val_mse: 2.0767e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.0970e-04 - mse: 0.0010 - val_loss: 9.9483e-05 - val_mse: 1.9897e-04\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.9176e-04 - mse: 9.8353e-04 - val_loss: 9.7879e-05 - val_mse: 1.9576e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 5.0245e-04 - mse: 0.0010 - val_loss: 9.3978e-05 - val_mse: 1.8796e-04\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.8157e-04 - mse: 9.6314e-04 - val_loss: 9.2479e-05 - val_mse: 1.8496e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.9005e-04 - mse: 9.8010e-04 - val_loss: 9.6059e-05 - val_mse: 1.9212e-04\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.8691e-04 - mse: 9.7381e-04 - val_loss: 9.9245e-05 - val_mse: 1.9849e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.6466e-04 - mse: 9.2931e-04 - val_loss: 1.0521e-04 - val_mse: 2.1042e-04\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.6297e-04 - mse: 9.2594e-04 - val_loss: 1.1163e-04 - val_mse: 2.2325e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 4.6557e-04 - mse: 9.3115e-04 - val_loss: 1.5469e-04 - val_mse: 3.0937e-04\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.6495e-04 - mse: 9.2989e-04 - val_loss: 8.7471e-05 - val_mse: 1.7494e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.5309e-04 - mse: 9.0618e-04 - val_loss: 9.9751e-05 - val_mse: 1.9950e-04\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 4.5455e-04 - mse: 9.0910e-04 - val_loss: 1.3995e-04 - val_mse: 2.7990e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.7503e-04 - mse: 9.5006e-04 - val_loss: 9.7567e-05 - val_mse: 1.9513e-04\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.4231e-04 - mse: 8.8462e-04 - val_loss: 9.5438e-05 - val_mse: 1.9088e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.4475e-04 - mse: 8.8950e-04 - val_loss: 9.8096e-05 - val_mse: 1.9619e-04\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.6480e-04 - mse: 9.2960e-04 - val_loss: 1.1589e-04 - val_mse: 2.3178e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 4.4633e-04 - mse: 8.9267e-04 - val_loss: 9.9092e-05 - val_mse: 1.9818e-04\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.4497e-04 - mse: 8.8994e-04 - val_loss: 9.8382e-05 - val_mse: 1.9676e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.3082e-04 - mse: 8.6164e-04 - val_loss: 8.4285e-05 - val_mse: 1.6857e-04\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 4.2528e-04 - mse: 8.5056e-04 - val_loss: 8.2362e-05 - val_mse: 1.6472e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.3676e-04 - mse: 8.7351e-04 - val_loss: 1.0633e-04 - val_mse: 2.1265e-04\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 4.2451e-04 - mse: 8.4902e-04 - val_loss: 8.4221e-05 - val_mse: 1.6844e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 4.1547e-04 - mse: 8.3095e-04 - val_loss: 8.8111e-05 - val_mse: 1.7622e-04\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 4.2745e-04 - mse: 8.5490e-04 - val_loss: 1.0225e-04 - val_mse: 2.0450e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.2214e-04 - mse: 8.4428e-04 - val_loss: 1.1464e-04 - val_mse: 2.2929e-04\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.0642e-04 - mse: 8.1284e-04 - val_loss: 9.7166e-05 - val_mse: 1.9433e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.1145e-04 - mse: 8.2289e-04 - val_loss: 8.1461e-05 - val_mse: 1.6292e-04\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 4.1277e-04 - mse: 8.2555e-04 - val_loss: 1.1771e-04 - val_mse: 2.3542e-04\n",
      "pred.shape : (380, 1) , y_test.shape : (400,)\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:743.485634446954\n",
      "train set 확인:  (1680, 4) (1680,) test set 확인:  (420, 4) (420,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 6s 34ms/step - loss: 0.0875 - mse: 0.1750 - val_loss: 0.0057 - val_mse: 0.0115\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0051 - mse: 0.0103 - val_loss: 6.5436e-04 - val_mse: 0.0013\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 2.7454e-04 - val_mse: 5.4908e-04\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 9.7933e-04 - mse: 0.0020 - val_loss: 2.4057e-04 - val_mse: 4.8115e-04\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 9.5245e-04 - mse: 0.0019 - val_loss: 2.4533e-04 - val_mse: 4.9065e-04\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 8.7743e-04 - mse: 0.0018 - val_loss: 1.6378e-04 - val_mse: 3.2756e-04\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 8.4005e-04 - mse: 0.0017 - val_loss: 1.9529e-04 - val_mse: 3.9057e-04\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 8.1687e-04 - mse: 0.0016 - val_loss: 1.4206e-04 - val_mse: 2.8413e-04\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 7.7691e-04 - mse: 0.0016 - val_loss: 1.3573e-04 - val_mse: 2.7146e-04\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 7.6685e-04 - mse: 0.0015 - val_loss: 1.3908e-04 - val_mse: 2.7816e-04\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 7.1372e-04 - mse: 0.0014 - val_loss: 1.5476e-04 - val_mse: 3.0953e-04\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 6.9007e-04 - mse: 0.0014 - val_loss: 1.4028e-04 - val_mse: 2.8057e-04\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 6.5166e-04 - mse: 0.0013 - val_loss: 1.3144e-04 - val_mse: 2.6289e-04\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 6.4641e-04 - mse: 0.0013 - val_loss: 1.7755e-04 - val_mse: 3.5509e-04\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 6.0632e-04 - mse: 0.0012 - val_loss: 1.5243e-04 - val_mse: 3.0486e-04\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.9034e-04 - mse: 0.0012 - val_loss: 1.0875e-04 - val_mse: 2.1751e-04\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 5.7340e-04 - mse: 0.0011 - val_loss: 1.1275e-04 - val_mse: 2.2549e-04\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 5.6531e-04 - mse: 0.0011 - val_loss: 1.3049e-04 - val_mse: 2.6098e-04\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 5.2565e-04 - mse: 0.0011 - val_loss: 1.0639e-04 - val_mse: 2.1278e-04\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.2992e-04 - mse: 0.0011 - val_loss: 1.2982e-04 - val_mse: 2.5964e-04\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 5.0263e-04 - mse: 0.0010 - val_loss: 1.1200e-04 - val_mse: 2.2400e-04\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.6584e-04 - mse: 9.3167e-04 - val_loss: 9.3329e-05 - val_mse: 1.8666e-04\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.6833e-04 - mse: 9.3665e-04 - val_loss: 9.0978e-05 - val_mse: 1.8196e-04\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.4653e-04 - mse: 8.9306e-04 - val_loss: 1.1266e-04 - val_mse: 2.2532e-04\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.5219e-04 - mse: 9.0438e-04 - val_loss: 1.2528e-04 - val_mse: 2.5056e-04\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 4.5134e-04 - mse: 9.0268e-04 - val_loss: 2.1019e-04 - val_mse: 4.2038e-04\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 4.6405e-04 - mse: 9.2811e-04 - val_loss: 9.8418e-05 - val_mse: 1.9684e-04\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.1173e-04 - mse: 8.2345e-04 - val_loss: 9.4851e-05 - val_mse: 1.8970e-04\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.0622e-04 - mse: 8.1245e-04 - val_loss: 8.5275e-05 - val_mse: 1.7055e-04\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9164e-04 - mse: 7.8327e-04 - val_loss: 8.8924e-05 - val_mse: 1.7785e-04\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 4.1989e-04 - mse: 8.3978e-04 - val_loss: 1.4632e-04 - val_mse: 2.9264e-04\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.8614e-04 - mse: 7.7228e-04 - val_loss: 8.1462e-05 - val_mse: 1.6292e-04\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.9184e-04 - mse: 7.8368e-04 - val_loss: 7.9573e-05 - val_mse: 1.5915e-04\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 4.0785e-04 - mse: 8.1571e-04 - val_loss: 8.2986e-05 - val_mse: 1.6597e-04\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 4.0648e-04 - mse: 8.1296e-04 - val_loss: 1.0168e-04 - val_mse: 2.0336e-04\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 4.0828e-04 - mse: 8.1657e-04 - val_loss: 1.0571e-04 - val_mse: 2.1143e-04\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 3.7172e-04 - mse: 7.4344e-04 - val_loss: 2.0254e-04 - val_mse: 4.0508e-04\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7357e-04 - mse: 7.4713e-04 - val_loss: 7.9585e-05 - val_mse: 1.5917e-04\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.6166e-04 - mse: 7.2331e-04 - val_loss: 8.4485e-05 - val_mse: 1.6897e-04\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5104e-04 - mse: 7.0208e-04 - val_loss: 8.5321e-05 - val_mse: 1.7064e-04\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5826e-04 - mse: 7.1653e-04 - val_loss: 7.4938e-05 - val_mse: 1.4988e-04\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 3.6946e-04 - mse: 7.3892e-04 - val_loss: 7.4867e-05 - val_mse: 1.4973e-04\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.5848e-04 - mse: 7.1697e-04 - val_loss: 3.0723e-04 - val_mse: 6.1446e-04\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.7365e-04 - mse: 7.4729e-04 - val_loss: 7.3279e-05 - val_mse: 1.4656e-04\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 3.5020e-04 - mse: 7.0040e-04 - val_loss: 8.2120e-05 - val_mse: 1.6424e-04\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 3.7651e-04 - mse: 7.5303e-04 - val_loss: 1.3699e-04 - val_mse: 2.7399e-04\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.4423e-04 - mse: 6.8845e-04 - val_loss: 1.2320e-04 - val_mse: 2.4641e-04\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 3.4869e-04 - mse: 6.9737e-04 - val_loss: 1.0072e-04 - val_mse: 2.0145e-04\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 3.5424e-04 - mse: 7.0849e-04 - val_loss: 7.6546e-05 - val_mse: 1.5309e-04\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 3.4278e-04 - mse: 6.8557e-04 - val_loss: 7.9866e-05 - val_mse: 1.5973e-04\n",
      "pred.shape : (400, 1) , y_test.shape : (420,)\n",
      "2100길이의 데이터 적용 완료\n",
      " 길이: 2100, RMSE:690.4013866390744\n",
      "train set 확인:  (1760, 4) (1760,) test set 확인:  (440, 4) (440,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 8s 41ms/step - loss: 0.0269 - mse: 0.0537 - val_loss: 7.1804e-04 - val_mse: 0.0014\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 2.2493e-04 - val_mse: 4.4987e-04\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 8.0900e-04 - mse: 0.0016 - val_loss: 1.5041e-04 - val_mse: 3.0082e-04\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 7.1335e-04 - mse: 0.0014 - val_loss: 1.4167e-04 - val_mse: 2.8335e-04\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 6.9761e-04 - mse: 0.0014 - val_loss: 1.6033e-04 - val_mse: 3.2066e-04\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 6.6978e-04 - mse: 0.0013 - val_loss: 1.3702e-04 - val_mse: 2.7403e-04\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 6.5077e-04 - mse: 0.0013 - val_loss: 1.3256e-04 - val_mse: 2.6512e-04\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 6.3296e-04 - mse: 0.0013 - val_loss: 1.4061e-04 - val_mse: 2.8121e-04\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 6.2634e-04 - mse: 0.0013 - val_loss: 1.2676e-04 - val_mse: 2.5352e-04\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 6.0344e-04 - mse: 0.0012 - val_loss: 1.3858e-04 - val_mse: 2.7716e-04\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 5.9867e-04 - mse: 0.0012 - val_loss: 1.2879e-04 - val_mse: 2.5759e-04\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 5.6860e-04 - mse: 0.0011 - val_loss: 1.1923e-04 - val_mse: 2.3846e-04\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 5.6289e-04 - mse: 0.0011 - val_loss: 1.2138e-04 - val_mse: 2.4277e-04\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 5.5495e-04 - mse: 0.0011 - val_loss: 1.2220e-04 - val_mse: 2.4440e-04\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 5.5257e-04 - mse: 0.0011 - val_loss: 1.1548e-04 - val_mse: 2.3095e-04\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 5.1477e-04 - mse: 0.0010 - val_loss: 1.2303e-04 - val_mse: 2.4605e-04\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 5.2019e-04 - mse: 0.0010 - val_loss: 1.0894e-04 - val_mse: 2.1788e-04\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 5.1130e-04 - mse: 0.0010 - val_loss: 1.2703e-04 - val_mse: 2.5405e-04\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 4.7947e-04 - mse: 9.5893e-04 - val_loss: 1.0439e-04 - val_mse: 2.0878e-04\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 4.6832e-04 - mse: 9.3663e-04 - val_loss: 1.1922e-04 - val_mse: 2.3844e-04\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 4.6470e-04 - mse: 9.2940e-04 - val_loss: 9.9532e-05 - val_mse: 1.9906e-04\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 4.7397e-04 - mse: 9.4793e-04 - val_loss: 9.8553e-05 - val_mse: 1.9711e-04\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 4.4831e-04 - mse: 8.9662e-04 - val_loss: 1.1756e-04 - val_mse: 2.3512e-04\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 2s 27ms/step - loss: 4.7502e-04 - mse: 9.5004e-04 - val_loss: 9.5938e-05 - val_mse: 1.9188e-04\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 4.2300e-04 - mse: 8.4601e-04 - val_loss: 9.7167e-05 - val_mse: 1.9433e-04\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 4.0678e-04 - mse: 8.1356e-04 - val_loss: 1.1487e-04 - val_mse: 2.2975e-04\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 4.1488e-04 - mse: 8.2975e-04 - val_loss: 1.0556e-04 - val_mse: 2.1112e-04\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.9255e-04 - mse: 7.8511e-04 - val_loss: 1.0224e-04 - val_mse: 2.0448e-04\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 4.0953e-04 - mse: 8.1905e-04 - val_loss: 8.7621e-05 - val_mse: 1.7524e-04\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 3.8552e-04 - mse: 7.7104e-04 - val_loss: 8.5805e-05 - val_mse: 1.7161e-04\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.8012e-04 - mse: 7.6024e-04 - val_loss: 9.9257e-05 - val_mse: 1.9851e-04\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 3.7700e-04 - mse: 7.5399e-04 - val_loss: 8.5483e-05 - val_mse: 1.7097e-04\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.7860e-04 - mse: 7.5721e-04 - val_loss: 8.6094e-05 - val_mse: 1.7219e-04\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 3.6207e-04 - mse: 7.2414e-04 - val_loss: 8.4875e-05 - val_mse: 1.6975e-04\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 3.5116e-04 - mse: 7.0232e-04 - val_loss: 1.0688e-04 - val_mse: 2.1375e-04\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 3.4703e-04 - mse: 6.9406e-04 - val_loss: 8.5182e-05 - val_mse: 1.7036e-04\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 3.6290e-04 - mse: 7.2580e-04 - val_loss: 1.4473e-04 - val_mse: 2.8946e-04\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 3.4988e-04 - mse: 6.9977e-04 - val_loss: 8.3387e-05 - val_mse: 1.6677e-04\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.2903e-04 - mse: 6.5806e-04 - val_loss: 8.0580e-05 - val_mse: 1.6116e-04\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.2888e-04 - mse: 6.5775e-04 - val_loss: 1.0206e-04 - val_mse: 2.0413e-04\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 3.3574e-04 - mse: 6.7147e-04 - val_loss: 1.0634e-04 - val_mse: 2.1268e-04\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 3.3858e-04 - mse: 6.7716e-04 - val_loss: 1.0207e-04 - val_mse: 2.0414e-04\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 3.2497e-04 - mse: 6.4994e-04 - val_loss: 1.1808e-04 - val_mse: 2.3617e-04\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 3.3205e-04 - mse: 6.6410e-04 - val_loss: 8.1089e-05 - val_mse: 1.6218e-04\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 3.3203e-04 - mse: 6.6406e-04 - val_loss: 7.9739e-05 - val_mse: 1.5948e-04\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 3.2191e-04 - mse: 6.4382e-04 - val_loss: 7.8599e-05 - val_mse: 1.5720e-04\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 3.2588e-04 - mse: 6.5177e-04 - val_loss: 7.3284e-05 - val_mse: 1.4657e-04\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 3.1854e-04 - mse: 6.3709e-04 - val_loss: 1.1246e-04 - val_mse: 2.2493e-04\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 3.1747e-04 - mse: 6.3493e-04 - val_loss: 7.2879e-05 - val_mse: 1.4576e-04\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 3.0223e-04 - mse: 6.0446e-04 - val_loss: 7.2101e-05 - val_mse: 1.4420e-04\n",
      "pred.shape : (420, 1) , y_test.shape : (440,)\n",
      "2200길이의 데이터 적용 완료\n",
      " 길이: 2200, RMSE:669.0602954657662\n",
      "train set 확인:  (1840, 4) (1840,) test set 확인:  (460, 4) (460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "57/57 [==============================] - 6s 34ms/step - loss: 0.0804 - mse: 0.1607 - val_loss: 6.9681e-04 - val_mse: 0.0014\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0025 - mse: 0.0051 - val_loss: 1.6753e-04 - val_mse: 3.3507e-04\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 8.1389e-04 - mse: 0.0016 - val_loss: 1.5763e-04 - val_mse: 3.1526e-04\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 7.7373e-04 - mse: 0.0015 - val_loss: 1.6095e-04 - val_mse: 3.2190e-04\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 7.3313e-04 - mse: 0.0015 - val_loss: 1.4927e-04 - val_mse: 2.9854e-04\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 7.1520e-04 - mse: 0.0014 - val_loss: 1.4624e-04 - val_mse: 2.9248e-04\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 7.0091e-04 - mse: 0.0014 - val_loss: 1.4309e-04 - val_mse: 2.8619e-04\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 6.7972e-04 - mse: 0.0014 - val_loss: 1.7054e-04 - val_mse: 3.4107e-04\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 6.5297e-04 - mse: 0.0013 - val_loss: 1.3692e-04 - val_mse: 2.7385e-04\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 6.3504e-04 - mse: 0.0013 - val_loss: 1.3547e-04 - val_mse: 2.7094e-04\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 6.2085e-04 - mse: 0.0012 - val_loss: 1.4525e-04 - val_mse: 2.9050e-04\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 6.2795e-04 - mse: 0.0013 - val_loss: 1.5640e-04 - val_mse: 3.1280e-04\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 6.1011e-04 - mse: 0.0012 - val_loss: 1.2523e-04 - val_mse: 2.5045e-04\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 5.9410e-04 - mse: 0.0012 - val_loss: 1.3899e-04 - val_mse: 2.7799e-04\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 5.3655e-04 - mse: 0.0011 - val_loss: 1.3657e-04 - val_mse: 2.7314e-04\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 5.3859e-04 - mse: 0.0011 - val_loss: 1.4826e-04 - val_mse: 2.9653e-04\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 5.0195e-04 - mse: 0.0010 - val_loss: 1.5284e-04 - val_mse: 3.0568e-04\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 5.0134e-04 - mse: 0.0010 - val_loss: 1.2829e-04 - val_mse: 2.5659e-04\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.7515e-04 - mse: 9.5031e-04 - val_loss: 1.3125e-04 - val_mse: 2.6250e-04\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.7301e-04 - mse: 9.4602e-04 - val_loss: 1.3086e-04 - val_mse: 2.6172e-04\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.8027e-04 - mse: 9.6054e-04 - val_loss: 1.2058e-04 - val_mse: 2.4116e-04\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.4949e-04 - mse: 8.9898e-04 - val_loss: 1.1093e-04 - val_mse: 2.2186e-04\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.3493e-04 - mse: 8.6987e-04 - val_loss: 1.5863e-04 - val_mse: 3.1726e-04\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 4.2648e-04 - mse: 8.5295e-04 - val_loss: 1.0952e-04 - val_mse: 2.1904e-04\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 4.3564e-04 - mse: 8.7128e-04 - val_loss: 1.0950e-04 - val_mse: 2.1899e-04\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 4.1139e-04 - mse: 8.2278e-04 - val_loss: 1.1114e-04 - val_mse: 2.2229e-04\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.1196e-04 - mse: 8.2392e-04 - val_loss: 1.3230e-04 - val_mse: 2.6460e-04\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 4.2294e-04 - mse: 8.4589e-04 - val_loss: 1.3058e-04 - val_mse: 2.6116e-04\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 4.4428e-04 - mse: 8.8856e-04 - val_loss: 1.2042e-04 - val_mse: 2.4085e-04\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.9023e-04 - mse: 7.8046e-04 - val_loss: 1.0772e-04 - val_mse: 2.1544e-04\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.8114e-04 - mse: 7.6228e-04 - val_loss: 9.3254e-05 - val_mse: 1.8651e-04\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.7485e-04 - mse: 7.4971e-04 - val_loss: 9.2466e-05 - val_mse: 1.8493e-04\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.7082e-04 - mse: 7.4165e-04 - val_loss: 1.1046e-04 - val_mse: 2.2093e-04\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.6453e-04 - mse: 7.2907e-04 - val_loss: 9.4021e-05 - val_mse: 1.8804e-04\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.6580e-04 - mse: 7.3161e-04 - val_loss: 1.7131e-04 - val_mse: 3.4263e-04\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 3.5641e-04 - mse: 7.1281e-04 - val_loss: 9.0767e-05 - val_mse: 1.8153e-04\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.4814e-04 - mse: 6.9628e-04 - val_loss: 2.0169e-04 - val_mse: 4.0337e-04\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.6932e-04 - mse: 7.3864e-04 - val_loss: 1.0482e-04 - val_mse: 2.0964e-04\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.5197e-04 - mse: 7.0394e-04 - val_loss: 1.1002e-04 - val_mse: 2.2003e-04\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.3552e-04 - mse: 6.7104e-04 - val_loss: 1.2554e-04 - val_mse: 2.5108e-04\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.3782e-04 - mse: 6.7564e-04 - val_loss: 9.1184e-05 - val_mse: 1.8237e-04\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 3.3597e-04 - mse: 6.7194e-04 - val_loss: 8.4550e-05 - val_mse: 1.6910e-04\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.2363e-04 - mse: 6.4727e-04 - val_loss: 8.9556e-05 - val_mse: 1.7911e-04\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.2858e-04 - mse: 6.5715e-04 - val_loss: 8.4528e-05 - val_mse: 1.6906e-04\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.4758e-04 - mse: 6.9517e-04 - val_loss: 1.9992e-04 - val_mse: 3.9983e-04\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 3.2871e-04 - mse: 6.5741e-04 - val_loss: 9.0950e-05 - val_mse: 1.8190e-04\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.1628e-04 - mse: 6.3256e-04 - val_loss: 8.8510e-05 - val_mse: 1.7702e-04\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.4199e-04 - mse: 6.8398e-04 - val_loss: 8.7461e-05 - val_mse: 1.7492e-04\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 3.1125e-04 - mse: 6.2251e-04 - val_loss: 9.8422e-05 - val_mse: 1.9684e-04\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.1661e-04 - mse: 6.3322e-04 - val_loss: 9.1218e-05 - val_mse: 1.8244e-04\n",
      "pred.shape : (440, 1) , y_test.shape : (460,)\n",
      "2300길이의 데이터 적용 완료\n",
      " 길이: 2300, RMSE:758.065361279851\n",
      "train set 확인:  (1920, 4) (1920,) test set 확인:  (480, 4) (480,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60/60 [==============================] - 5s 31ms/step - loss: 0.0522 - mse: 0.1045 - val_loss: 0.0038 - val_mse: 0.0077\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.0033 - mse: 0.0067 - val_loss: 2.7891e-04 - val_mse: 5.5782e-04\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 8.2720e-04 - mse: 0.0017 - val_loss: 2.9718e-04 - val_mse: 5.9436e-04\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 7.2239e-04 - mse: 0.0014 - val_loss: 1.8563e-04 - val_mse: 3.7125e-04\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: 7.0650e-04 - mse: 0.0014 - val_loss: 1.9355e-04 - val_mse: 3.8709e-04\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 6.9146e-04 - mse: 0.0014 - val_loss: 1.7590e-04 - val_mse: 3.5179e-04\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 6.5660e-04 - mse: 0.0013 - val_loss: 1.7285e-04 - val_mse: 3.4569e-04\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 6.5604e-04 - mse: 0.0013 - val_loss: 1.8633e-04 - val_mse: 3.7265e-04\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 6.1767e-04 - mse: 0.0012 - val_loss: 2.4348e-04 - val_mse: 4.8695e-04\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 6.2048e-04 - mse: 0.0012 - val_loss: 1.6778e-04 - val_mse: 3.3555e-04\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 5.9679e-04 - mse: 0.0012 - val_loss: 1.6732e-04 - val_mse: 3.3463e-04\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 5.8306e-04 - mse: 0.0012 - val_loss: 1.6490e-04 - val_mse: 3.2979e-04\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 5.7141e-04 - mse: 0.0011 - val_loss: 2.2842e-04 - val_mse: 4.5685e-04\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 5.4482e-04 - mse: 0.0011 - val_loss: 2.0575e-04 - val_mse: 4.1151e-04\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 5.4145e-04 - mse: 0.0011 - val_loss: 1.5238e-04 - val_mse: 3.0475e-04\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 5.2632e-04 - mse: 0.0011 - val_loss: 1.5490e-04 - val_mse: 3.0980e-04\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 5.0885e-04 - mse: 0.0010 - val_loss: 1.3925e-04 - val_mse: 2.7850e-04\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.9925e-04 - mse: 9.9851e-04 - val_loss: 1.5298e-04 - val_mse: 3.0595e-04\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.9670e-04 - mse: 9.9340e-04 - val_loss: 1.5329e-04 - val_mse: 3.0659e-04\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.7417e-04 - mse: 9.4834e-04 - val_loss: 1.5154e-04 - val_mse: 3.0307e-04\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 4.8915e-04 - mse: 9.7831e-04 - val_loss: 1.3272e-04 - val_mse: 2.6544e-04\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 4.5067e-04 - mse: 9.0135e-04 - val_loss: 1.2814e-04 - val_mse: 2.5628e-04\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.4470e-04 - mse: 8.8941e-04 - val_loss: 1.4572e-04 - val_mse: 2.9143e-04\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.3447e-04 - mse: 8.6894e-04 - val_loss: 1.2672e-04 - val_mse: 2.5343e-04\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 4.3492e-04 - mse: 8.6985e-04 - val_loss: 1.2496e-04 - val_mse: 2.4993e-04\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 4.2806e-04 - mse: 8.5612e-04 - val_loss: 1.3691e-04 - val_mse: 2.7381e-04\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 4.0795e-04 - mse: 8.1590e-04 - val_loss: 1.5073e-04 - val_mse: 3.0146e-04\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.9939e-04 - mse: 7.9878e-04 - val_loss: 1.4061e-04 - val_mse: 2.8122e-04\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 4.2935e-04 - mse: 8.5870e-04 - val_loss: 2.7396e-04 - val_mse: 5.4791e-04\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 4.0089e-04 - mse: 8.0179e-04 - val_loss: 1.6649e-04 - val_mse: 3.3299e-04\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 3.9120e-04 - mse: 7.8241e-04 - val_loss: 1.7167e-04 - val_mse: 3.4335e-04\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.0342e-04 - mse: 8.0685e-04 - val_loss: 1.3057e-04 - val_mse: 2.6114e-04\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 2s 23ms/step - loss: 3.8635e-04 - mse: 7.7271e-04 - val_loss: 1.6304e-04 - val_mse: 3.2607e-04\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 3.8194e-04 - mse: 7.6388e-04 - val_loss: 1.1222e-04 - val_mse: 2.2444e-04\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.6999e-04 - mse: 7.3999e-04 - val_loss: 1.3926e-04 - val_mse: 2.7852e-04\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 3.7705e-04 - mse: 7.5409e-04 - val_loss: 3.2260e-04 - val_mse: 6.4521e-04\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 3.8306e-04 - mse: 7.6612e-04 - val_loss: 1.5571e-04 - val_mse: 3.1142e-04\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 3.9954e-04 - mse: 7.9908e-04 - val_loss: 1.2385e-04 - val_mse: 2.4770e-04\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.7114e-04 - mse: 7.4228e-04 - val_loss: 1.3632e-04 - val_mse: 2.7264e-04\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 3.5222e-04 - mse: 7.0445e-04 - val_loss: 1.1006e-04 - val_mse: 2.2012e-04\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 3.4906e-04 - mse: 6.9812e-04 - val_loss: 1.1411e-04 - val_mse: 2.2822e-04\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 3.4843e-04 - mse: 6.9686e-04 - val_loss: 1.0939e-04 - val_mse: 2.1879e-04\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.4827e-04 - mse: 6.9654e-04 - val_loss: 1.0755e-04 - val_mse: 2.1510e-04\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 3.4976e-04 - mse: 6.9952e-04 - val_loss: 1.1001e-04 - val_mse: 2.2003e-04\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 3.5652e-04 - mse: 7.1304e-04 - val_loss: 1.0615e-04 - val_mse: 2.1230e-04\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.3628e-04 - mse: 6.7255e-04 - val_loss: 1.2116e-04 - val_mse: 2.4233e-04\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.6129e-04 - mse: 7.2258e-04 - val_loss: 1.3208e-04 - val_mse: 2.6415e-04\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.5208e-04 - mse: 7.0417e-04 - val_loss: 1.2311e-04 - val_mse: 2.4622e-04\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.4414e-04 - mse: 6.8829e-04 - val_loss: 1.0241e-04 - val_mse: 2.0482e-04\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 3.4770e-04 - mse: 6.9540e-04 - val_loss: 1.0471e-04 - val_mse: 2.0943e-04\n",
      "pred.shape : (460, 1) , y_test.shape : (480,)\n",
      "2400길이의 데이터 적용 완료\n",
      " 길이: 2400, RMSE:812.2081652872217\n",
      "train set 확인:  (2000, 4) (2000,) test set 확인:  (500, 4) (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 7s 38ms/step - loss: 0.0518 - mse: 0.1036 - val_loss: 0.0022 - val_mse: 0.0043\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0030 - mse: 0.0061 - val_loss: 2.5603e-04 - val_mse: 5.1207e-04\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 9.4088e-04 - mse: 0.0019 - val_loss: 2.4554e-04 - val_mse: 4.9108e-04\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 8.1068e-04 - mse: 0.0016 - val_loss: 2.3661e-04 - val_mse: 4.7322e-04\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 7.9237e-04 - mse: 0.0016 - val_loss: 2.4213e-04 - val_mse: 4.8427e-04\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 7.6778e-04 - mse: 0.0015 - val_loss: 2.3534e-04 - val_mse: 4.7068e-04\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 7.5096e-04 - mse: 0.0015 - val_loss: 3.0848e-04 - val_mse: 6.1697e-04\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 7.3872e-04 - mse: 0.0015 - val_loss: 2.1324e-04 - val_mse: 4.2649e-04\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 7.1609e-04 - mse: 0.0014 - val_loss: 2.0936e-04 - val_mse: 4.1872e-04\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 6.9410e-04 - mse: 0.0014 - val_loss: 2.0436e-04 - val_mse: 4.0872e-04\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 6.8399e-04 - mse: 0.0014 - val_loss: 2.4566e-04 - val_mse: 4.9131e-04\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 6.7877e-04 - mse: 0.0014 - val_loss: 2.4111e-04 - val_mse: 4.8221e-04\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 6.5223e-04 - mse: 0.0013 - val_loss: 1.9432e-04 - val_mse: 3.8864e-04\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 6.2741e-04 - mse: 0.0013 - val_loss: 1.9093e-04 - val_mse: 3.8187e-04\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 6.0870e-04 - mse: 0.0012 - val_loss: 2.1811e-04 - val_mse: 4.3622e-04\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.9025e-04 - mse: 0.0012 - val_loss: 1.9541e-04 - val_mse: 3.9082e-04\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 5.6260e-04 - mse: 0.0011 - val_loss: 2.1505e-04 - val_mse: 4.3009e-04\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.5222e-04 - mse: 0.0011 - val_loss: 3.3075e-04 - val_mse: 6.6150e-04\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 5.2228e-04 - mse: 0.0010 - val_loss: 2.0906e-04 - val_mse: 4.1813e-04\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.8826e-04 - mse: 9.7653e-04 - val_loss: 1.5282e-04 - val_mse: 3.0563e-04\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.5854e-04 - mse: 9.1709e-04 - val_loss: 1.4559e-04 - val_mse: 2.9118e-04\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 4.5804e-04 - mse: 9.1609e-04 - val_loss: 1.5072e-04 - val_mse: 3.0144e-04\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.3811e-04 - mse: 8.7621e-04 - val_loss: 1.7364e-04 - val_mse: 3.4727e-04\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.0729e-04 - mse: 8.1458e-04 - val_loss: 1.3718e-04 - val_mse: 2.7435e-04\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 3.9976e-04 - mse: 7.9952e-04 - val_loss: 1.8268e-04 - val_mse: 3.6536e-04\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 3.8539e-04 - mse: 7.7079e-04 - val_loss: 1.4496e-04 - val_mse: 2.8993e-04\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 3.6327e-04 - mse: 7.2654e-04 - val_loss: 1.2027e-04 - val_mse: 2.4055e-04\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 3.4504e-04 - mse: 6.9007e-04 - val_loss: 1.1661e-04 - val_mse: 2.3323e-04\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 3.2970e-04 - mse: 6.5940e-04 - val_loss: 1.1657e-04 - val_mse: 2.3314e-04\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 3.2838e-04 - mse: 6.5677e-04 - val_loss: 1.2826e-04 - val_mse: 2.5652e-04\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 3.1486e-04 - mse: 6.2971e-04 - val_loss: 1.0730e-04 - val_mse: 2.1461e-04\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 3.0098e-04 - mse: 6.0195e-04 - val_loss: 1.3024e-04 - val_mse: 2.6048e-04\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 3.0848e-04 - mse: 6.1695e-04 - val_loss: 1.9161e-04 - val_mse: 3.8322e-04\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 3.0648e-04 - mse: 6.1296e-04 - val_loss: 1.1340e-04 - val_mse: 2.2680e-04\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 3.2725e-04 - mse: 6.5450e-04 - val_loss: 1.1744e-04 - val_mse: 2.3488e-04\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 2.8863e-04 - mse: 5.7727e-04 - val_loss: 1.7142e-04 - val_mse: 3.4284e-04\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 2.9411e-04 - mse: 5.8823e-04 - val_loss: 1.7746e-04 - val_mse: 3.5493e-04\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 2.8068e-04 - mse: 5.6136e-04 - val_loss: 9.5955e-05 - val_mse: 1.9191e-04\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 2.8223e-04 - mse: 5.6447e-04 - val_loss: 1.8799e-04 - val_mse: 3.7597e-04\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.8166e-04 - mse: 5.6332e-04 - val_loss: 9.9234e-05 - val_mse: 1.9847e-04\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 2.6596e-04 - mse: 5.3192e-04 - val_loss: 9.3026e-05 - val_mse: 1.8605e-04\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.8080e-04 - mse: 5.6159e-04 - val_loss: 1.3700e-04 - val_mse: 2.7399e-04\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 2.7109e-04 - mse: 5.4218e-04 - val_loss: 9.0816e-05 - val_mse: 1.8163e-04\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.6390e-04 - mse: 5.2781e-04 - val_loss: 9.1758e-05 - val_mse: 1.8352e-04\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 3.0498e-04 - mse: 6.0996e-04 - val_loss: 1.1211e-04 - val_mse: 2.2422e-04\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.6427e-04 - mse: 5.2853e-04 - val_loss: 1.0826e-04 - val_mse: 2.1651e-04\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 2.6740e-04 - mse: 5.3479e-04 - val_loss: 1.3622e-04 - val_mse: 2.7245e-04\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 2.7795e-04 - mse: 5.5590e-04 - val_loss: 9.4112e-05 - val_mse: 1.8822e-04\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.5865e-04 - mse: 5.1730e-04 - val_loss: 9.7506e-05 - val_mse: 1.9501e-04\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.6635e-04 - mse: 5.3270e-04 - val_loss: 1.6610e-04 - val_mse: 3.3220e-04\n",
      "pred.shape : (480, 1) , y_test.shape : (500,)\n",
      "2500길이의 데이터 적용 완료\n",
      " 길이: 2500, RMSE:1022.944393040216\n",
      "train set 확인:  (2080, 4) (2080,) test set 확인:  (520, 4) (520,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 8s 51ms/step - loss: 0.0324 - mse: 0.0648 - val_loss: 6.9286e-04 - val_mse: 0.0014\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 2.7093e-04 - val_mse: 5.4186e-04\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 7.0033e-04 - mse: 0.0014 - val_loss: 2.5076e-04 - val_mse: 5.0153e-04\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 6.3541e-04 - mse: 0.0013 - val_loss: 2.5181e-04 - val_mse: 5.0361e-04\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 6.1473e-04 - mse: 0.0012 - val_loss: 2.4106e-04 - val_mse: 4.8212e-04\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 2s 22ms/step - loss: 5.9456e-04 - mse: 0.0012 - val_loss: 2.1903e-04 - val_mse: 4.3806e-04\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 5.7320e-04 - mse: 0.0011 - val_loss: 2.1663e-04 - val_mse: 4.3327e-04\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 5.7182e-04 - mse: 0.0011 - val_loss: 2.1113e-04 - val_mse: 4.2226e-04\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 5.5314e-04 - mse: 0.0011 - val_loss: 2.0492e-04 - val_mse: 4.0984e-04\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 5.0969e-04 - mse: 0.0010 - val_loss: 1.9021e-04 - val_mse: 3.8041e-04\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 5.0191e-04 - mse: 0.0010 - val_loss: 2.1562e-04 - val_mse: 4.3124e-04\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 4.7131e-04 - mse: 9.4263e-04 - val_loss: 1.9754e-04 - val_mse: 3.9507e-04\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 4.4694e-04 - mse: 8.9387e-04 - val_loss: 1.7041e-04 - val_mse: 3.4081e-04\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 4.2211e-04 - mse: 8.4423e-04 - val_loss: 1.8882e-04 - val_mse: 3.7763e-04\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 4.0477e-04 - mse: 8.0953e-04 - val_loss: 1.8811e-04 - val_mse: 3.7621e-04\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 4.0563e-04 - mse: 8.1127e-04 - val_loss: 1.4675e-04 - val_mse: 2.9350e-04\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 3.8149e-04 - mse: 7.6298e-04 - val_loss: 1.3919e-04 - val_mse: 2.7838e-04\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 2s 22ms/step - loss: 3.4798e-04 - mse: 6.9596e-04 - val_loss: 1.9145e-04 - val_mse: 3.8290e-04\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 3.4085e-04 - mse: 6.8171e-04 - val_loss: 1.5579e-04 - val_mse: 3.1159e-04\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 3.3219e-04 - mse: 6.6438e-04 - val_loss: 2.2716e-04 - val_mse: 4.5431e-04\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 3.1651e-04 - mse: 6.3303e-04 - val_loss: 1.5643e-04 - val_mse: 3.1287e-04\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 3.1021e-04 - mse: 6.2042e-04 - val_loss: 1.2116e-04 - val_mse: 2.4233e-04\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 2.9925e-04 - mse: 5.9849e-04 - val_loss: 1.1931e-04 - val_mse: 2.3861e-04\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 3.0541e-04 - mse: 6.1082e-04 - val_loss: 1.1840e-04 - val_mse: 2.3680e-04\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 2.9613e-04 - mse: 5.9225e-04 - val_loss: 1.3823e-04 - val_mse: 2.7646e-04\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 2.9504e-04 - mse: 5.9007e-04 - val_loss: 1.6980e-04 - val_mse: 3.3961e-04\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 2.7960e-04 - mse: 5.5919e-04 - val_loss: 1.3630e-04 - val_mse: 2.7260e-04\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 2.8164e-04 - mse: 5.6329e-04 - val_loss: 1.5467e-04 - val_mse: 3.0935e-04\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 3.1698e-04 - mse: 6.3395e-04 - val_loss: 1.1343e-04 - val_mse: 2.2686e-04\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 2.8900e-04 - mse: 5.7800e-04 - val_loss: 1.2708e-04 - val_mse: 2.5415e-04\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 2.8160e-04 - mse: 5.6321e-04 - val_loss: 1.3274e-04 - val_mse: 2.6549e-04\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 2.8513e-04 - mse: 5.7026e-04 - val_loss: 1.2087e-04 - val_mse: 2.4173e-04\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 2.8932e-04 - mse: 5.7863e-04 - val_loss: 1.0898e-04 - val_mse: 2.1795e-04\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 2.7212e-04 - mse: 5.4425e-04 - val_loss: 1.1347e-04 - val_mse: 2.2693e-04\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 2.8598e-04 - mse: 5.7195e-04 - val_loss: 1.6306e-04 - val_mse: 3.2612e-04\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 2.7924e-04 - mse: 5.5847e-04 - val_loss: 1.9472e-04 - val_mse: 3.8943e-04\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 2.9064e-04 - mse: 5.8127e-04 - val_loss: 1.0897e-04 - val_mse: 2.1794e-04\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 2.6692e-04 - mse: 5.3383e-04 - val_loss: 1.2648e-04 - val_mse: 2.5296e-04\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 2.6178e-04 - mse: 5.2355e-04 - val_loss: 1.0567e-04 - val_mse: 2.1134e-04\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 2s 22ms/step - loss: 2.9148e-04 - mse: 5.8295e-04 - val_loss: 1.0646e-04 - val_mse: 2.1292e-04\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 1s 21ms/step - loss: 2.9421e-04 - mse: 5.8843e-04 - val_loss: 1.0294e-04 - val_mse: 2.0589e-04\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 2.6544e-04 - mse: 5.3088e-04 - val_loss: 1.2721e-04 - val_mse: 2.5441e-04\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 2.5775e-04 - mse: 5.1551e-04 - val_loss: 1.8070e-04 - val_mse: 3.6141e-04\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 2.7830e-04 - mse: 5.5659e-04 - val_loss: 1.0166e-04 - val_mse: 2.0332e-04\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 2.5908e-04 - mse: 5.1816e-04 - val_loss: 1.0376e-04 - val_mse: 2.0752e-04\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 2.5752e-04 - mse: 5.1504e-04 - val_loss: 1.0112e-04 - val_mse: 2.0223e-04\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 2s 23ms/step - loss: 2.5982e-04 - mse: 5.1963e-04 - val_loss: 9.9825e-05 - val_mse: 1.9965e-04\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 2s 24ms/step - loss: 2.6182e-04 - mse: 5.2364e-04 - val_loss: 2.1580e-04 - val_mse: 4.3161e-04\n",
      "Epoch 49/50\n",
      "65/65 [==============================] - 2s 20ms/step - loss: 2.5809e-04 - mse: 5.1618e-04 - val_loss: 1.1731e-04 - val_mse: 2.3461e-04\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 2s 20ms/step - loss: 2.5827e-04 - mse: 5.1655e-04 - val_loss: 1.0143e-04 - val_mse: 2.0285e-04\n",
      "pred.shape : (500, 1) , y_test.shape : (520,)\n",
      "2600길이의 데이터 적용 완료\n",
      " 길이: 2600, RMSE:830.7767734294065\n",
      "train set 확인:  (2160, 4) (2160,) test set 확인:  (540, 4) (540,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 8s 37ms/step - loss: 0.0296 - mse: 0.0593 - val_loss: 3.8804e-04 - val_mse: 7.7607e-04\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 3.0415e-04 - val_mse: 6.0830e-04\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 5.6632e-04 - mse: 0.0011 - val_loss: 2.4220e-04 - val_mse: 4.8441e-04\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 5.1778e-04 - mse: 0.0010 - val_loss: 2.3764e-04 - val_mse: 4.7528e-04\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 5.0184e-04 - mse: 0.0010 - val_loss: 2.3935e-04 - val_mse: 4.7871e-04\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 5.0200e-04 - mse: 0.0010 - val_loss: 2.5825e-04 - val_mse: 5.1650e-04\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 4.8191e-04 - mse: 9.6383e-04 - val_loss: 2.5015e-04 - val_mse: 5.0030e-04\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 4.7290e-04 - mse: 9.4581e-04 - val_loss: 2.2436e-04 - val_mse: 4.4873e-04\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 4.5827e-04 - mse: 9.1655e-04 - val_loss: 2.3362e-04 - val_mse: 4.6723e-04\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 4.5035e-04 - mse: 9.0070e-04 - val_loss: 2.1461e-04 - val_mse: 4.2921e-04\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 4.3633e-04 - mse: 8.7267e-04 - val_loss: 2.1877e-04 - val_mse: 4.3754e-04\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 2s 21ms/step - loss: 4.2898e-04 - mse: 8.5797e-04 - val_loss: 2.0567e-04 - val_mse: 4.1134e-04\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 4.3408e-04 - mse: 8.6816e-04 - val_loss: 2.1372e-04 - val_mse: 4.2743e-04\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 2s 20ms/step - loss: 4.0613e-04 - mse: 8.1226e-04 - val_loss: 1.9896e-04 - val_mse: 3.9792e-04\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 4.1108e-04 - mse: 8.2215e-04 - val_loss: 1.9119e-04 - val_mse: 3.8239e-04\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.9077e-04 - mse: 7.8154e-04 - val_loss: 2.0739e-04 - val_mse: 4.1477e-04\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.7847e-04 - mse: 7.5694e-04 - val_loss: 1.8940e-04 - val_mse: 3.7880e-04\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.7253e-04 - mse: 7.4507e-04 - val_loss: 1.7936e-04 - val_mse: 3.5872e-04\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.5779e-04 - mse: 7.1558e-04 - val_loss: 1.7280e-04 - val_mse: 3.4560e-04\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.4679e-04 - mse: 6.9358e-04 - val_loss: 1.7061e-04 - val_mse: 3.4122e-04\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.3673e-04 - mse: 6.7346e-04 - val_loss: 1.6728e-04 - val_mse: 3.3457e-04\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 2s 20ms/step - loss: 3.3712e-04 - mse: 6.7423e-04 - val_loss: 1.6314e-04 - val_mse: 3.2628e-04\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 2s 21ms/step - loss: 3.2628e-04 - mse: 6.5257e-04 - val_loss: 1.6441e-04 - val_mse: 3.2882e-04\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 3.2689e-04 - mse: 6.5378e-04 - val_loss: 2.0117e-04 - val_mse: 4.0233e-04\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 3.1925e-04 - mse: 6.3850e-04 - val_loss: 1.6055e-04 - val_mse: 3.2110e-04\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.0440e-04 - mse: 6.0881e-04 - val_loss: 2.2340e-04 - val_mse: 4.4680e-04\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 2s 21ms/step - loss: 3.1059e-04 - mse: 6.2118e-04 - val_loss: 1.5795e-04 - val_mse: 3.1590e-04\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 3.1642e-04 - mse: 6.3283e-04 - val_loss: 1.5766e-04 - val_mse: 3.1532e-04\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 2s 20ms/step - loss: 3.0766e-04 - mse: 6.1533e-04 - val_loss: 1.6587e-04 - val_mse: 3.3174e-04\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 2s 20ms/step - loss: 3.1566e-04 - mse: 6.3133e-04 - val_loss: 1.4573e-04 - val_mse: 2.9146e-04\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 2.9137e-04 - mse: 5.8274e-04 - val_loss: 1.3939e-04 - val_mse: 2.7878e-04\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 2.8050e-04 - mse: 5.6100e-04 - val_loss: 1.5183e-04 - val_mse: 3.0367e-04\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 2.7200e-04 - mse: 5.4400e-04 - val_loss: 1.4255e-04 - val_mse: 2.8511e-04\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 2.8014e-04 - mse: 5.6027e-04 - val_loss: 2.1920e-04 - val_mse: 4.3840e-04\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 2.7544e-04 - mse: 5.5089e-04 - val_loss: 1.3053e-04 - val_mse: 2.6105e-04\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 2.7690e-04 - mse: 5.5380e-04 - val_loss: 2.0323e-04 - val_mse: 4.0647e-04\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 2.7122e-04 - mse: 5.4244e-04 - val_loss: 1.2929e-04 - val_mse: 2.5858e-04\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 2s 21ms/step - loss: 2.7340e-04 - mse: 5.4681e-04 - val_loss: 1.3083e-04 - val_mse: 2.6166e-04\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 2s 21ms/step - loss: 2.8418e-04 - mse: 5.6836e-04 - val_loss: 1.4347e-04 - val_mse: 2.8695e-04\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 2.5219e-04 - mse: 5.0438e-04 - val_loss: 1.6595e-04 - val_mse: 3.3189e-04\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 2.8165e-04 - mse: 5.6331e-04 - val_loss: 1.7231e-04 - val_mse: 3.4462e-04\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 2.6201e-04 - mse: 5.2403e-04 - val_loss: 1.5778e-04 - val_mse: 3.1557e-04\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 2.4933e-04 - mse: 4.9866e-04 - val_loss: 1.3316e-04 - val_mse: 2.6631e-04\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 2.4853e-04 - mse: 4.9705e-04 - val_loss: 1.2295e-04 - val_mse: 2.4589e-04\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 2.3981e-04 - mse: 4.7962e-04 - val_loss: 1.1739e-04 - val_mse: 2.3477e-04\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 2.3981e-04 - mse: 4.7962e-04 - val_loss: 1.5784e-04 - val_mse: 3.1568e-04\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 2.8074e-04 - mse: 5.6148e-04 - val_loss: 1.5299e-04 - val_mse: 3.0598e-04\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 2.4149e-04 - mse: 4.8298e-04 - val_loss: 2.0392e-04 - val_mse: 4.0785e-04\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 2s 22ms/step - loss: 2.4309e-04 - mse: 4.8618e-04 - val_loss: 1.1452e-04 - val_mse: 2.2903e-04\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 2.4147e-04 - mse: 4.8293e-04 - val_loss: 1.4022e-04 - val_mse: 2.8043e-04\n",
      "pred.shape : (520, 1) , y_test.shape : (540,)\n",
      "2700길이의 데이터 적용 완료\n",
      " 길이: 2700, RMSE:1066.824267637055\n",
      "train set 확인:  (2240, 4) (2240,) test set 확인:  (560, 4) (560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 9s 40ms/step - loss: 0.0413 - mse: 0.0825 - val_loss: 4.0634e-04 - val_mse: 8.1267e-04\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 3.5000e-04 - val_mse: 6.9999e-04\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 2s 19ms/step - loss: 6.6440e-04 - mse: 0.0013 - val_loss: 2.6402e-04 - val_mse: 5.2804e-04\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 5.0042e-04 - mse: 0.0010 - val_loss: 2.8495e-04 - val_mse: 5.6991e-04\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 2s 22ms/step - loss: 4.9737e-04 - mse: 9.9473e-04 - val_loss: 2.6300e-04 - val_mse: 5.2600e-04\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 4.8791e-04 - mse: 9.7581e-04 - val_loss: 2.9801e-04 - val_mse: 5.9602e-04\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 2s 22ms/step - loss: 4.8548e-04 - mse: 9.7096e-04 - val_loss: 2.4577e-04 - val_mse: 4.9154e-04\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 4.6978e-04 - mse: 9.3956e-04 - val_loss: 2.4696e-04 - val_mse: 4.9391e-04\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 4.6779e-04 - mse: 9.3559e-04 - val_loss: 2.5698e-04 - val_mse: 5.1396e-04\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 4.5974e-04 - mse: 9.1949e-04 - val_loss: 2.3756e-04 - val_mse: 4.7512e-04\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 4.4825e-04 - mse: 8.9651e-04 - val_loss: 2.3435e-04 - val_mse: 4.6871e-04\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 2s 19ms/step - loss: 4.5207e-04 - mse: 9.0414e-04 - val_loss: 2.2953e-04 - val_mse: 4.5907e-04\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 4.3624e-04 - mse: 8.7247e-04 - val_loss: 2.2534e-04 - val_mse: 4.5069e-04\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 4.3306e-04 - mse: 8.6612e-04 - val_loss: 2.2213e-04 - val_mse: 4.4426e-04\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 4.2666e-04 - mse: 8.5333e-04 - val_loss: 2.3222e-04 - val_mse: 4.6444e-04\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4.3772e-04 - mse: 8.7545e-04 - val_loss: 2.6722e-04 - val_mse: 5.3443e-04\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4.0884e-04 - mse: 8.1767e-04 - val_loss: 2.1042e-04 - val_mse: 4.2083e-04\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 3.9368e-04 - mse: 7.8736e-04 - val_loss: 2.5296e-04 - val_mse: 5.0591e-04\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 3.9715e-04 - mse: 7.9430e-04 - val_loss: 2.7085e-04 - val_mse: 5.4170e-04\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 2s 26ms/step - loss: 3.8968e-04 - mse: 7.7935e-04 - val_loss: 2.0595e-04 - val_mse: 4.1189e-04\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 2s 19ms/step - loss: 3.7949e-04 - mse: 7.5898e-04 - val_loss: 2.2693e-04 - val_mse: 4.5387e-04\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 2s 21ms/step - loss: 3.7191e-04 - mse: 7.4383e-04 - val_loss: 1.9089e-04 - val_mse: 3.8178e-04\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 2s 19ms/step - loss: 3.5944e-04 - mse: 7.1887e-04 - val_loss: 1.9954e-04 - val_mse: 3.9909e-04\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 3.5073e-04 - mse: 7.0146e-04 - val_loss: 1.9386e-04 - val_mse: 3.8772e-04\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 3.5597e-04 - mse: 7.1194e-04 - val_loss: 1.9514e-04 - val_mse: 3.9027e-04\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 3.5083e-04 - mse: 7.0166e-04 - val_loss: 1.7642e-04 - val_mse: 3.5284e-04\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 3.5208e-04 - mse: 7.0416e-04 - val_loss: 2.4076e-04 - val_mse: 4.8152e-04\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 3.3221e-04 - mse: 6.6443e-04 - val_loss: 1.6886e-04 - val_mse: 3.3773e-04\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 2s 21ms/step - loss: 3.2611e-04 - mse: 6.5222e-04 - val_loss: 2.0076e-04 - val_mse: 4.0153e-04\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 3.0851e-04 - mse: 6.1703e-04 - val_loss: 1.6039e-04 - val_mse: 3.2079e-04\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 2.9205e-04 - mse: 5.8411e-04 - val_loss: 1.5646e-04 - val_mse: 3.1292e-04\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 2.8531e-04 - mse: 5.7062e-04 - val_loss: 1.8481e-04 - val_mse: 3.6962e-04\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 2.7105e-04 - mse: 5.4210e-04 - val_loss: 1.5008e-04 - val_mse: 3.0015e-04\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 2.5835e-04 - mse: 5.1671e-04 - val_loss: 1.4289e-04 - val_mse: 2.8579e-04\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 2.6261e-04 - mse: 5.2523e-04 - val_loss: 1.9658e-04 - val_mse: 3.9317e-04\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 2.5144e-04 - mse: 5.0287e-04 - val_loss: 1.5549e-04 - val_mse: 3.1098e-04\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 2.4439e-04 - mse: 4.8877e-04 - val_loss: 1.4513e-04 - val_mse: 2.9026e-04\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 2.5969e-04 - mse: 5.1938e-04 - val_loss: 1.9816e-04 - val_mse: 3.9632e-04\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 2.5305e-04 - mse: 5.0611e-04 - val_loss: 1.1649e-04 - val_mse: 2.3298e-04\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2.3080e-04 - mse: 4.6159e-04 - val_loss: 1.3086e-04 - val_mse: 2.6173e-04\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 2.1969e-04 - mse: 4.3937e-04 - val_loss: 1.1396e-04 - val_mse: 2.2792e-04\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 2s 22ms/step - loss: 2.1853e-04 - mse: 4.3707e-04 - val_loss: 1.3179e-04 - val_mse: 2.6357e-04\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2.0441e-04 - mse: 4.0882e-04 - val_loss: 1.4610e-04 - val_mse: 2.9219e-04\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 2s 19ms/step - loss: 2.0633e-04 - mse: 4.1266e-04 - val_loss: 1.0902e-04 - val_mse: 2.1805e-04\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 2.0305e-04 - mse: 4.0610e-04 - val_loss: 1.3269e-04 - val_mse: 2.6537e-04\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2.0062e-04 - mse: 4.0125e-04 - val_loss: 1.0744e-04 - val_mse: 2.1487e-04\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.9471e-04 - mse: 3.8942e-04 - val_loss: 9.6107e-05 - val_mse: 1.9221e-04\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 1.8302e-04 - mse: 3.6605e-04 - val_loss: 1.0195e-04 - val_mse: 2.0390e-04\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 1.8278e-04 - mse: 3.6556e-04 - val_loss: 1.3471e-04 - val_mse: 2.6941e-04\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 1.8265e-04 - mse: 3.6530e-04 - val_loss: 1.1097e-04 - val_mse: 2.2193e-04\n",
      "pred.shape : (540, 1) , y_test.shape : (560,)\n",
      "2800길이의 데이터 적용 완료\n",
      " 길이: 2800, RMSE:1054.9744041495994\n",
      "train set 확인:  (2320, 4) (2320,) test set 확인:  (580, 4) (580,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 34ms/step - loss: 0.0039 - mse: 0.0078 - val_loss: 4.1208e-04 - val_mse: 8.2416e-04\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 4.1689e-04 - mse: 8.3379e-04 - val_loss: 3.2258e-04 - val_mse: 6.4517e-04\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.6099e-04 - mse: 7.2199e-04 - val_loss: 3.2064e-04 - val_mse: 6.4128e-04\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 3.5527e-04 - mse: 7.1054e-04 - val_loss: 3.0294e-04 - val_mse: 6.0589e-04\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.3957e-04 - mse: 6.7915e-04 - val_loss: 2.9496e-04 - val_mse: 5.8992e-04\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.2861e-04 - mse: 6.5722e-04 - val_loss: 3.1102e-04 - val_mse: 6.2205e-04\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 3.2241e-04 - mse: 6.4482e-04 - val_loss: 2.9024e-04 - val_mse: 5.8049e-04\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 3.0191e-04 - mse: 6.0382e-04 - val_loss: 2.8128e-04 - val_mse: 5.6256e-04\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 2.9323e-04 - mse: 5.8645e-04 - val_loss: 2.8879e-04 - val_mse: 5.7757e-04\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 2.9534e-04 - mse: 5.9068e-04 - val_loss: 2.5913e-04 - val_mse: 5.1826e-04\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.8278e-04 - mse: 5.6557e-04 - val_loss: 2.5879e-04 - val_mse: 5.1758e-04\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.6850e-04 - mse: 5.3700e-04 - val_loss: 2.2855e-04 - val_mse: 4.5710e-04\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 2.7834e-04 - mse: 5.5668e-04 - val_loss: 2.3089e-04 - val_mse: 4.6179e-04\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 2.7097e-04 - mse: 5.4193e-04 - val_loss: 2.4897e-04 - val_mse: 4.9794e-04\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 2.6341e-04 - mse: 5.2681e-04 - val_loss: 2.1514e-04 - val_mse: 4.3028e-04\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.5705e-04 - mse: 5.1410e-04 - val_loss: 2.8382e-04 - val_mse: 5.6764e-04\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.4041e-04 - mse: 4.8082e-04 - val_loss: 2.2911e-04 - val_mse: 4.5822e-04\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 2.5028e-04 - mse: 5.0056e-04 - val_loss: 2.0148e-04 - val_mse: 4.0297e-04\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3220e-04 - mse: 4.6441e-04 - val_loss: 2.2148e-04 - val_mse: 4.4295e-04\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 2s 18ms/step - loss: 2.3535e-04 - mse: 4.7069e-04 - val_loss: 2.1002e-04 - val_mse: 4.2003e-04\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.2776e-04 - mse: 4.5551e-04 - val_loss: 2.0063e-04 - val_mse: 4.0126e-04\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 2.3462e-04 - mse: 4.6924e-04 - val_loss: 1.8568e-04 - val_mse: 3.7136e-04\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1656e-04 - mse: 4.3312e-04 - val_loss: 2.2762e-04 - val_mse: 4.5523e-04\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1348e-04 - mse: 4.2696e-04 - val_loss: 1.7687e-04 - val_mse: 3.5373e-04\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.1728e-04 - mse: 4.3456e-04 - val_loss: 2.2411e-04 - val_mse: 4.4822e-04\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.2534e-04 - mse: 4.5068e-04 - val_loss: 2.5815e-04 - val_mse: 5.1631e-04\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1094e-04 - mse: 4.2187e-04 - val_loss: 1.7322e-04 - val_mse: 3.4644e-04\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 2.0667e-04 - mse: 4.1335e-04 - val_loss: 1.6711e-04 - val_mse: 3.3422e-04\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.0228e-04 - mse: 4.0455e-04 - val_loss: 1.6343e-04 - val_mse: 3.2685e-04\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.9012e-04 - mse: 3.8024e-04 - val_loss: 1.7942e-04 - val_mse: 3.5885e-04\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 2.0137e-04 - mse: 4.0274e-04 - val_loss: 1.5900e-04 - val_mse: 3.1800e-04\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.9313e-04 - mse: 3.8627e-04 - val_loss: 1.8287e-04 - val_mse: 3.6574e-04\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 2.0256e-04 - mse: 4.0512e-04 - val_loss: 1.5324e-04 - val_mse: 3.0648e-04\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.8736e-04 - mse: 3.7473e-04 - val_loss: 1.6030e-04 - val_mse: 3.2060e-04\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.7834e-04 - mse: 3.5669e-04 - val_loss: 1.5008e-04 - val_mse: 3.0017e-04\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.8995e-04 - mse: 3.7990e-04 - val_loss: 1.4926e-04 - val_mse: 2.9851e-04\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.8399e-04 - mse: 3.6799e-04 - val_loss: 1.5215e-04 - val_mse: 3.0430e-04\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.7649e-04 - mse: 3.5298e-04 - val_loss: 1.4716e-04 - val_mse: 2.9431e-04\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 2.0987e-04 - mse: 4.1973e-04 - val_loss: 1.7438e-04 - val_mse: 3.4876e-04\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.7720e-04 - mse: 3.5440e-04 - val_loss: 1.4623e-04 - val_mse: 2.9246e-04\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.7056e-04 - mse: 3.4111e-04 - val_loss: 1.4870e-04 - val_mse: 2.9741e-04\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.6963e-04 - mse: 3.3926e-04 - val_loss: 1.3806e-04 - val_mse: 2.7611e-04\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.6843e-04 - mse: 3.3686e-04 - val_loss: 1.5071e-04 - val_mse: 3.0143e-04\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.8094e-04 - mse: 3.6188e-04 - val_loss: 2.5256e-04 - val_mse: 5.0512e-04\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.7532e-04 - mse: 3.5064e-04 - val_loss: 1.3526e-04 - val_mse: 2.7052e-04\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.6688e-04 - mse: 3.3376e-04 - val_loss: 1.3153e-04 - val_mse: 2.6306e-04\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.6192e-04 - mse: 3.2383e-04 - val_loss: 1.3308e-04 - val_mse: 2.6617e-04\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 2s 20ms/step - loss: 1.6542e-04 - mse: 3.3084e-04 - val_loss: 1.7286e-04 - val_mse: 3.4573e-04\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.6462e-04 - mse: 3.2924e-04 - val_loss: 1.4296e-04 - val_mse: 2.8592e-04\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 2s 19ms/step - loss: 1.6132e-04 - mse: 3.2263e-04 - val_loss: 1.3233e-04 - val_mse: 2.6467e-04\n",
      "pred.shape : (560, 1) , y_test.shape : (580,)\n",
      "2900길이의 데이터 적용 완료\n",
      " 길이: 2900, RMSE:1152.0796199526499\n",
      "train set 확인:  (2400, 4) (2400,) test set 확인:  (600, 4) (600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 9s 36ms/step - loss: 0.0347 - mse: 0.0694 - val_loss: 6.5497e-04 - val_mse: 0.0013\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 4.9685e-04 - val_mse: 9.9370e-04\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 4.8384e-04 - mse: 9.6767e-04 - val_loss: 4.7200e-04 - val_mse: 9.4399e-04\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 4.3280e-04 - mse: 8.6561e-04 - val_loss: 4.4206e-04 - val_mse: 8.8413e-04\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 4.2427e-04 - mse: 8.4855e-04 - val_loss: 4.5775e-04 - val_mse: 9.1550e-04\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 4.1224e-04 - mse: 8.2449e-04 - val_loss: 4.2243e-04 - val_mse: 8.4485e-04\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 4.1251e-04 - mse: 8.2502e-04 - val_loss: 4.3718e-04 - val_mse: 8.7436e-04\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 4.0199e-04 - mse: 8.0398e-04 - val_loss: 4.0791e-04 - val_mse: 8.1582e-04\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.9395e-04 - mse: 7.8790e-04 - val_loss: 4.1565e-04 - val_mse: 8.3131e-04\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.8186e-04 - mse: 7.6372e-04 - val_loss: 4.3556e-04 - val_mse: 8.7113e-04\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 3.7730e-04 - mse: 7.5460e-04 - val_loss: 3.9556e-04 - val_mse: 7.9112e-04\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.7469e-04 - mse: 7.4938e-04 - val_loss: 3.8229e-04 - val_mse: 7.6457e-04\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 3.5452e-04 - mse: 7.0905e-04 - val_loss: 3.4934e-04 - val_mse: 6.9868e-04\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 3.3526e-04 - mse: 6.7052e-04 - val_loss: 3.6098e-04 - val_mse: 7.2196e-04\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 3.2676e-04 - mse: 6.5353e-04 - val_loss: 3.1762e-04 - val_mse: 6.3523e-04\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 3.1725e-04 - mse: 6.3450e-04 - val_loss: 3.0246e-04 - val_mse: 6.0492e-04\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.9816e-04 - mse: 5.9632e-04 - val_loss: 3.3682e-04 - val_mse: 6.7363e-04\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.1042e-04 - mse: 6.2084e-04 - val_loss: 2.9512e-04 - val_mse: 5.9024e-04\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.8593e-04 - mse: 5.7187e-04 - val_loss: 2.6641e-04 - val_mse: 5.3283e-04\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.7681e-04 - mse: 5.5362e-04 - val_loss: 2.8332e-04 - val_mse: 5.6663e-04\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6157e-04 - mse: 5.2315e-04 - val_loss: 3.1473e-04 - val_mse: 6.2946e-04\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.6058e-04 - mse: 5.2115e-04 - val_loss: 3.7661e-04 - val_mse: 7.5321e-04\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6466e-04 - mse: 5.2931e-04 - val_loss: 2.3366e-04 - val_mse: 4.6732e-04\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.4142e-04 - mse: 4.8284e-04 - val_loss: 2.4384e-04 - val_mse: 4.8767e-04\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.3805e-04 - mse: 4.7610e-04 - val_loss: 2.7246e-04 - val_mse: 5.4492e-04\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.2651e-04 - mse: 4.5302e-04 - val_loss: 2.0173e-04 - val_mse: 4.0346e-04\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.1338e-04 - mse: 4.2676e-04 - val_loss: 1.9393e-04 - val_mse: 3.8786e-04\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.1219e-04 - mse: 4.2438e-04 - val_loss: 1.9854e-04 - val_mse: 3.9707e-04\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 2.1450e-04 - mse: 4.2899e-04 - val_loss: 2.1353e-04 - val_mse: 4.2706e-04\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.1784e-04 - mse: 4.3568e-04 - val_loss: 1.8459e-04 - val_mse: 3.6917e-04\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 1.9540e-04 - mse: 3.9079e-04 - val_loss: 1.9137e-04 - val_mse: 3.8275e-04\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 1.8761e-04 - mse: 3.7522e-04 - val_loss: 1.7571e-04 - val_mse: 3.5143e-04\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 1.9162e-04 - mse: 3.8324e-04 - val_loss: 2.0555e-04 - val_mse: 4.1110e-04\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.9176e-04 - mse: 3.8352e-04 - val_loss: 1.6005e-04 - val_mse: 3.2010e-04\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.8721e-04 - mse: 3.7442e-04 - val_loss: 1.5969e-04 - val_mse: 3.1938e-04\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.8293e-04 - mse: 3.6586e-04 - val_loss: 2.5234e-04 - val_mse: 5.0469e-04\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.9174e-04 - mse: 3.8348e-04 - val_loss: 2.1288e-04 - val_mse: 4.2575e-04\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.7688e-04 - mse: 3.5376e-04 - val_loss: 1.7764e-04 - val_mse: 3.5529e-04\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.7523e-04 - mse: 3.5047e-04 - val_loss: 1.4673e-04 - val_mse: 2.9347e-04\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.6747e-04 - mse: 3.3494e-04 - val_loss: 2.4505e-04 - val_mse: 4.9010e-04\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.9315e-04 - mse: 3.8630e-04 - val_loss: 1.9029e-04 - val_mse: 3.8057e-04\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.7840e-04 - mse: 3.5681e-04 - val_loss: 1.5177e-04 - val_mse: 3.0354e-04\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.7581e-04 - mse: 3.5162e-04 - val_loss: 1.8088e-04 - val_mse: 3.6176e-04\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.6421e-04 - mse: 3.2842e-04 - val_loss: 1.4730e-04 - val_mse: 2.9461e-04\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 1.6728e-04 - mse: 3.3456e-04 - val_loss: 1.4493e-04 - val_mse: 2.8986e-04\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.6780e-04 - mse: 3.3561e-04 - val_loss: 1.6273e-04 - val_mse: 3.2546e-04\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.7125e-04 - mse: 3.4249e-04 - val_loss: 1.8203e-04 - val_mse: 3.6406e-04\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.6250e-04 - mse: 3.2501e-04 - val_loss: 1.4151e-04 - val_mse: 2.8303e-04\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.6065e-04 - mse: 3.2130e-04 - val_loss: 1.4514e-04 - val_mse: 2.9029e-04\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 1.6218e-04 - mse: 3.2436e-04 - val_loss: 1.3242e-04 - val_mse: 2.6483e-04\n",
      "pred.shape : (580, 1) , y_test.shape : (600,)\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:1157.02745821256\n",
      "train set 확인:  (2480, 4) (2480,) test set 확인:  (620, 4) (620,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 10s 35ms/step - loss: 0.0361 - mse: 0.0721 - val_loss: 5.4653e-04 - val_mse: 0.0011\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.0029 - mse: 0.0059 - val_loss: 3.6046e-04 - val_mse: 7.2093e-04\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 3.6527e-04 - mse: 7.3054e-04 - val_loss: 3.5461e-04 - val_mse: 7.0922e-04\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 3.2263e-04 - mse: 6.4525e-04 - val_loss: 3.7520e-04 - val_mse: 7.5040e-04\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 3.1352e-04 - mse: 6.2704e-04 - val_loss: 3.2339e-04 - val_mse: 6.4678e-04\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 3.0763e-04 - mse: 6.1526e-04 - val_loss: 3.1740e-04 - val_mse: 6.3481e-04\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 2s 17ms/step - loss: 2.9582e-04 - mse: 5.9165e-04 - val_loss: 3.5361e-04 - val_mse: 7.0722e-04\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 2.8066e-04 - mse: 5.6133e-04 - val_loss: 2.7681e-04 - val_mse: 5.5362e-04\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 2.7623e-04 - mse: 5.5245e-04 - val_loss: 3.0411e-04 - val_mse: 6.0822e-04\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 2.7418e-04 - mse: 5.4836e-04 - val_loss: 2.6001e-04 - val_mse: 5.2001e-04\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 2.6253e-04 - mse: 5.2507e-04 - val_loss: 2.9267e-04 - val_mse: 5.8534e-04\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 2.4993e-04 - mse: 4.9986e-04 - val_loss: 2.5888e-04 - val_mse: 5.1776e-04\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 2.4163e-04 - mse: 4.8326e-04 - val_loss: 2.2866e-04 - val_mse: 4.5731e-04\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 2.5534e-04 - mse: 5.1068e-04 - val_loss: 2.2098e-04 - val_mse: 4.4197e-04\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 2.4292e-04 - mse: 4.8584e-04 - val_loss: 2.2700e-04 - val_mse: 4.5399e-04\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 2.2622e-04 - mse: 4.5245e-04 - val_loss: 2.1675e-04 - val_mse: 4.3350e-04\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 2.1704e-04 - mse: 4.3409e-04 - val_loss: 2.0249e-04 - val_mse: 4.0497e-04\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 2.2267e-04 - mse: 4.4533e-04 - val_loss: 2.0215e-04 - val_mse: 4.0431e-04\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 2.0884e-04 - mse: 4.1768e-04 - val_loss: 1.9583e-04 - val_mse: 3.9167e-04\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 2.1522e-04 - mse: 4.3043e-04 - val_loss: 2.2813e-04 - val_mse: 4.5626e-04\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 2.0272e-04 - mse: 4.0544e-04 - val_loss: 2.4768e-04 - val_mse: 4.9536e-04\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 2.1066e-04 - mse: 4.2133e-04 - val_loss: 2.5550e-04 - val_mse: 5.1101e-04\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 2.0101e-04 - mse: 4.0201e-04 - val_loss: 2.0193e-04 - val_mse: 4.0385e-04\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.9824e-04 - mse: 3.9649e-04 - val_loss: 1.7184e-04 - val_mse: 3.4367e-04\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.8872e-04 - mse: 3.7744e-04 - val_loss: 1.9426e-04 - val_mse: 3.8851e-04\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.8334e-04 - mse: 3.6667e-04 - val_loss: 1.7877e-04 - val_mse: 3.5755e-04\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.7931e-04 - mse: 3.5862e-04 - val_loss: 2.1645e-04 - val_mse: 4.3289e-04\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.8439e-04 - mse: 3.6877e-04 - val_loss: 1.8046e-04 - val_mse: 3.6093e-04\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.8518e-04 - mse: 3.7035e-04 - val_loss: 1.5691e-04 - val_mse: 3.1383e-04\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 1.8415e-04 - mse: 3.6831e-04 - val_loss: 2.4264e-04 - val_mse: 4.8528e-04\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 1.8615e-04 - mse: 3.7230e-04 - val_loss: 1.8111e-04 - val_mse: 3.6222e-04\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 1.6987e-04 - mse: 3.3973e-04 - val_loss: 1.5708e-04 - val_mse: 3.1417e-04\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 1.7167e-04 - mse: 3.4334e-04 - val_loss: 1.6677e-04 - val_mse: 3.3354e-04\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.8078e-04 - mse: 3.6156e-04 - val_loss: 1.4849e-04 - val_mse: 2.9699e-04\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.8434e-04 - mse: 3.6868e-04 - val_loss: 1.5825e-04 - val_mse: 3.1649e-04\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.7311e-04 - mse: 3.4621e-04 - val_loss: 1.8857e-04 - val_mse: 3.7714e-04\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.7049e-04 - mse: 3.4098e-04 - val_loss: 1.4768e-04 - val_mse: 2.9536e-04\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.6770e-04 - mse: 3.3540e-04 - val_loss: 1.4397e-04 - val_mse: 2.8795e-04\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.7917e-04 - mse: 3.5835e-04 - val_loss: 1.9128e-04 - val_mse: 3.8257e-04\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.7283e-04 - mse: 3.4565e-04 - val_loss: 1.5637e-04 - val_mse: 3.1274e-04\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 1.7220e-04 - mse: 3.4439e-04 - val_loss: 1.4160e-04 - val_mse: 2.8320e-04\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.6877e-04 - mse: 3.3754e-04 - val_loss: 1.5145e-04 - val_mse: 3.0289e-04\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.7545e-04 - mse: 3.5090e-04 - val_loss: 2.0559e-04 - val_mse: 4.1118e-04\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 1.6791e-04 - mse: 3.3582e-04 - val_loss: 1.4030e-04 - val_mse: 2.8061e-04\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 2s 18ms/step - loss: 1.6873e-04 - mse: 3.3746e-04 - val_loss: 1.4401e-04 - val_mse: 2.8802e-04\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 1.6751e-04 - mse: 3.3502e-04 - val_loss: 2.2286e-04 - val_mse: 4.4572e-04\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 1.6499e-04 - mse: 3.2999e-04 - val_loss: 1.4449e-04 - val_mse: 2.8898e-04\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 1.6372e-04 - mse: 3.2745e-04 - val_loss: 1.3689e-04 - val_mse: 2.7377e-04\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 1.6356e-04 - mse: 3.2712e-04 - val_loss: 1.9119e-04 - val_mse: 3.8239e-04\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 1.6074e-04 - mse: 3.2148e-04 - val_loss: 1.3663e-04 - val_mse: 2.7327e-04\n",
      "pred.shape : (600, 1) , y_test.shape : (620,)\n",
      "3100길이의 데이터 적용 완료\n",
      " 길이: 3100, RMSE:1175.3136008579515\n",
      "train set 확인:  (2560, 4) (2560,) test set 확인:  (640, 4) (640,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 [==============================] - 10s 52ms/step - loss: 0.0074 - mse: 0.0148 - val_loss: 3.6296e-04 - val_mse: 7.2592e-04\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 4.3709e-04 - mse: 8.7418e-04 - val_loss: 3.5737e-04 - val_mse: 7.1475e-04\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 3.3115e-04 - mse: 6.6230e-04 - val_loss: 3.2545e-04 - val_mse: 6.5089e-04\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 3.0755e-04 - mse: 6.1510e-04 - val_loss: 3.1068e-04 - val_mse: 6.2135e-04\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.9086e-04 - mse: 5.8172e-04 - val_loss: 3.8220e-04 - val_mse: 7.6441e-04\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.8276e-04 - mse: 5.6553e-04 - val_loss: 2.6730e-04 - val_mse: 5.3460e-04\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 2.7057e-04 - mse: 5.4114e-04 - val_loss: 3.1129e-04 - val_mse: 6.2258e-04\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.6016e-04 - mse: 5.2031e-04 - val_loss: 2.4129e-04 - val_mse: 4.8259e-04\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.4681e-04 - mse: 4.9362e-04 - val_loss: 2.2975e-04 - val_mse: 4.5950e-04\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 2.4064e-04 - mse: 4.8128e-04 - val_loss: 2.2217e-04 - val_mse: 4.4435e-04\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 2.4013e-04 - mse: 4.8027e-04 - val_loss: 3.3467e-04 - val_mse: 6.6935e-04\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 2.2418e-04 - mse: 4.4836e-04 - val_loss: 2.0679e-04 - val_mse: 4.1357e-04\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 2.2272e-04 - mse: 4.4545e-04 - val_loss: 2.1188e-04 - val_mse: 4.2376e-04\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.2330e-04 - mse: 4.4660e-04 - val_loss: 1.9768e-04 - val_mse: 3.9536e-04\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 2.1757e-04 - mse: 4.3514e-04 - val_loss: 2.2952e-04 - val_mse: 4.5904e-04\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 2.1001e-04 - mse: 4.2002e-04 - val_loss: 1.8936e-04 - val_mse: 3.7872e-04\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 1.9186e-04 - mse: 3.8372e-04 - val_loss: 1.7603e-04 - val_mse: 3.5207e-04\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.9489e-04 - mse: 3.8979e-04 - val_loss: 1.7310e-04 - val_mse: 3.4620e-04\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 1.8346e-04 - mse: 3.6691e-04 - val_loss: 1.7490e-04 - val_mse: 3.4979e-04\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.9647e-04 - mse: 3.9293e-04 - val_loss: 1.6832e-04 - val_mse: 3.3663e-04\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.8366e-04 - mse: 3.6733e-04 - val_loss: 1.6201e-04 - val_mse: 3.2401e-04\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.7788e-04 - mse: 3.5577e-04 - val_loss: 1.6201e-04 - val_mse: 3.2402e-04\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.7476e-04 - mse: 3.4952e-04 - val_loss: 1.4333e-04 - val_mse: 2.8666e-04\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.6234e-04 - mse: 3.2469e-04 - val_loss: 1.3922e-04 - val_mse: 2.7845e-04\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.6585e-04 - mse: 3.3170e-04 - val_loss: 1.3508e-04 - val_mse: 2.7015e-04\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 1.7416e-04 - mse: 3.4832e-04 - val_loss: 1.3210e-04 - val_mse: 2.6419e-04\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.5050e-04 - mse: 3.0100e-04 - val_loss: 1.3421e-04 - val_mse: 2.6843e-04\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.5233e-04 - mse: 3.0466e-04 - val_loss: 1.9491e-04 - val_mse: 3.8981e-04\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4888e-04 - mse: 2.9776e-04 - val_loss: 1.9552e-04 - val_mse: 3.9103e-04\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4681e-04 - mse: 2.9361e-04 - val_loss: 1.3239e-04 - val_mse: 2.6479e-04\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 1.5067e-04 - mse: 3.0133e-04 - val_loss: 1.1852e-04 - val_mse: 2.3705e-04\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4844e-04 - mse: 2.9688e-04 - val_loss: 1.4460e-04 - val_mse: 2.8921e-04\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4968e-04 - mse: 2.9937e-04 - val_loss: 1.6817e-04 - val_mse: 3.3635e-04\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4657e-04 - mse: 2.9315e-04 - val_loss: 1.1275e-04 - val_mse: 2.2550e-04\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4012e-04 - mse: 2.8023e-04 - val_loss: 1.5090e-04 - val_mse: 3.0180e-04\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.4451e-04 - mse: 2.8902e-04 - val_loss: 1.2725e-04 - val_mse: 2.5449e-04\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.4005e-04 - mse: 2.8009e-04 - val_loss: 1.0915e-04 - val_mse: 2.1831e-04\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.5763e-04 - mse: 3.1526e-04 - val_loss: 1.2124e-04 - val_mse: 2.4248e-04\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3862e-04 - mse: 2.7724e-04 - val_loss: 1.3407e-04 - val_mse: 2.6814e-04\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3632e-04 - mse: 2.7265e-04 - val_loss: 1.0840e-04 - val_mse: 2.1681e-04\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3897e-04 - mse: 2.7795e-04 - val_loss: 1.0484e-04 - val_mse: 2.0967e-04\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4546e-04 - mse: 2.9092e-04 - val_loss: 1.1959e-04 - val_mse: 2.3918e-04\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3020e-04 - mse: 2.6041e-04 - val_loss: 1.1512e-04 - val_mse: 2.3023e-04\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3650e-04 - mse: 2.7300e-04 - val_loss: 1.0420e-04 - val_mse: 2.0840e-04\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.4788e-04 - mse: 2.9575e-04 - val_loss: 1.5432e-04 - val_mse: 3.0864e-04\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.3358e-04 - mse: 2.6716e-04 - val_loss: 1.1493e-04 - val_mse: 2.2986e-04\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.3557e-04 - mse: 2.7113e-04 - val_loss: 1.3759e-04 - val_mse: 2.7519e-04\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.3032e-04 - mse: 2.6065e-04 - val_loss: 1.3368e-04 - val_mse: 2.6736e-04\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.2865e-04 - mse: 2.5729e-04 - val_loss: 9.8534e-05 - val_mse: 1.9707e-04\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 2s 18ms/step - loss: 1.3671e-04 - mse: 2.7343e-04 - val_loss: 9.8011e-05 - val_mse: 1.9602e-04\n",
      "pred.shape : (620, 1) , y_test.shape : (640,)\n",
      "3200길이의 데이터 적용 완료\n",
      " 길이: 3200, RMSE:995.431417967325\n",
      "train set 확인:  (2640, 4) (2640,) test set 확인:  (660, 4) (660,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 8s 34ms/step - loss: 0.0035 - mse: 0.0069 - val_loss: 3.6376e-04 - val_mse: 7.2752e-04\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 3.4468e-04 - mse: 6.8936e-04 - val_loss: 3.5270e-04 - val_mse: 7.0540e-04\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 3.1762e-04 - mse: 6.3524e-04 - val_loss: 3.7113e-04 - val_mse: 7.4226e-04\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.9410e-04 - mse: 5.8819e-04 - val_loss: 2.8886e-04 - val_mse: 5.7771e-04\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.8017e-04 - mse: 5.6034e-04 - val_loss: 2.9837e-04 - val_mse: 5.9673e-04\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 2.7125e-04 - mse: 5.4250e-04 - val_loss: 2.7437e-04 - val_mse: 5.4875e-04\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 2.8141e-04 - mse: 5.6282e-04 - val_loss: 2.9239e-04 - val_mse: 5.8477e-04\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 2.5613e-04 - mse: 5.1225e-04 - val_loss: 2.4230e-04 - val_mse: 4.8459e-04\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.5019e-04 - mse: 5.0038e-04 - val_loss: 2.3341e-04 - val_mse: 4.6681e-04\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.3602e-04 - mse: 4.7203e-04 - val_loss: 2.2031e-04 - val_mse: 4.4061e-04\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 2.3855e-04 - mse: 4.7711e-04 - val_loss: 2.3520e-04 - val_mse: 4.7041e-04\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.3463e-04 - mse: 4.6926e-04 - val_loss: 2.1362e-04 - val_mse: 4.2724e-04\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.1708e-04 - mse: 4.3416e-04 - val_loss: 1.9202e-04 - val_mse: 3.8404e-04\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 2.0862e-04 - mse: 4.1725e-04 - val_loss: 2.0277e-04 - val_mse: 4.0553e-04\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 2.0004e-04 - mse: 4.0008e-04 - val_loss: 2.1966e-04 - val_mse: 4.3933e-04\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 1.9793e-04 - mse: 3.9586e-04 - val_loss: 2.1022e-04 - val_mse: 4.2044e-04\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.9403e-04 - mse: 3.8807e-04 - val_loss: 1.7833e-04 - val_mse: 3.5665e-04\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 1.8943e-04 - mse: 3.7886e-04 - val_loss: 1.6532e-04 - val_mse: 3.3065e-04\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.8370e-04 - mse: 3.6740e-04 - val_loss: 1.6265e-04 - val_mse: 3.2530e-04\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.8126e-04 - mse: 3.6253e-04 - val_loss: 2.1614e-04 - val_mse: 4.3228e-04\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.8558e-04 - mse: 3.7116e-04 - val_loss: 1.5940e-04 - val_mse: 3.1879e-04\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.8623e-04 - mse: 3.7246e-04 - val_loss: 1.5166e-04 - val_mse: 3.0332e-04\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.8448e-04 - mse: 3.6895e-04 - val_loss: 1.4935e-04 - val_mse: 2.9871e-04\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.7339e-04 - mse: 3.4678e-04 - val_loss: 1.6298e-04 - val_mse: 3.2596e-04\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.7138e-04 - mse: 3.4277e-04 - val_loss: 1.4256e-04 - val_mse: 2.8511e-04\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 1.6315e-04 - mse: 3.2631e-04 - val_loss: 1.3967e-04 - val_mse: 2.7934e-04\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.6329e-04 - mse: 3.2658e-04 - val_loss: 1.5366e-04 - val_mse: 3.0732e-04\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.6416e-04 - mse: 3.2832e-04 - val_loss: 1.6123e-04 - val_mse: 3.2247e-04\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.6105e-04 - mse: 3.2210e-04 - val_loss: 1.3689e-04 - val_mse: 2.7379e-04\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.6053e-04 - mse: 3.2106e-04 - val_loss: 1.3250e-04 - val_mse: 2.6501e-04\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.7084e-04 - mse: 3.4167e-04 - val_loss: 2.4724e-04 - val_mse: 4.9448e-04\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 1.6860e-04 - mse: 3.3721e-04 - val_loss: 1.2757e-04 - val_mse: 2.5515e-04\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.6963e-04 - mse: 3.3927e-04 - val_loss: 2.0187e-04 - val_mse: 4.0373e-04\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.5511e-04 - mse: 3.1021e-04 - val_loss: 4.0214e-04 - val_mse: 8.0429e-04\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.5434e-04 - mse: 3.0867e-04 - val_loss: 1.2237e-04 - val_mse: 2.4474e-04\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.4469e-04 - mse: 2.8938e-04 - val_loss: 2.3224e-04 - val_mse: 4.6448e-04\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.5855e-04 - mse: 3.1711e-04 - val_loss: 1.3793e-04 - val_mse: 2.7586e-04\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.4661e-04 - mse: 2.9322e-04 - val_loss: 1.1908e-04 - val_mse: 2.3816e-04\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.5539e-04 - mse: 3.1078e-04 - val_loss: 1.1753e-04 - val_mse: 2.3505e-04\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.4291e-04 - mse: 2.8583e-04 - val_loss: 1.2466e-04 - val_mse: 2.4933e-04\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.4193e-04 - mse: 2.8386e-04 - val_loss: 2.1662e-04 - val_mse: 4.3324e-04\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 1.4095e-04 - mse: 2.8189e-04 - val_loss: 1.1701e-04 - val_mse: 2.3402e-04\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 1.3791e-04 - mse: 2.7581e-04 - val_loss: 1.1135e-04 - val_mse: 2.2270e-04\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3764e-04 - mse: 2.7527e-04 - val_loss: 1.2862e-04 - val_mse: 2.5725e-04\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.3794e-04 - mse: 2.7587e-04 - val_loss: 1.1424e-04 - val_mse: 2.2848e-04\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 1.4368e-04 - mse: 2.8736e-04 - val_loss: 2.2050e-04 - val_mse: 4.4101e-04\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.4194e-04 - mse: 2.8387e-04 - val_loss: 1.0576e-04 - val_mse: 2.1152e-04\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3224e-04 - mse: 2.6448e-04 - val_loss: 1.2218e-04 - val_mse: 2.4436e-04\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 2s 18ms/step - loss: 1.4158e-04 - mse: 2.8316e-04 - val_loss: 1.0472e-04 - val_mse: 2.0944e-04\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 2s 17ms/step - loss: 1.3846e-04 - mse: 2.7692e-04 - val_loss: 1.1358e-04 - val_mse: 2.2716e-04\n",
      "pred.shape : (640, 1) , y_test.shape : (660,)\n",
      "3300길이의 데이터 적용 완료\n",
      " 길이: 3300, RMSE:1071.5864048476176\n",
      "train set 확인:  (2720, 4) (2720,) test set 확인:  (680, 4) (680,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 8s 32ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 3.4881e-04 - val_mse: 6.9762e-04\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 3.5417e-04 - mse: 7.0834e-04 - val_loss: 3.3977e-04 - val_mse: 6.7953e-04\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 3.2960e-04 - mse: 6.5919e-04 - val_loss: 3.1587e-04 - val_mse: 6.3174e-04\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 3.2263e-04 - mse: 6.4526e-04 - val_loss: 2.8095e-04 - val_mse: 5.6190e-04\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 2.9600e-04 - mse: 5.9199e-04 - val_loss: 3.0571e-04 - val_mse: 6.1142e-04\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 3.0180e-04 - mse: 6.0359e-04 - val_loss: 3.0188e-04 - val_mse: 6.0375e-04\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 2s 17ms/step - loss: 2.7650e-04 - mse: 5.5299e-04 - val_loss: 2.5767e-04 - val_mse: 5.1533e-04\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.7480e-04 - mse: 5.4960e-04 - val_loss: 2.4041e-04 - val_mse: 4.8081e-04\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.6276e-04 - mse: 5.2551e-04 - val_loss: 3.2036e-04 - val_mse: 6.4073e-04\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 2.5778e-04 - mse: 5.1556e-04 - val_loss: 2.2690e-04 - val_mse: 4.5379e-04\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.3184e-04 - mse: 4.6369e-04 - val_loss: 2.4379e-04 - val_mse: 4.8757e-04\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.2876e-04 - mse: 4.5752e-04 - val_loss: 2.8194e-04 - val_mse: 5.6389e-04\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.1370e-04 - mse: 4.2740e-04 - val_loss: 2.0112e-04 - val_mse: 4.0224e-04\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 2.0024e-04 - mse: 4.0048e-04 - val_loss: 1.8784e-04 - val_mse: 3.7567e-04\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.9503e-04 - mse: 3.9006e-04 - val_loss: 3.0394e-04 - val_mse: 6.0788e-04\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.0044e-04 - mse: 4.0088e-04 - val_loss: 1.8940e-04 - val_mse: 3.7880e-04\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.9172e-04 - mse: 3.8344e-04 - val_loss: 1.6619e-04 - val_mse: 3.3238e-04\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 2s 17ms/step - loss: 1.8290e-04 - mse: 3.6579e-04 - val_loss: 1.5064e-04 - val_mse: 3.0128e-04\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.0183e-04 - mse: 4.0367e-04 - val_loss: 1.5358e-04 - val_mse: 3.0716e-04\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 2s 17ms/step - loss: 1.7345e-04 - mse: 3.4691e-04 - val_loss: 1.4061e-04 - val_mse: 2.8123e-04\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 1.7352e-04 - mse: 3.4704e-04 - val_loss: 1.8655e-04 - val_mse: 3.7311e-04\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.6963e-04 - mse: 3.3925e-04 - val_loss: 1.3867e-04 - val_mse: 2.7734e-04\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 1.7096e-04 - mse: 3.4191e-04 - val_loss: 1.2932e-04 - val_mse: 2.5865e-04\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 1.6385e-04 - mse: 3.2770e-04 - val_loss: 1.2770e-04 - val_mse: 2.5540e-04\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.6758e-04 - mse: 3.3516e-04 - val_loss: 1.2937e-04 - val_mse: 2.5874e-04\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.7536e-04 - mse: 3.5072e-04 - val_loss: 1.2533e-04 - val_mse: 2.5065e-04\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 1.5758e-04 - mse: 3.1516e-04 - val_loss: 2.2656e-04 - val_mse: 4.5311e-04\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.6535e-04 - mse: 3.3069e-04 - val_loss: 2.8184e-04 - val_mse: 5.6368e-04\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.5992e-04 - mse: 3.1984e-04 - val_loss: 1.1407e-04 - val_mse: 2.2813e-04\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.5433e-04 - mse: 3.0865e-04 - val_loss: 1.1520e-04 - val_mse: 2.3041e-04\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.4901e-04 - mse: 2.9803e-04 - val_loss: 1.2011e-04 - val_mse: 2.4021e-04\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.5089e-04 - mse: 3.0178e-04 - val_loss: 1.1256e-04 - val_mse: 2.2513e-04\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.4587e-04 - mse: 2.9174e-04 - val_loss: 1.0879e-04 - val_mse: 2.1758e-04\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.4268e-04 - mse: 2.8536e-04 - val_loss: 1.1920e-04 - val_mse: 2.3840e-04\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.4541e-04 - mse: 2.9083e-04 - val_loss: 2.2442e-04 - val_mse: 4.4884e-04\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.4223e-04 - mse: 2.8446e-04 - val_loss: 1.7182e-04 - val_mse: 3.4363e-04\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 1.5059e-04 - mse: 3.0117e-04 - val_loss: 1.1181e-04 - val_mse: 2.2363e-04\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 1.7358e-04 - mse: 3.4717e-04 - val_loss: 1.6859e-04 - val_mse: 3.3719e-04\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.4071e-04 - mse: 2.8142e-04 - val_loss: 1.0775e-04 - val_mse: 2.1549e-04\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.4321e-04 - mse: 2.8641e-04 - val_loss: 1.1558e-04 - val_mse: 2.3115e-04\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.4216e-04 - mse: 2.8432e-04 - val_loss: 1.2443e-04 - val_mse: 2.4887e-04\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.3330e-04 - mse: 2.6659e-04 - val_loss: 1.0947e-04 - val_mse: 2.1894e-04\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.4080e-04 - mse: 2.8160e-04 - val_loss: 1.2774e-04 - val_mse: 2.5548e-04\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 1.3818e-04 - mse: 2.7635e-04 - val_loss: 9.4951e-05 - val_mse: 1.8990e-04\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.2997e-04 - mse: 2.5994e-04 - val_loss: 9.3593e-05 - val_mse: 1.8719e-04\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 1.3473e-04 - mse: 2.6946e-04 - val_loss: 9.2831e-05 - val_mse: 1.8566e-04\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 1.2646e-04 - mse: 2.5291e-04 - val_loss: 9.2125e-05 - val_mse: 1.8425e-04\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.4105e-04 - mse: 2.8210e-04 - val_loss: 9.6382e-05 - val_mse: 1.9276e-04\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.3975e-04 - mse: 2.7950e-04 - val_loss: 1.9575e-04 - val_mse: 3.9150e-04\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 1.5163e-04 - mse: 3.0326e-04 - val_loss: 1.8777e-04 - val_mse: 3.7554e-04\n",
      "pred.shape : (660, 1) , y_test.shape : (680,)\n",
      "3400길이의 데이터 적용 완료\n",
      " 길이: 3400, RMSE:1377.799622509745\n",
      "train set 확인:  (2800, 4) (2800,) test set 확인:  (700, 4) (700,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 35ms/step - loss: 0.0033 - mse: 0.0067 - val_loss: 4.3954e-04 - val_mse: 8.7907e-04\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.0219e-04 - mse: 8.0437e-04 - val_loss: 3.7881e-04 - val_mse: 7.5761e-04\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.6485e-04 - mse: 7.2970e-04 - val_loss: 4.9382e-04 - val_mse: 9.8765e-04\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 3.7738e-04 - mse: 7.5475e-04 - val_loss: 6.1696e-04 - val_mse: 0.0012\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.7831e-04 - mse: 7.5662e-04 - val_loss: 4.6293e-04 - val_mse: 9.2587e-04\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.6103e-04 - mse: 7.2206e-04 - val_loss: 4.4376e-04 - val_mse: 8.8753e-04\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.4088e-04 - mse: 6.8177e-04 - val_loss: 3.5766e-04 - val_mse: 7.1532e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 3.2021e-04 - mse: 6.4043e-04 - val_loss: 3.0711e-04 - val_mse: 6.1422e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 3.1199e-04 - mse: 6.2399e-04 - val_loss: 3.5633e-04 - val_mse: 7.1266e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.0469e-04 - mse: 6.0939e-04 - val_loss: 4.1061e-04 - val_mse: 8.2123e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 3.0506e-04 - mse: 6.1011e-04 - val_loss: 4.5651e-04 - val_mse: 9.1302e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.9746e-04 - mse: 5.9493e-04 - val_loss: 3.0732e-04 - val_mse: 6.1465e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.8301e-04 - mse: 5.6603e-04 - val_loss: 3.3038e-04 - val_mse: 6.6076e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.6608e-04 - mse: 5.3216e-04 - val_loss: 3.9605e-04 - val_mse: 7.9209e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.8881e-04 - mse: 5.7763e-04 - val_loss: 2.7890e-04 - val_mse: 5.5780e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.6793e-04 - mse: 5.3586e-04 - val_loss: 2.2555e-04 - val_mse: 4.5110e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.4303e-04 - mse: 4.8606e-04 - val_loss: 3.4245e-04 - val_mse: 6.8489e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 2.3668e-04 - mse: 4.7337e-04 - val_loss: 2.0274e-04 - val_mse: 4.0549e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 2.2286e-04 - mse: 4.4572e-04 - val_loss: 2.5963e-04 - val_mse: 5.1925e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.2845e-04 - mse: 4.5690e-04 - val_loss: 1.8170e-04 - val_mse: 3.6340e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.5146e-04 - mse: 5.0293e-04 - val_loss: 1.8411e-04 - val_mse: 3.6822e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.0608e-04 - mse: 4.1216e-04 - val_loss: 1.7909e-04 - val_mse: 3.5817e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.0487e-04 - mse: 4.0973e-04 - val_loss: 2.4410e-04 - val_mse: 4.8820e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 1.9319e-04 - mse: 3.8639e-04 - val_loss: 1.6139e-04 - val_mse: 3.2277e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.8866e-04 - mse: 3.7731e-04 - val_loss: 1.5308e-04 - val_mse: 3.0617e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.8567e-04 - mse: 3.7134e-04 - val_loss: 1.5891e-04 - val_mse: 3.1782e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.7490e-04 - mse: 3.4980e-04 - val_loss: 1.4456e-04 - val_mse: 2.8911e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 1.7371e-04 - mse: 3.4743e-04 - val_loss: 1.4026e-04 - val_mse: 2.8051e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 1.8284e-04 - mse: 3.6568e-04 - val_loss: 1.4112e-04 - val_mse: 2.8224e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.8179e-04 - mse: 3.6357e-04 - val_loss: 1.3597e-04 - val_mse: 2.7193e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.7758e-04 - mse: 3.5515e-04 - val_loss: 1.3446e-04 - val_mse: 2.6891e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 1.6924e-04 - mse: 3.3849e-04 - val_loss: 1.3427e-04 - val_mse: 2.6854e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.7157e-04 - mse: 3.4315e-04 - val_loss: 1.2974e-04 - val_mse: 2.5949e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.6286e-04 - mse: 3.2571e-04 - val_loss: 1.8164e-04 - val_mse: 3.6328e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 2s 23ms/step - loss: 1.6188e-04 - mse: 3.2377e-04 - val_loss: 1.3287e-04 - val_mse: 2.6574e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.6189e-04 - mse: 3.2379e-04 - val_loss: 1.4388e-04 - val_mse: 2.8775e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.6526e-04 - mse: 3.3052e-04 - val_loss: 2.0826e-04 - val_mse: 4.1652e-04\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 1.5181e-04 - mse: 3.0361e-04 - val_loss: 1.2673e-04 - val_mse: 2.5347e-04\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 1.6959e-04 - mse: 3.3917e-04 - val_loss: 1.4042e-04 - val_mse: 2.8083e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 1.6143e-04 - mse: 3.2287e-04 - val_loss: 2.0430e-04 - val_mse: 4.0859e-04\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.6718e-04 - mse: 3.3436e-04 - val_loss: 1.1897e-04 - val_mse: 2.3794e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.4873e-04 - mse: 2.9746e-04 - val_loss: 1.3353e-04 - val_mse: 2.6706e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.6090e-04 - mse: 3.2180e-04 - val_loss: 1.7080e-04 - val_mse: 3.4160e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 2s 24ms/step - loss: 1.5863e-04 - mse: 3.1725e-04 - val_loss: 1.4751e-04 - val_mse: 2.9502e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 1.5397e-04 - mse: 3.0795e-04 - val_loss: 1.3057e-04 - val_mse: 2.6114e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 1.4473e-04 - mse: 2.8946e-04 - val_loss: 1.4588e-04 - val_mse: 2.9177e-04\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.4550e-04 - mse: 2.9101e-04 - val_loss: 1.1768e-04 - val_mse: 2.3536e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 1.4594e-04 - mse: 2.9187e-04 - val_loss: 1.1455e-04 - val_mse: 2.2910e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.4547e-04 - mse: 2.9094e-04 - val_loss: 1.5056e-04 - val_mse: 3.0113e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 1.5511e-04 - mse: 3.1022e-04 - val_loss: 1.3151e-04 - val_mse: 2.6303e-04\n",
      "pred.shape : (680, 1) , y_test.shape : (700,)\n",
      "3500길이의 데이터 적용 완료\n",
      " 길이: 3500, RMSE:1153.0869891641162\n",
      "train set 확인:  (2880, 4) (2880,) test set 확인:  (720, 4) (720,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 10s 35ms/step - loss: 0.0111 - mse: 0.0222 - val_loss: 6.0341e-04 - val_mse: 0.0012\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 7.8021e-04 - mse: 0.0016 - val_loss: 3.3072e-04 - val_mse: 6.6143e-04\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 3.4533e-04 - mse: 6.9066e-04 - val_loss: 3.2708e-04 - val_mse: 6.5417e-04\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 3.3916e-04 - mse: 6.7831e-04 - val_loss: 3.3644e-04 - val_mse: 6.7287e-04\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 3.3122e-04 - mse: 6.6244e-04 - val_loss: 3.1329e-04 - val_mse: 6.2658e-04\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 3.2984e-04 - mse: 6.5969e-04 - val_loss: 3.4067e-04 - val_mse: 6.8134e-04\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 3.2860e-04 - mse: 6.5721e-04 - val_loss: 3.7414e-04 - val_mse: 7.4827e-04\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 3.3305e-04 - mse: 6.6611e-04 - val_loss: 3.4185e-04 - val_mse: 6.8369e-04\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 3.1950e-04 - mse: 6.3900e-04 - val_loss: 2.9826e-04 - val_mse: 5.9652e-04\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 2s 23ms/step - loss: 3.1263e-04 - mse: 6.2525e-04 - val_loss: 3.4269e-04 - val_mse: 6.8537e-04\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 3.0082e-04 - mse: 6.0163e-04 - val_loss: 3.1162e-04 - val_mse: 6.2324e-04\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.9579e-04 - mse: 5.9159e-04 - val_loss: 3.0232e-04 - val_mse: 6.0465e-04\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.9128e-04 - mse: 5.8257e-04 - val_loss: 3.0773e-04 - val_mse: 6.1545e-04\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.8656e-04 - mse: 5.7313e-04 - val_loss: 2.8609e-04 - val_mse: 5.7217e-04\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.8429e-04 - mse: 5.6858e-04 - val_loss: 2.7341e-04 - val_mse: 5.4681e-04\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.7839e-04 - mse: 5.5677e-04 - val_loss: 2.9839e-04 - val_mse: 5.9678e-04\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.8657e-04 - mse: 5.7314e-04 - val_loss: 2.9639e-04 - val_mse: 5.9279e-04\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.7628e-04 - mse: 5.5257e-04 - val_loss: 4.3363e-04 - val_mse: 8.6726e-04\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.8181e-04 - mse: 5.6361e-04 - val_loss: 3.2106e-04 - val_mse: 6.4211e-04\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.7713e-04 - mse: 5.5426e-04 - val_loss: 3.6325e-04 - val_mse: 7.2649e-04\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.6003e-04 - mse: 5.2005e-04 - val_loss: 2.4251e-04 - val_mse: 4.8503e-04\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 2.5079e-04 - mse: 5.0158e-04 - val_loss: 2.3944e-04 - val_mse: 4.7888e-04\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.5982e-04 - mse: 5.1964e-04 - val_loss: 2.2155e-04 - val_mse: 4.4309e-04\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.5549e-04 - mse: 5.1097e-04 - val_loss: 2.1660e-04 - val_mse: 4.3320e-04\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.4243e-04 - mse: 4.8485e-04 - val_loss: 2.0114e-04 - val_mse: 4.0228e-04\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.3612e-04 - mse: 4.7223e-04 - val_loss: 2.1770e-04 - val_mse: 4.3539e-04\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.3564e-04 - mse: 4.7128e-04 - val_loss: 2.3049e-04 - val_mse: 4.6098e-04\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.2888e-04 - mse: 4.5776e-04 - val_loss: 2.5229e-04 - val_mse: 5.0459e-04\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 2.1656e-04 - mse: 4.3312e-04 - val_loss: 1.9392e-04 - val_mse: 3.8784e-04\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.1338e-04 - mse: 4.2676e-04 - val_loss: 2.4347e-04 - val_mse: 4.8695e-04\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.0031e-04 - mse: 4.0062e-04 - val_loss: 1.7032e-04 - val_mse: 3.4064e-04\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.0573e-04 - mse: 4.1147e-04 - val_loss: 1.6533e-04 - val_mse: 3.3066e-04\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.9121e-04 - mse: 3.8241e-04 - val_loss: 2.0912e-04 - val_mse: 4.1824e-04\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.8639e-04 - mse: 3.7278e-04 - val_loss: 1.4878e-04 - val_mse: 2.9757e-04\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.8981e-04 - mse: 3.7961e-04 - val_loss: 1.5699e-04 - val_mse: 3.1398e-04\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 1.9747e-04 - mse: 3.9494e-04 - val_loss: 1.6081e-04 - val_mse: 3.2162e-04\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7071e-04 - mse: 3.4141e-04 - val_loss: 1.3842e-04 - val_mse: 2.7684e-04\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.6479e-04 - mse: 3.2957e-04 - val_loss: 1.5418e-04 - val_mse: 3.0835e-04\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.6618e-04 - mse: 3.3235e-04 - val_loss: 1.4336e-04 - val_mse: 2.8672e-04\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.6240e-04 - mse: 3.2480e-04 - val_loss: 1.2583e-04 - val_mse: 2.5166e-04\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 1.5701e-04 - mse: 3.1402e-04 - val_loss: 1.4583e-04 - val_mse: 2.9166e-04\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 2s 24ms/step - loss: 1.5353e-04 - mse: 3.0707e-04 - val_loss: 1.2792e-04 - val_mse: 2.5583e-04\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.5193e-04 - mse: 3.0385e-04 - val_loss: 1.2787e-04 - val_mse: 2.5575e-04\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5431e-04 - mse: 3.0863e-04 - val_loss: 1.4278e-04 - val_mse: 2.8556e-04\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.4909e-04 - mse: 2.9819e-04 - val_loss: 1.1413e-04 - val_mse: 2.2826e-04\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.5285e-04 - mse: 3.0570e-04 - val_loss: 1.1179e-04 - val_mse: 2.2358e-04\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5442e-04 - mse: 3.0883e-04 - val_loss: 1.0978e-04 - val_mse: 2.1956e-04\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.4506e-04 - mse: 2.9013e-04 - val_loss: 1.9092e-04 - val_mse: 3.8184e-04\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5067e-04 - mse: 3.0135e-04 - val_loss: 1.4407e-04 - val_mse: 2.8813e-04\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.3626e-04 - mse: 2.7252e-04 - val_loss: 1.1712e-04 - val_mse: 2.3423e-04\n",
      "pred.shape : (700, 1) , y_test.shape : (720,)\n",
      "3600길이의 데이터 적용 완료\n",
      " 길이: 3600, RMSE:1088.1386426684091\n",
      "train set 확인:  (2960, 4) (2960,) test set 확인:  (740, 4) (740,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - 10s 37ms/step - loss: 0.0151 - mse: 0.0302 - val_loss: 7.4062e-04 - val_mse: 0.0015\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 6.4461e-04 - mse: 0.0013 - val_loss: 3.7987e-04 - val_mse: 7.5973e-04\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 3.7559e-04 - mse: 7.5118e-04 - val_loss: 3.7534e-04 - val_mse: 7.5069e-04\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 3.4259e-04 - mse: 6.8517e-04 - val_loss: 4.0656e-04 - val_mse: 8.1313e-04\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 3.1788e-04 - mse: 6.3576e-04 - val_loss: 3.9506e-04 - val_mse: 7.9012e-04\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 3.0101e-04 - mse: 6.0203e-04 - val_loss: 3.6648e-04 - val_mse: 7.3296e-04\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 2.8028e-04 - mse: 5.6056e-04 - val_loss: 3.4841e-04 - val_mse: 6.9681e-04\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.6718e-04 - mse: 5.3435e-04 - val_loss: 2.3885e-04 - val_mse: 4.7771e-04\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 2.7911e-04 - mse: 5.5821e-04 - val_loss: 2.9576e-04 - val_mse: 5.9152e-04\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.5658e-04 - mse: 5.1317e-04 - val_loss: 2.3183e-04 - val_mse: 4.6365e-04\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.4758e-04 - mse: 4.9517e-04 - val_loss: 2.2247e-04 - val_mse: 4.4495e-04\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 2.5491e-04 - mse: 5.0983e-04 - val_loss: 2.1323e-04 - val_mse: 4.2646e-04\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 2.3943e-04 - mse: 4.7886e-04 - val_loss: 2.7531e-04 - val_mse: 5.5061e-04\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 2.4252e-04 - mse: 4.8503e-04 - val_loss: 3.0011e-04 - val_mse: 6.0022e-04\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 2.4004e-04 - mse: 4.8008e-04 - val_loss: 2.9016e-04 - val_mse: 5.8033e-04\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 2.2518e-04 - mse: 4.5036e-04 - val_loss: 1.9252e-04 - val_mse: 3.8503e-04\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.1874e-04 - mse: 4.3747e-04 - val_loss: 2.0206e-04 - val_mse: 4.0411e-04\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 2.1827e-04 - mse: 4.3653e-04 - val_loss: 2.2939e-04 - val_mse: 4.5877e-04\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.2323e-04 - mse: 4.4646e-04 - val_loss: 2.2724e-04 - val_mse: 4.5448e-04\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 2.1867e-04 - mse: 4.3734e-04 - val_loss: 1.7696e-04 - val_mse: 3.5393e-04\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.1825e-04 - mse: 4.3651e-04 - val_loss: 1.7695e-04 - val_mse: 3.5389e-04\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 2.1780e-04 - mse: 4.3559e-04 - val_loss: 1.7167e-04 - val_mse: 3.4333e-04\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 2.1340e-04 - mse: 4.2681e-04 - val_loss: 1.9552e-04 - val_mse: 3.9103e-04\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.0750e-04 - mse: 4.1499e-04 - val_loss: 1.8644e-04 - val_mse: 3.7288e-04\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.0283e-04 - mse: 4.0565e-04 - val_loss: 1.7467e-04 - val_mse: 3.4933e-04\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.9593e-04 - mse: 3.9185e-04 - val_loss: 1.7482e-04 - val_mse: 3.4965e-04\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 2.0061e-04 - mse: 4.0122e-04 - val_loss: 1.5898e-04 - val_mse: 3.1795e-04\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.8892e-04 - mse: 3.7784e-04 - val_loss: 1.5671e-04 - val_mse: 3.1341e-04\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.9055e-04 - mse: 3.8109e-04 - val_loss: 1.5754e-04 - val_mse: 3.1507e-04\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 1.9202e-04 - mse: 3.8404e-04 - val_loss: 1.6553e-04 - val_mse: 3.3107e-04\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.8055e-04 - mse: 3.6109e-04 - val_loss: 1.5008e-04 - val_mse: 3.0017e-04\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 1.7902e-04 - mse: 3.5804e-04 - val_loss: 1.4814e-04 - val_mse: 2.9628e-04\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 2.0199e-04 - mse: 4.0398e-04 - val_loss: 3.6918e-04 - val_mse: 7.3837e-04\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.7779e-04 - mse: 3.5557e-04 - val_loss: 1.6516e-04 - val_mse: 3.3032e-04\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.9261e-04 - mse: 3.8523e-04 - val_loss: 1.9474e-04 - val_mse: 3.8948e-04\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 1.7790e-04 - mse: 3.5581e-04 - val_loss: 2.6136e-04 - val_mse: 5.2271e-04\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.8493e-04 - mse: 3.6987e-04 - val_loss: 1.9805e-04 - val_mse: 3.9610e-04\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.8018e-04 - mse: 3.6035e-04 - val_loss: 1.4002e-04 - val_mse: 2.8003e-04\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.7516e-04 - mse: 3.5032e-04 - val_loss: 1.5618e-04 - val_mse: 3.1236e-04\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 1.7732e-04 - mse: 3.5463e-04 - val_loss: 1.6053e-04 - val_mse: 3.2106e-04\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 2s 15ms/step - loss: 1.7002e-04 - mse: 3.4005e-04 - val_loss: 1.5021e-04 - val_mse: 3.0043e-04\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.7929e-04 - mse: 3.5859e-04 - val_loss: 1.9033e-04 - val_mse: 3.8066e-04\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 1.6584e-04 - mse: 3.3168e-04 - val_loss: 1.4390e-04 - val_mse: 2.8779e-04\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.6736e-04 - mse: 3.3471e-04 - val_loss: 2.1271e-04 - val_mse: 4.2542e-04\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.6731e-04 - mse: 3.3463e-04 - val_loss: 1.3344e-04 - val_mse: 2.6688e-04\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.6887e-04 - mse: 3.3775e-04 - val_loss: 1.2994e-04 - val_mse: 2.5988e-04\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.6538e-04 - mse: 3.3077e-04 - val_loss: 1.3118e-04 - val_mse: 2.6237e-04\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 1.6844e-04 - mse: 3.3688e-04 - val_loss: 1.4658e-04 - val_mse: 2.9316e-04\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.7604e-04 - mse: 3.5207e-04 - val_loss: 3.2764e-04 - val_mse: 6.5529e-04\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 1.7144e-04 - mse: 3.4288e-04 - val_loss: 1.3114e-04 - val_mse: 2.6227e-04\n",
      "pred.shape : (720, 1) , y_test.shape : (740,)\n",
      "3700길이의 데이터 적용 완료\n",
      " 길이: 3700, RMSE:1152.0099160077332\n",
      "train set 확인:  (3040, 4) (3040,) test set 확인:  (760, 4) (760,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "95/95 [==============================] - 7s 29ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 4.6195e-04 - val_mse: 9.2391e-04\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.4040e-04 - mse: 6.8080e-04 - val_loss: 4.7857e-04 - val_mse: 9.5715e-04\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.0359e-04 - mse: 6.0718e-04 - val_loss: 3.6804e-04 - val_mse: 7.3609e-04\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.8968e-04 - mse: 5.7936e-04 - val_loss: 3.4867e-04 - val_mse: 6.9734e-04\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 2s 19ms/step - loss: 2.7613e-04 - mse: 5.5227e-04 - val_loss: 2.6421e-04 - val_mse: 5.2841e-04\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 5s 47ms/step - loss: 2.7222e-04 - mse: 5.4443e-04 - val_loss: 2.6690e-04 - val_mse: 5.3380e-04\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 3s 26ms/step - loss: 2.5732e-04 - mse: 5.1465e-04 - val_loss: 2.3548e-04 - val_mse: 4.7095e-04\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 2s 24ms/step - loss: 2.5030e-04 - mse: 5.0060e-04 - val_loss: 2.4325e-04 - val_mse: 4.8650e-04\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 2.6119e-04 - mse: 5.2238e-04 - val_loss: 2.1586e-04 - val_mse: 4.3171e-04\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 4s 37ms/step - loss: 2.2907e-04 - mse: 4.5814e-04 - val_loss: 2.7774e-04 - val_mse: 5.5548e-04\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.2289e-04 - mse: 4.4577e-04 - val_loss: 2.1595e-04 - val_mse: 4.3190e-04\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 2s 24ms/step - loss: 2.2790e-04 - mse: 4.5581e-04 - val_loss: 3.0262e-04 - val_mse: 6.0523e-04\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 4s 36ms/step - loss: 2.2176e-04 - mse: 4.4352e-04 - val_loss: 2.7929e-04 - val_mse: 5.5859e-04\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 2.0214e-04 - mse: 4.0428e-04 - val_loss: 1.8274e-04 - val_mse: 3.6548e-04\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 2.0110e-04 - mse: 4.0221e-04 - val_loss: 1.8286e-04 - val_mse: 3.6572e-04\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 5s 46ms/step - loss: 1.9351e-04 - mse: 3.8701e-04 - val_loss: 1.8106e-04 - val_mse: 3.6213e-04\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 4s 39ms/step - loss: 1.9389e-04 - mse: 3.8779e-04 - val_loss: 1.9074e-04 - val_mse: 3.8149e-04\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 1s 14ms/step - loss: 1.8545e-04 - mse: 3.7090e-04 - val_loss: 1.9958e-04 - val_mse: 3.9917e-04\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 1s 15ms/step - loss: 1.8630e-04 - mse: 3.7261e-04 - val_loss: 1.6831e-04 - val_mse: 3.3661e-04\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 2s 15ms/step - loss: 1.9392e-04 - mse: 3.8785e-04 - val_loss: 1.5770e-04 - val_mse: 3.1539e-04\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 1.7698e-04 - mse: 3.5396e-04 - val_loss: 1.5327e-04 - val_mse: 3.0655e-04\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.7372e-04 - mse: 3.4745e-04 - val_loss: 1.5399e-04 - val_mse: 3.0798e-04\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.8856e-04 - mse: 3.7713e-04 - val_loss: 2.2588e-04 - val_mse: 4.5175e-04\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.7492e-04 - mse: 3.4983e-04 - val_loss: 1.6984e-04 - val_mse: 3.3967e-04\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.6978e-04 - mse: 3.3956e-04 - val_loss: 2.8224e-04 - val_mse: 5.6449e-04\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 1.6320e-04 - mse: 3.2640e-04 - val_loss: 1.3723e-04 - val_mse: 2.7447e-04\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 3s 17ms/step - loss: 1.6750e-04 - mse: 3.3501e-04 - val_loss: 2.4149e-04 - val_mse: 4.8299e-04\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 1s 13ms/step - loss: 1.6469e-04 - mse: 3.2939e-04 - val_loss: 1.3207e-04 - val_mse: 2.6415e-04\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 1s 12ms/step - loss: 1.5699e-04 - mse: 3.1399e-04 - val_loss: 1.3190e-04 - val_mse: 2.6380e-04\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.6118e-04 - mse: 3.2236e-04 - val_loss: 1.3388e-04 - val_mse: 2.6776e-04\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 1.5312e-04 - mse: 3.0624e-04 - val_loss: 1.6114e-04 - val_mse: 3.2228e-04\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 1s 14ms/step - loss: 1.5328e-04 - mse: 3.0656e-04 - val_loss: 1.9468e-04 - val_mse: 3.8937e-04\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 1.6015e-04 - mse: 3.2030e-04 - val_loss: 1.2460e-04 - val_mse: 2.4920e-04\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 2s 15ms/step - loss: 1.5302e-04 - mse: 3.0605e-04 - val_loss: 1.2774e-04 - val_mse: 2.5548e-04\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 1s 11ms/step - loss: 1.5426e-04 - mse: 3.0852e-04 - val_loss: 1.2927e-04 - val_mse: 2.5854e-04\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 1s 10ms/step - loss: 1.5497e-04 - mse: 3.0994e-04 - val_loss: 1.9000e-04 - val_mse: 3.8000e-04\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 3s 34ms/step - loss: 1.5740e-04 - mse: 3.1479e-04 - val_loss: 1.2935e-04 - val_mse: 2.5870e-04\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 2s 15ms/step - loss: 1.4460e-04 - mse: 2.8920e-04 - val_loss: 1.4336e-04 - val_mse: 2.8672e-04\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 1s 14ms/step - loss: 1.4923e-04 - mse: 2.9845e-04 - val_loss: 1.2309e-04 - val_mse: 2.4619e-04\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 4s 37ms/step - loss: 1.4739e-04 - mse: 2.9478e-04 - val_loss: 1.1937e-04 - val_mse: 2.3875e-04\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.6008e-04 - mse: 3.2015e-04 - val_loss: 1.8105e-04 - val_mse: 3.6209e-04\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.4325e-04 - mse: 2.8649e-04 - val_loss: 1.4629e-04 - val_mse: 2.9258e-04\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.4603e-04 - mse: 2.9206e-04 - val_loss: 1.1936e-04 - val_mse: 2.3873e-04\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 1.3830e-04 - mse: 2.7661e-04 - val_loss: 1.4047e-04 - val_mse: 2.8094e-04\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 1.4066e-04 - mse: 2.8132e-04 - val_loss: 1.1171e-04 - val_mse: 2.2341e-04\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.4196e-04 - mse: 2.8392e-04 - val_loss: 1.5934e-04 - val_mse: 3.1868e-04\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 1s 13ms/step - loss: 1.4815e-04 - mse: 2.9630e-04 - val_loss: 1.1762e-04 - val_mse: 2.3524e-04\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.4142e-04 - mse: 2.8283e-04 - val_loss: 1.5791e-04 - val_mse: 3.1582e-04\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.4389e-04 - mse: 2.8778e-04 - val_loss: 1.3650e-04 - val_mse: 2.7301e-04\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 1.3809e-04 - mse: 2.7619e-04 - val_loss: 1.0824e-04 - val_mse: 2.1648e-04\n",
      "pred.shape : (740, 1) , y_test.shape : (760,)\n",
      "3800길이의 데이터 적용 완료\n",
      " 길이: 3800, RMSE:1103.7574482595073\n",
      "train set 확인:  (3120, 4) (3120,) test set 확인:  (780, 4) (780,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "97/97 [==============================] - 3s 14ms/step - loss: 0.0101 - mse: 0.0202 - val_loss: 2.7274e-04 - val_mse: 5.4548e-04\n",
      "Epoch 2/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 3.3378e-04 - mse: 6.6757e-04 - val_loss: 2.5843e-04 - val_mse: 5.1687e-04\n",
      "Epoch 3/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.5822e-04 - mse: 5.1643e-04 - val_loss: 2.7597e-04 - val_mse: 5.5193e-04\n",
      "Epoch 4/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.4543e-04 - mse: 4.9086e-04 - val_loss: 2.9719e-04 - val_mse: 5.9438e-04\n",
      "Epoch 5/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.4750e-04 - mse: 4.9501e-04 - val_loss: 2.3696e-04 - val_mse: 4.7392e-04\n",
      "Epoch 6/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.3496e-04 - mse: 4.6992e-04 - val_loss: 2.3478e-04 - val_mse: 4.6956e-04\n",
      "Epoch 7/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.4658e-04 - mse: 4.9315e-04 - val_loss: 2.3715e-04 - val_mse: 4.7430e-04\n",
      "Epoch 8/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.1838e-04 - mse: 4.3677e-04 - val_loss: 2.5478e-04 - val_mse: 5.0957e-04\n",
      "Epoch 9/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.2023e-04 - mse: 4.4046e-04 - val_loss: 2.0659e-04 - val_mse: 4.1319e-04\n",
      "Epoch 10/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.0882e-04 - mse: 4.1764e-04 - val_loss: 2.7278e-04 - val_mse: 5.4556e-04\n",
      "Epoch 11/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.0901e-04 - mse: 4.1801e-04 - val_loss: 1.9086e-04 - val_mse: 3.8172e-04\n",
      "Epoch 12/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.0962e-04 - mse: 4.1923e-04 - val_loss: 1.8683e-04 - val_mse: 3.7365e-04\n",
      "Epoch 13/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 2.0093e-04 - mse: 4.0186e-04 - val_loss: 1.8637e-04 - val_mse: 3.7275e-04\n",
      "Epoch 14/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.9465e-04 - mse: 3.8930e-04 - val_loss: 1.8157e-04 - val_mse: 3.6314e-04\n",
      "Epoch 15/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.9975e-04 - mse: 3.9949e-04 - val_loss: 1.8649e-04 - val_mse: 3.7298e-04\n",
      "Epoch 16/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8328e-04 - mse: 3.6655e-04 - val_loss: 1.6695e-04 - val_mse: 3.3391e-04\n",
      "Epoch 17/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8663e-04 - mse: 3.7326e-04 - val_loss: 1.6428e-04 - val_mse: 3.2857e-04\n",
      "Epoch 18/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8773e-04 - mse: 3.7546e-04 - val_loss: 1.6101e-04 - val_mse: 3.2202e-04\n",
      "Epoch 19/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.7598e-04 - mse: 3.5196e-04 - val_loss: 1.7106e-04 - val_mse: 3.4211e-04\n",
      "Epoch 20/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8749e-04 - mse: 3.7498e-04 - val_loss: 2.3155e-04 - val_mse: 4.6310e-04\n",
      "Epoch 21/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.7170e-04 - mse: 3.4341e-04 - val_loss: 1.9216e-04 - val_mse: 3.8432e-04\n",
      "Epoch 22/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6857e-04 - mse: 3.3714e-04 - val_loss: 1.4382e-04 - val_mse: 2.8764e-04\n",
      "Epoch 23/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6362e-04 - mse: 3.2725e-04 - val_loss: 1.3862e-04 - val_mse: 2.7724e-04\n",
      "Epoch 24/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6244e-04 - mse: 3.2488e-04 - val_loss: 1.8438e-04 - val_mse: 3.6877e-04\n",
      "Epoch 25/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6465e-04 - mse: 3.2929e-04 - val_loss: 1.4443e-04 - val_mse: 2.8885e-04\n",
      "Epoch 26/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.5752e-04 - mse: 3.1503e-04 - val_loss: 2.1774e-04 - val_mse: 4.3548e-04\n",
      "Epoch 27/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6456e-04 - mse: 3.2912e-04 - val_loss: 1.5428e-04 - val_mse: 3.0857e-04\n",
      "Epoch 28/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.5120e-04 - mse: 3.0240e-04 - val_loss: 1.3902e-04 - val_mse: 2.7804e-04\n",
      "Epoch 29/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.4582e-04 - mse: 2.9165e-04 - val_loss: 1.2240e-04 - val_mse: 2.4481e-04\n",
      "Epoch 30/50\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.4870e-04 - mse: 2.9741e-04 - val_loss: 1.6412e-04 - val_mse: 3.2825e-04\n",
      "Epoch 31/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.6445e-04 - mse: 3.2891e-04 - val_loss: 2.3900e-04 - val_mse: 4.7799e-04\n",
      "Epoch 32/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.3901e-04 - mse: 2.7803e-04 - val_loss: 1.3139e-04 - val_mse: 2.6279e-04\n",
      "Epoch 33/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.4070e-04 - mse: 2.8139e-04 - val_loss: 1.2071e-04 - val_mse: 2.4143e-04\n",
      "Epoch 34/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.3500e-04 - mse: 2.7001e-04 - val_loss: 1.2469e-04 - val_mse: 2.4938e-04\n",
      "Epoch 35/50\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.3724e-04 - mse: 2.7449e-04 - val_loss: 2.9644e-04 - val_mse: 5.9288e-04\n",
      "Epoch 36/50\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2354e-04 - mse: 2.4707e-04 - val_loss: 1.3565e-04 - val_mse: 2.7130e-04\n",
      "Epoch 37/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1799e-04 - mse: 2.3597e-04 - val_loss: 8.7360e-05 - val_mse: 1.7472e-04\n",
      "Epoch 38/50\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1656e-04 - mse: 2.3313e-04 - val_loss: 8.3786e-05 - val_mse: 1.6757e-04\n",
      "Epoch 39/50\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1497e-04 - mse: 2.2994e-04 - val_loss: 9.3125e-05 - val_mse: 1.8625e-04\n",
      "Epoch 40/50\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.2483e-04 - mse: 2.4967e-04 - val_loss: 1.2592e-04 - val_mse: 2.5185e-04\n",
      "Epoch 41/50\n",
      "97/97 [==============================] - 2s 15ms/step - loss: 1.0769e-04 - mse: 2.1539e-04 - val_loss: 7.9111e-05 - val_mse: 1.5822e-04\n",
      "Epoch 42/50\n",
      "97/97 [==============================] - 2s 17ms/step - loss: 1.1482e-04 - mse: 2.2964e-04 - val_loss: 1.2432e-04 - val_mse: 2.4863e-04\n",
      "Epoch 43/50\n",
      "97/97 [==============================] - 2s 16ms/step - loss: 1.1280e-04 - mse: 2.2560e-04 - val_loss: 8.9433e-05 - val_mse: 1.7887e-04\n",
      "Epoch 44/50\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.1494e-04 - mse: 2.2987e-04 - val_loss: 1.0793e-04 - val_mse: 2.1585e-04\n",
      "Epoch 45/50\n",
      "97/97 [==============================] - 2s 15ms/step - loss: 1.0900e-04 - mse: 2.1800e-04 - val_loss: 7.7781e-05 - val_mse: 1.5556e-04\n",
      "Epoch 46/50\n",
      "97/97 [==============================] - 2s 15ms/step - loss: 1.0673e-04 - mse: 2.1346e-04 - val_loss: 7.4885e-05 - val_mse: 1.4977e-04\n",
      "Epoch 47/50\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0334e-04 - mse: 2.0668e-04 - val_loss: 7.6095e-05 - val_mse: 1.5219e-04\n",
      "Epoch 48/50\n",
      "97/97 [==============================] - 2s 15ms/step - loss: 1.1191e-04 - mse: 2.2382e-04 - val_loss: 1.1574e-04 - val_mse: 2.3149e-04\n",
      "Epoch 49/50\n",
      "97/97 [==============================] - 2s 17ms/step - loss: 1.0998e-04 - mse: 2.1995e-04 - val_loss: 1.3328e-04 - val_mse: 2.6656e-04\n",
      "Epoch 50/50\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 1.1089e-04 - mse: 2.2178e-04 - val_loss: 7.3681e-05 - val_mse: 1.4736e-04\n",
      "pred.shape : (760, 1) , y_test.shape : (780,)\n",
      "3900길이의 데이터 적용 완료\n",
      " 길이: 3900, RMSE:927.0544520119569\n",
      "train set 확인:  (3200, 4) (3200,) test set 확인:  (800, 4) (800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 6s 22ms/step - loss: 0.0052 - mse: 0.0103 - val_loss: 3.5281e-04 - val_mse: 7.0562e-04\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 3.0464e-04 - mse: 6.0927e-04 - val_loss: 4.1435e-04 - val_mse: 8.2870e-04\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.9761e-04 - mse: 5.9522e-04 - val_loss: 2.6613e-04 - val_mse: 5.3225e-04\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.8042e-04 - mse: 5.6083e-04 - val_loss: 2.5748e-04 - val_mse: 5.1497e-04\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.7355e-04 - mse: 5.4710e-04 - val_loss: 2.9261e-04 - val_mse: 5.8523e-04\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 2.5584e-04 - mse: 5.1169e-04 - val_loss: 2.4666e-04 - val_mse: 4.9331e-04\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 2.4774e-04 - mse: 4.9547e-04 - val_loss: 2.3416e-04 - val_mse: 4.6832e-04\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 2.4864e-04 - mse: 4.9728e-04 - val_loss: 2.5271e-04 - val_mse: 5.0542e-04\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.3164e-04 - mse: 4.6327e-04 - val_loss: 2.2808e-04 - val_mse: 4.5617e-04\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.2793e-04 - mse: 4.5585e-04 - val_loss: 2.5582e-04 - val_mse: 5.1164e-04\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.1745e-04 - mse: 4.3491e-04 - val_loss: 2.6096e-04 - val_mse: 5.2191e-04\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.1177e-04 - mse: 4.2353e-04 - val_loss: 2.1899e-04 - val_mse: 4.3797e-04\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.9748e-04 - mse: 3.9496e-04 - val_loss: 1.8772e-04 - val_mse: 3.7545e-04\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.0059e-04 - mse: 4.0118e-04 - val_loss: 1.6905e-04 - val_mse: 3.3811e-04\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.8721e-04 - mse: 3.7442e-04 - val_loss: 1.6348e-04 - val_mse: 3.2695e-04\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.7522e-04 - mse: 3.5044e-04 - val_loss: 1.8944e-04 - val_mse: 3.7887e-04\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.7617e-04 - mse: 3.5234e-04 - val_loss: 1.9671e-04 - val_mse: 3.9342e-04\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.7910e-04 - mse: 3.5820e-04 - val_loss: 2.4609e-04 - val_mse: 4.9218e-04\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.8460e-04 - mse: 3.6920e-04 - val_loss: 1.7932e-04 - val_mse: 3.5863e-04\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.8151e-04 - mse: 3.6301e-04 - val_loss: 1.3770e-04 - val_mse: 2.7540e-04\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.6349e-04 - mse: 3.2698e-04 - val_loss: 1.7567e-04 - val_mse: 3.5135e-04\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.6024e-04 - mse: 3.2048e-04 - val_loss: 2.2691e-04 - val_mse: 4.5381e-04\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.5128e-04 - mse: 3.0255e-04 - val_loss: 1.5086e-04 - val_mse: 3.0171e-04\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.4557e-04 - mse: 2.9113e-04 - val_loss: 1.4038e-04 - val_mse: 2.8076e-04\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.4885e-04 - mse: 2.9771e-04 - val_loss: 1.2380e-04 - val_mse: 2.4761e-04\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 1.4363e-04 - mse: 2.8725e-04 - val_loss: 1.6638e-04 - val_mse: 3.3275e-04\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 1.4533e-04 - mse: 2.9066e-04 - val_loss: 1.3684e-04 - val_mse: 2.7367e-04\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.5063e-04 - mse: 3.0125e-04 - val_loss: 1.8078e-04 - val_mse: 3.6156e-04\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 1.3876e-04 - mse: 2.7751e-04 - val_loss: 1.1500e-04 - val_mse: 2.3001e-04\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.4797e-04 - mse: 2.9593e-04 - val_loss: 2.0765e-04 - val_mse: 4.1530e-04\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.4048e-04 - mse: 2.8097e-04 - val_loss: 1.1751e-04 - val_mse: 2.3503e-04\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.3704e-04 - mse: 2.7408e-04 - val_loss: 1.1601e-04 - val_mse: 2.3202e-04\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.3576e-04 - mse: 2.7152e-04 - val_loss: 1.1299e-04 - val_mse: 2.2598e-04\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.4471e-04 - mse: 2.8942e-04 - val_loss: 2.0405e-04 - val_mse: 4.0810e-04\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.3633e-04 - mse: 2.7265e-04 - val_loss: 1.4651e-04 - val_mse: 2.9301e-04\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.3732e-04 - mse: 2.7465e-04 - val_loss: 1.1862e-04 - val_mse: 2.3724e-04\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.3137e-04 - mse: 2.6273e-04 - val_loss: 2.5183e-04 - val_mse: 5.0366e-04\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.2905e-04 - mse: 2.5810e-04 - val_loss: 1.0412e-04 - val_mse: 2.0823e-04\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.3407e-04 - mse: 2.6815e-04 - val_loss: 1.1299e-04 - val_mse: 2.2597e-04\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.2558e-04 - mse: 2.5115e-04 - val_loss: 1.8669e-04 - val_mse: 3.7338e-04\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.3595e-04 - mse: 2.7190e-04 - val_loss: 1.8446e-04 - val_mse: 3.6892e-04\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.3006e-04 - mse: 2.6012e-04 - val_loss: 1.2629e-04 - val_mse: 2.5257e-04\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.2918e-04 - mse: 2.5836e-04 - val_loss: 1.0736e-04 - val_mse: 2.1472e-04\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.2261e-04 - mse: 2.4522e-04 - val_loss: 1.1629e-04 - val_mse: 2.3258e-04\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.2337e-04 - mse: 2.4674e-04 - val_loss: 1.0766e-04 - val_mse: 2.1533e-04\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.3556e-04 - mse: 2.7113e-04 - val_loss: 1.1041e-04 - val_mse: 2.2081e-04\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 1.1945e-04 - mse: 2.3891e-04 - val_loss: 9.8052e-05 - val_mse: 1.9610e-04\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.4776e-04 - mse: 2.9553e-04 - val_loss: 1.8837e-04 - val_mse: 3.7674e-04\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.2114e-04 - mse: 2.4229e-04 - val_loss: 1.0191e-04 - val_mse: 2.0383e-04\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1843e-04 - mse: 2.3685e-04 - val_loss: 1.0529e-04 - val_mse: 2.1058e-04\n",
      "pred.shape : (780, 1) , y_test.shape : (800,)\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:1141.2562457375145\n",
      "train set 확인:  (3280, 4) (3280,) test set 확인:  (820, 4) (820,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102/102 [==============================] - 6s 24ms/step - loss: 0.0076 - mse: 0.0153 - val_loss: 2.4378e-04 - val_mse: 4.8756e-04\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 2.8069e-04 - mse: 5.6139e-04 - val_loss: 3.1035e-04 - val_mse: 6.2070e-04\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 2.3718e-04 - mse: 4.7437e-04 - val_loss: 2.3072e-04 - val_mse: 4.6144e-04\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 2.3636e-04 - mse: 4.7271e-04 - val_loss: 2.2560e-04 - val_mse: 4.5119e-04\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 2s 20ms/step - loss: 2.1810e-04 - mse: 4.3619e-04 - val_loss: 2.1824e-04 - val_mse: 4.3649e-04\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 2.2352e-04 - mse: 4.4705e-04 - val_loss: 2.6047e-04 - val_mse: 5.2094e-04\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 2s 14ms/step - loss: 2.1481e-04 - mse: 4.2962e-04 - val_loss: 2.1668e-04 - val_mse: 4.3335e-04\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 2.0021e-04 - mse: 4.0042e-04 - val_loss: 2.0155e-04 - val_mse: 4.0310e-04\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.9383e-04 - mse: 3.8767e-04 - val_loss: 1.8526e-04 - val_mse: 3.7052e-04\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.9091e-04 - mse: 3.8183e-04 - val_loss: 1.7263e-04 - val_mse: 3.4526e-04\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 1.8378e-04 - mse: 3.6756e-04 - val_loss: 1.6609e-04 - val_mse: 3.3217e-04\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.7502e-04 - mse: 3.5004e-04 - val_loss: 1.7017e-04 - val_mse: 3.4034e-04\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.8255e-04 - mse: 3.6509e-04 - val_loss: 1.6191e-04 - val_mse: 3.2381e-04\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 1.6668e-04 - mse: 3.3336e-04 - val_loss: 4.5699e-04 - val_mse: 9.1398e-04\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.6120e-04 - mse: 3.2241e-04 - val_loss: 1.3769e-04 - val_mse: 2.7539e-04\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.4476e-04 - mse: 2.8952e-04 - val_loss: 1.2728e-04 - val_mse: 2.5457e-04\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.5874e-04 - mse: 3.1748e-04 - val_loss: 2.0029e-04 - val_mse: 4.0058e-04\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.4132e-04 - mse: 2.8263e-04 - val_loss: 1.2959e-04 - val_mse: 2.5919e-04\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.3397e-04 - mse: 2.6794e-04 - val_loss: 1.3031e-04 - val_mse: 2.6062e-04\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.2763e-04 - mse: 2.5526e-04 - val_loss: 1.2501e-04 - val_mse: 2.5003e-04\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.2778e-04 - mse: 2.5555e-04 - val_loss: 1.1583e-04 - val_mse: 2.3166e-04\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.2129e-04 - mse: 2.4258e-04 - val_loss: 1.0660e-04 - val_mse: 2.1320e-04\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.2067e-04 - mse: 2.4134e-04 - val_loss: 1.8169e-04 - val_mse: 3.6337e-04\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.3239e-04 - mse: 2.6478e-04 - val_loss: 1.0155e-04 - val_mse: 2.0309e-04\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.2125e-04 - mse: 2.4251e-04 - val_loss: 1.0199e-04 - val_mse: 2.0399e-04\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.2475e-04 - mse: 2.4949e-04 - val_loss: 1.0082e-04 - val_mse: 2.0164e-04\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.2035e-04 - mse: 2.4070e-04 - val_loss: 1.0383e-04 - val_mse: 2.0766e-04\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 1.2628e-04 - mse: 2.5255e-04 - val_loss: 1.0440e-04 - val_mse: 2.0880e-04\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 2s 19ms/step - loss: 1.1507e-04 - mse: 2.3015e-04 - val_loss: 9.2988e-05 - val_mse: 1.8598e-04\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 1.0954e-04 - mse: 2.1908e-04 - val_loss: 1.3508e-04 - val_mse: 2.7016e-04\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.1334e-04 - mse: 2.2668e-04 - val_loss: 9.5257e-05 - val_mse: 1.9051e-04\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.1071e-04 - mse: 2.2142e-04 - val_loss: 9.0037e-05 - val_mse: 1.8007e-04\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 1.0848e-04 - mse: 2.1696e-04 - val_loss: 8.6011e-05 - val_mse: 1.7202e-04\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.0674e-04 - mse: 2.1349e-04 - val_loss: 1.1061e-04 - val_mse: 2.2122e-04\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.0613e-04 - mse: 2.1226e-04 - val_loss: 1.0290e-04 - val_mse: 2.0580e-04\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.0573e-04 - mse: 2.1146e-04 - val_loss: 3.2144e-04 - val_mse: 6.4289e-04\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.0285e-04 - mse: 2.0570e-04 - val_loss: 1.0832e-04 - val_mse: 2.1664e-04\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 1.0502e-04 - mse: 2.1003e-04 - val_loss: 7.8608e-05 - val_mse: 1.5722e-04\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.0768e-04 - mse: 2.1537e-04 - val_loss: 9.3122e-05 - val_mse: 1.8624e-04\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 9.9080e-05 - mse: 1.9816e-04 - val_loss: 1.3142e-04 - val_mse: 2.6283e-04\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.0368e-04 - mse: 2.0737e-04 - val_loss: 7.9115e-05 - val_mse: 1.5823e-04\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 9.8922e-05 - mse: 1.9784e-04 - val_loss: 9.7631e-05 - val_mse: 1.9526e-04\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 2s 14ms/step - loss: 9.5172e-05 - mse: 1.9034e-04 - val_loss: 7.9296e-05 - val_mse: 1.5859e-04\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.0547e-04 - mse: 2.1095e-04 - val_loss: 1.4960e-04 - val_mse: 2.9920e-04\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 1.0759e-04 - mse: 2.1517e-04 - val_loss: 8.1319e-05 - val_mse: 1.6264e-04\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 9.4976e-05 - mse: 1.8995e-04 - val_loss: 1.0276e-04 - val_mse: 2.0552e-04\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 1.0110e-04 - mse: 2.0221e-04 - val_loss: 7.3218e-05 - val_mse: 1.4644e-04\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 2s 14ms/step - loss: 9.7516e-05 - mse: 1.9503e-04 - val_loss: 9.9350e-05 - val_mse: 1.9870e-04\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 2s 14ms/step - loss: 1.0364e-04 - mse: 2.0728e-04 - val_loss: 7.2695e-05 - val_mse: 1.4539e-04\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 2s 15ms/step - loss: 9.8591e-05 - mse: 1.9718e-04 - val_loss: 7.7179e-05 - val_mse: 1.5436e-04\n",
      "pred.shape : (800, 1) , y_test.shape : (820,)\n",
      "4100길이의 데이터 적용 완료\n",
      " 길이: 4100, RMSE:1025.0851638414542\n",
      "train set 확인:  (3360, 4) (3360,) test set 확인:  (840, 4) (840,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 6s 23ms/step - loss: 0.0040 - mse: 0.0079 - val_loss: 2.4888e-04 - val_mse: 4.9776e-04\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.8998e-04 - mse: 5.7995e-04 - val_loss: 3.0415e-04 - val_mse: 6.0829e-04\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.2993e-04 - mse: 4.5986e-04 - val_loss: 2.2854e-04 - val_mse: 4.5709e-04\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.0741e-04 - mse: 4.1482e-04 - val_loss: 2.2282e-04 - val_mse: 4.4564e-04\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 2.0779e-04 - mse: 4.1557e-04 - val_loss: 2.2791e-04 - val_mse: 4.5583e-04\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.0640e-04 - mse: 4.1279e-04 - val_loss: 2.3563e-04 - val_mse: 4.7125e-04\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 1.9818e-04 - mse: 3.9637e-04 - val_loss: 2.1362e-04 - val_mse: 4.2723e-04\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.8847e-04 - mse: 3.7695e-04 - val_loss: 2.2804e-04 - val_mse: 4.5609e-04\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.9616e-04 - mse: 3.9232e-04 - val_loss: 2.6183e-04 - val_mse: 5.2367e-04\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.7863e-04 - mse: 3.5726e-04 - val_loss: 2.0337e-04 - val_mse: 4.0674e-04\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7371e-04 - mse: 3.4743e-04 - val_loss: 2.1390e-04 - val_mse: 4.2780e-04\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.9360e-04 - mse: 3.8720e-04 - val_loss: 1.6822e-04 - val_mse: 3.3644e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6831e-04 - mse: 3.3661e-04 - val_loss: 1.6494e-04 - val_mse: 3.2988e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5388e-04 - mse: 3.0776e-04 - val_loss: 2.5337e-04 - val_mse: 5.0675e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 1.6057e-04 - mse: 3.2114e-04 - val_loss: 1.9514e-04 - val_mse: 3.9028e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4601e-04 - mse: 2.9201e-04 - val_loss: 2.0095e-04 - val_mse: 4.0191e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4162e-04 - mse: 2.8325e-04 - val_loss: 1.2983e-04 - val_mse: 2.5966e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3400e-04 - mse: 2.6799e-04 - val_loss: 1.2420e-04 - val_mse: 2.4840e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3441e-04 - mse: 2.6882e-04 - val_loss: 2.0008e-04 - val_mse: 4.0017e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4067e-04 - mse: 2.8134e-04 - val_loss: 1.3195e-04 - val_mse: 2.6389e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.2649e-04 - mse: 2.5299e-04 - val_loss: 1.1151e-04 - val_mse: 2.2302e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.2512e-04 - mse: 2.5024e-04 - val_loss: 1.1857e-04 - val_mse: 2.3714e-04\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.2006e-04 - mse: 2.4012e-04 - val_loss: 1.1130e-04 - val_mse: 2.2261e-04\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.1497e-04 - mse: 2.2993e-04 - val_loss: 1.0787e-04 - val_mse: 2.1575e-04\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.1543e-04 - mse: 2.3086e-04 - val_loss: 9.6793e-05 - val_mse: 1.9359e-04\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.0992e-04 - mse: 2.1983e-04 - val_loss: 9.3854e-05 - val_mse: 1.8771e-04\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.0492e-04 - mse: 2.0985e-04 - val_loss: 1.5616e-04 - val_mse: 3.1231e-04\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.0445e-04 - mse: 2.0890e-04 - val_loss: 8.8362e-05 - val_mse: 1.7672e-04\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.0074e-04 - mse: 2.0149e-04 - val_loss: 8.7271e-05 - val_mse: 1.7454e-04\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.0550e-04 - mse: 2.1101e-04 - val_loss: 8.4809e-05 - val_mse: 1.6962e-04\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 9.9473e-05 - mse: 1.9895e-04 - val_loss: 8.2661e-05 - val_mse: 1.6532e-04\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 9.5540e-05 - mse: 1.9108e-04 - val_loss: 9.6289e-05 - val_mse: 1.9258e-04\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.5222e-05 - mse: 1.9044e-04 - val_loss: 8.9142e-05 - val_mse: 1.7828e-04\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.3230e-05 - mse: 1.8646e-04 - val_loss: 8.9973e-05 - val_mse: 1.7995e-04\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.5681e-05 - mse: 1.9136e-04 - val_loss: 7.8036e-05 - val_mse: 1.5607e-04\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.0698e-04 - mse: 2.1396e-04 - val_loss: 1.0958e-04 - val_mse: 2.1917e-04\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.8806e-05 - mse: 1.9761e-04 - val_loss: 1.0485e-04 - val_mse: 2.0971e-04\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 2s 13ms/step - loss: 9.0483e-05 - mse: 1.8097e-04 - val_loss: 8.2119e-05 - val_mse: 1.6424e-04\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 2s 13ms/step - loss: 9.2433e-05 - mse: 1.8487e-04 - val_loss: 8.2369e-05 - val_mse: 1.6474e-04\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 1.0034e-04 - mse: 2.0067e-04 - val_loss: 1.7816e-04 - val_mse: 3.5632e-04\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 9.7276e-05 - mse: 1.9455e-04 - val_loss: 8.9675e-05 - val_mse: 1.7935e-04\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.7806e-05 - mse: 1.9561e-04 - val_loss: 8.2544e-05 - val_mse: 1.6509e-04\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 9.4164e-05 - mse: 1.8833e-04 - val_loss: 9.3888e-05 - val_mse: 1.8778e-04\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 9.4297e-05 - mse: 1.8859e-04 - val_loss: 7.3966e-05 - val_mse: 1.4793e-04\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 9.2986e-05 - mse: 1.8597e-04 - val_loss: 7.1893e-05 - val_mse: 1.4379e-04\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 8.5634e-05 - mse: 1.7127e-04 - val_loss: 1.3642e-04 - val_mse: 2.7283e-04\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 8.7781e-05 - mse: 1.7556e-04 - val_loss: 7.2398e-05 - val_mse: 1.4480e-04\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.0745e-05 - mse: 1.8149e-04 - val_loss: 1.0405e-04 - val_mse: 2.0811e-04\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 9.2855e-05 - mse: 1.8571e-04 - val_loss: 1.1689e-04 - val_mse: 2.3378e-04\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 8.8379e-05 - mse: 1.7676e-04 - val_loss: 6.8146e-05 - val_mse: 1.3629e-04\n",
      "pred.shape : (820, 1) , y_test.shape : (840,)\n",
      "4200길이의 데이터 적용 완료\n",
      " 길이: 4200, RMSE:995.6080381356913\n",
      "train set 확인:  (3440, 4) (3440,) test set 확인:  (860, 4) (860,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "107/107 [==============================] - 6s 21ms/step - loss: 0.0055 - mse: 0.0111 - val_loss: 2.2995e-04 - val_mse: 4.5990e-04\n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 2.5009e-04 - mse: 5.0018e-04 - val_loss: 2.2843e-04 - val_mse: 4.5686e-04\n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.7517e-04 - mse: 3.5034e-04 - val_loss: 1.8282e-04 - val_mse: 3.6563e-04\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.6302e-04 - mse: 3.2605e-04 - val_loss: 1.6957e-04 - val_mse: 3.3914e-04\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.6364e-04 - mse: 3.2727e-04 - val_loss: 1.6717e-04 - val_mse: 3.3435e-04\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.6180e-04 - mse: 3.2360e-04 - val_loss: 1.6292e-04 - val_mse: 3.2583e-04\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 1.5574e-04 - mse: 3.1148e-04 - val_loss: 1.6836e-04 - val_mse: 3.3672e-04\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 2s 16ms/step - loss: 1.5249e-04 - mse: 3.0498e-04 - val_loss: 2.1066e-04 - val_mse: 4.2132e-04\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 1.5111e-04 - mse: 3.0221e-04 - val_loss: 1.6124e-04 - val_mse: 3.2249e-04\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.4885e-04 - mse: 2.9769e-04 - val_loss: 2.2786e-04 - val_mse: 4.5572e-04\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.4522e-04 - mse: 2.9045e-04 - val_loss: 1.7292e-04 - val_mse: 3.4585e-04\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.4584e-04 - mse: 2.9167e-04 - val_loss: 1.6107e-04 - val_mse: 3.2213e-04\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.4502e-04 - mse: 2.9004e-04 - val_loss: 1.8307e-04 - val_mse: 3.6615e-04\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.4196e-04 - mse: 2.8393e-04 - val_loss: 1.3624e-04 - val_mse: 2.7248e-04\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.3271e-04 - mse: 2.6542e-04 - val_loss: 1.5989e-04 - val_mse: 3.1978e-04\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.2861e-04 - mse: 2.5721e-04 - val_loss: 1.2852e-04 - val_mse: 2.5705e-04\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.3060e-04 - mse: 2.6119e-04 - val_loss: 2.3466e-04 - val_mse: 4.6932e-04\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.3591e-04 - mse: 2.7182e-04 - val_loss: 1.3062e-04 - val_mse: 2.6125e-04\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.2459e-04 - mse: 2.4919e-04 - val_loss: 1.9426e-04 - val_mse: 3.8852e-04\n",
      "Epoch 20/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.2742e-04 - mse: 2.5484e-04 - val_loss: 1.2778e-04 - val_mse: 2.5556e-04\n",
      "Epoch 21/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.2218e-04 - mse: 2.4435e-04 - val_loss: 1.2371e-04 - val_mse: 2.4741e-04\n",
      "Epoch 22/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.1846e-04 - mse: 2.3692e-04 - val_loss: 1.2031e-04 - val_mse: 2.4062e-04\n",
      "Epoch 23/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.2104e-04 - mse: 2.4209e-04 - val_loss: 1.9794e-04 - val_mse: 3.9588e-04\n",
      "Epoch 24/50\n",
      "107/107 [==============================] - 2s 13ms/step - loss: 1.1604e-04 - mse: 2.3207e-04 - val_loss: 1.1401e-04 - val_mse: 2.2803e-04\n",
      "Epoch 25/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.1722e-04 - mse: 2.3444e-04 - val_loss: 1.2773e-04 - val_mse: 2.5547e-04\n",
      "Epoch 26/50\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 1.1141e-04 - mse: 2.2281e-04 - val_loss: 1.0937e-04 - val_mse: 2.1874e-04\n",
      "Epoch 27/50\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 1.2029e-04 - mse: 2.4057e-04 - val_loss: 1.1070e-04 - val_mse: 2.2139e-04\n",
      "Epoch 28/50\n",
      "107/107 [==============================] - 2s 16ms/step - loss: 1.2180e-04 - mse: 2.4360e-04 - val_loss: 1.0483e-04 - val_mse: 2.0966e-04\n",
      "Epoch 29/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.1261e-04 - mse: 2.2523e-04 - val_loss: 1.3120e-04 - val_mse: 2.6240e-04\n",
      "Epoch 30/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.2130e-04 - mse: 2.4260e-04 - val_loss: 2.5820e-04 - val_mse: 5.1640e-04\n",
      "Epoch 31/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.1263e-04 - mse: 2.2526e-04 - val_loss: 1.1445e-04 - val_mse: 2.2890e-04\n",
      "Epoch 32/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.0530e-04 - mse: 2.1060e-04 - val_loss: 1.2577e-04 - val_mse: 2.5153e-04\n",
      "Epoch 33/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.0668e-04 - mse: 2.1337e-04 - val_loss: 1.0031e-04 - val_mse: 2.0062e-04\n",
      "Epoch 34/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 1.0994e-04 - mse: 2.1988e-04 - val_loss: 1.1984e-04 - val_mse: 2.3968e-04\n",
      "Epoch 35/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.0055e-04 - mse: 2.0110e-04 - val_loss: 1.1805e-04 - val_mse: 2.3610e-04\n",
      "Epoch 36/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.0016e-04 - mse: 2.0031e-04 - val_loss: 9.0980e-05 - val_mse: 1.8196e-04\n",
      "Epoch 37/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.0161e-04 - mse: 2.0322e-04 - val_loss: 9.1547e-05 - val_mse: 1.8309e-04\n",
      "Epoch 38/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 9.6355e-05 - mse: 1.9271e-04 - val_loss: 8.7232e-05 - val_mse: 1.7446e-04\n",
      "Epoch 39/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 9.6908e-05 - mse: 1.9382e-04 - val_loss: 9.8553e-05 - val_mse: 1.9711e-04\n",
      "Epoch 40/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 9.6483e-05 - mse: 1.9297e-04 - val_loss: 1.0046e-04 - val_mse: 2.0092e-04\n",
      "Epoch 41/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 1.0889e-04 - mse: 2.1777e-04 - val_loss: 1.1349e-04 - val_mse: 2.2699e-04\n",
      "Epoch 42/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 9.7041e-05 - mse: 1.9408e-04 - val_loss: 8.2604e-05 - val_mse: 1.6521e-04\n",
      "Epoch 43/50\n",
      "107/107 [==============================] - 2s 18ms/step - loss: 9.7661e-05 - mse: 1.9532e-04 - val_loss: 7.9646e-05 - val_mse: 1.5929e-04\n",
      "Epoch 44/50\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 1.0326e-04 - mse: 2.0653e-04 - val_loss: 1.1452e-04 - val_mse: 2.2904e-04\n",
      "Epoch 45/50\n",
      "107/107 [==============================] - 2s 16ms/step - loss: 9.0095e-05 - mse: 1.8019e-04 - val_loss: 7.7895e-05 - val_mse: 1.5579e-04\n",
      "Epoch 46/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 9.4021e-05 - mse: 1.8804e-04 - val_loss: 8.3428e-05 - val_mse: 1.6686e-04\n",
      "Epoch 47/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 9.1386e-05 - mse: 1.8277e-04 - val_loss: 9.2563e-05 - val_mse: 1.8513e-04\n",
      "Epoch 48/50\n",
      "107/107 [==============================] - 2s 13ms/step - loss: 9.7358e-05 - mse: 1.9472e-04 - val_loss: 8.3113e-05 - val_mse: 1.6623e-04\n",
      "Epoch 49/50\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 8.9510e-05 - mse: 1.7902e-04 - val_loss: 8.2758e-05 - val_mse: 1.6552e-04\n",
      "Epoch 50/50\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 8.9031e-05 - mse: 1.7806e-04 - val_loss: 7.2473e-05 - val_mse: 1.4495e-04\n",
      "pred.shape : (840, 1) , y_test.shape : (860,)\n",
      "4300길이의 데이터 적용 완료\n",
      " 길이: 4300, RMSE:1081.4743433103451\n",
      "train set 확인:  (3520, 4) (3520,) test set 확인:  (880, 4) (880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - 7s 22ms/step - loss: 0.0072 - mse: 0.0144 - val_loss: 1.6383e-04 - val_mse: 3.2767e-04\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 1.9890e-04 - mse: 3.9781e-04 - val_loss: 2.0847e-04 - val_mse: 4.1694e-04\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 1.6861e-04 - mse: 3.3722e-04 - val_loss: 1.5841e-04 - val_mse: 3.1681e-04\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 1.5441e-04 - mse: 3.0881e-04 - val_loss: 1.5945e-04 - val_mse: 3.1889e-04\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 1.4832e-04 - mse: 2.9664e-04 - val_loss: 1.4748e-04 - val_mse: 2.9496e-04\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 1.4173e-04 - mse: 2.8345e-04 - val_loss: 1.4523e-04 - val_mse: 2.9046e-04\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 1.3849e-04 - mse: 2.7697e-04 - val_loss: 1.3761e-04 - val_mse: 2.7521e-04\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 1.2729e-04 - mse: 2.5457e-04 - val_loss: 1.3816e-04 - val_mse: 2.7631e-04\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 1.3035e-04 - mse: 2.6070e-04 - val_loss: 1.3551e-04 - val_mse: 2.7102e-04\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 1.2903e-04 - mse: 2.5806e-04 - val_loss: 1.8370e-04 - val_mse: 3.6740e-04\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 1.2496e-04 - mse: 2.4992e-04 - val_loss: 1.8037e-04 - val_mse: 3.6074e-04\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 1.1881e-04 - mse: 2.3761e-04 - val_loss: 1.1984e-04 - val_mse: 2.3967e-04\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 1.2509e-04 - mse: 2.5018e-04 - val_loss: 1.4305e-04 - val_mse: 2.8609e-04\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 1.1282e-04 - mse: 2.2564e-04 - val_loss: 1.2519e-04 - val_mse: 2.5037e-04\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.0880e-04 - mse: 2.1759e-04 - val_loss: 1.2326e-04 - val_mse: 2.4652e-04\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.0592e-04 - mse: 2.1183e-04 - val_loss: 1.0458e-04 - val_mse: 2.0915e-04\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.1032e-04 - mse: 2.2065e-04 - val_loss: 1.1627e-04 - val_mse: 2.3254e-04\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 1.0559e-04 - mse: 2.1119e-04 - val_loss: 1.0120e-04 - val_mse: 2.0240e-04\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 1.0165e-04 - mse: 2.0330e-04 - val_loss: 1.3945e-04 - val_mse: 2.7891e-04\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.0368e-04 - mse: 2.0735e-04 - val_loss: 9.7183e-05 - val_mse: 1.9437e-04\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 9.6562e-05 - mse: 1.9312e-04 - val_loss: 8.9706e-05 - val_mse: 1.7941e-04\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 9.9431e-05 - mse: 1.9886e-04 - val_loss: 1.1735e-04 - val_mse: 2.3469e-04\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 9.5035e-05 - mse: 1.9007e-04 - val_loss: 1.4820e-04 - val_mse: 2.9640e-04\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 9.5241e-05 - mse: 1.9048e-04 - val_loss: 1.5967e-04 - val_mse: 3.1934e-04\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 9.3192e-05 - mse: 1.8638e-04 - val_loss: 8.2803e-05 - val_mse: 1.6561e-04\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 8.8439e-05 - mse: 1.7688e-04 - val_loss: 8.4175e-05 - val_mse: 1.6835e-04\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 8.6094e-05 - mse: 1.7219e-04 - val_loss: 7.7031e-05 - val_mse: 1.5406e-04\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 8.3911e-05 - mse: 1.6782e-04 - val_loss: 1.3236e-04 - val_mse: 2.6472e-04\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 8.5740e-05 - mse: 1.7148e-04 - val_loss: 1.3072e-04 - val_mse: 2.6144e-04\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 7.9572e-05 - mse: 1.5914e-04 - val_loss: 8.4547e-05 - val_mse: 1.6909e-04\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 8.8664e-05 - mse: 1.7733e-04 - val_loss: 9.4017e-05 - val_mse: 1.8803e-04\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 8.8798e-05 - mse: 1.7760e-04 - val_loss: 8.0906e-05 - val_mse: 1.6181e-04\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 8.3425e-05 - mse: 1.6685e-04 - val_loss: 1.4535e-04 - val_mse: 2.9071e-04\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.8106e-05 - mse: 1.5621e-04 - val_loss: 7.3811e-05 - val_mse: 1.4762e-04\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 7.5816e-05 - mse: 1.5163e-04 - val_loss: 6.7068e-05 - val_mse: 1.3414e-04\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.5251e-05 - mse: 1.5050e-04 - val_loss: 8.8907e-05 - val_mse: 1.7781e-04\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 7.9578e-05 - mse: 1.5916e-04 - val_loss: 1.3593e-04 - val_mse: 2.7187e-04\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 7.5625e-05 - mse: 1.5125e-04 - val_loss: 9.2724e-05 - val_mse: 1.8545e-04\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.8401e-05 - mse: 1.5680e-04 - val_loss: 6.2813e-05 - val_mse: 1.2563e-04\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 7.1237e-05 - mse: 1.4247e-04 - val_loss: 9.5131e-05 - val_mse: 1.9026e-04\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.7372e-05 - mse: 1.5474e-04 - val_loss: 6.3515e-05 - val_mse: 1.2703e-04\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.2654e-05 - mse: 1.4531e-04 - val_loss: 6.0688e-05 - val_mse: 1.2138e-04\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 6.9994e-05 - mse: 1.3999e-04 - val_loss: 6.7378e-05 - val_mse: 1.3476e-04\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.4710e-05 - mse: 1.4942e-04 - val_loss: 6.1385e-05 - val_mse: 1.2277e-04\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 6.9559e-05 - mse: 1.3912e-04 - val_loss: 6.3294e-05 - val_mse: 1.2659e-04\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.6246e-05 - mse: 1.5249e-04 - val_loss: 1.1056e-04 - val_mse: 2.2112e-04\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 6.8228e-05 - mse: 1.3646e-04 - val_loss: 5.6816e-05 - val_mse: 1.1363e-04\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 6.9573e-05 - mse: 1.3915e-04 - val_loss: 6.0967e-05 - val_mse: 1.2193e-04\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 7.0680e-05 - mse: 1.4136e-04 - val_loss: 5.5883e-05 - val_mse: 1.1177e-04\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 6.5914e-05 - mse: 1.3183e-04 - val_loss: 5.7514e-05 - val_mse: 1.1503e-04\n",
      "pred.shape : (860, 1) , y_test.shape : (880,)\n",
      "4400길이의 데이터 적용 완료\n",
      " 길이: 4400, RMSE:977.8036161716806\n",
      "train set 확인:  (3600, 4) (3600,) test set 확인:  (900, 4) (900,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "112/112 [==============================] - 8s 25ms/step - loss: 0.0045 - mse: 0.0090 - val_loss: 2.2162e-04 - val_mse: 4.4324e-04\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 1.8326e-04 - mse: 3.6652e-04 - val_loss: 3.4686e-04 - val_mse: 6.9371e-04\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.8178e-04 - mse: 3.6356e-04 - val_loss: 2.1784e-04 - val_mse: 4.3567e-04\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.8394e-04 - mse: 3.6788e-04 - val_loss: 1.9666e-04 - val_mse: 3.9332e-04\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.6539e-04 - mse: 3.3079e-04 - val_loss: 1.9267e-04 - val_mse: 3.8534e-04\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.6347e-04 - mse: 3.2695e-04 - val_loss: 2.0931e-04 - val_mse: 4.1862e-04\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.6135e-04 - mse: 3.2271e-04 - val_loss: 2.1670e-04 - val_mse: 4.3340e-04\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.5375e-04 - mse: 3.0751e-04 - val_loss: 1.7071e-04 - val_mse: 3.4141e-04\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.4724e-04 - mse: 2.9448e-04 - val_loss: 2.0937e-04 - val_mse: 4.1875e-04\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.5133e-04 - mse: 3.0267e-04 - val_loss: 1.9473e-04 - val_mse: 3.8946e-04\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.3953e-04 - mse: 2.7905e-04 - val_loss: 1.7400e-04 - val_mse: 3.4800e-04\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 1.3220e-04 - mse: 2.6441e-04 - val_loss: 1.9765e-04 - val_mse: 3.9529e-04\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2986e-04 - mse: 2.5973e-04 - val_loss: 1.3783e-04 - val_mse: 2.7567e-04\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 1.3208e-04 - mse: 2.6417e-04 - val_loss: 1.4950e-04 - val_mse: 2.9901e-04\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.1477e-04 - mse: 2.2954e-04 - val_loss: 1.7321e-04 - val_mse: 3.4643e-04\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.1272e-04 - mse: 2.2545e-04 - val_loss: 1.3799e-04 - val_mse: 2.7597e-04\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 1.0816e-04 - mse: 2.1632e-04 - val_loss: 1.0520e-04 - val_mse: 2.1041e-04\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 1.0683e-04 - mse: 2.1366e-04 - val_loss: 1.0057e-04 - val_mse: 2.0114e-04\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 9.8499e-05 - mse: 1.9700e-04 - val_loss: 9.7370e-05 - val_mse: 1.9474e-04\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 1.0054e-04 - mse: 2.0109e-04 - val_loss: 9.7243e-05 - val_mse: 1.9449e-04\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 9.6499e-05 - mse: 1.9300e-04 - val_loss: 9.4921e-05 - val_mse: 1.8984e-04\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 9.6850e-05 - mse: 1.9370e-04 - val_loss: 1.1422e-04 - val_mse: 2.2844e-04\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 8.9845e-05 - mse: 1.7969e-04 - val_loss: 8.4549e-05 - val_mse: 1.6910e-04\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 8.3377e-05 - mse: 1.6675e-04 - val_loss: 9.0773e-05 - val_mse: 1.8155e-04\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 8.6940e-05 - mse: 1.7388e-04 - val_loss: 8.6168e-05 - val_mse: 1.7234e-04\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 8.7606e-05 - mse: 1.7521e-04 - val_loss: 8.0777e-05 - val_mse: 1.6155e-04\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 8.4757e-05 - mse: 1.6951e-04 - val_loss: 9.4109e-05 - val_mse: 1.8822e-04\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 7.8020e-05 - mse: 1.5604e-04 - val_loss: 8.0067e-05 - val_mse: 1.6013e-04\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 7.4978e-05 - mse: 1.4996e-04 - val_loss: 7.3007e-05 - val_mse: 1.4601e-04\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 8.4393e-05 - mse: 1.6879e-04 - val_loss: 9.9007e-05 - val_mse: 1.9801e-04\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 8.2593e-05 - mse: 1.6519e-04 - val_loss: 2.4682e-04 - val_mse: 4.9364e-04\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 8.2388e-05 - mse: 1.6478e-04 - val_loss: 7.7213e-05 - val_mse: 1.5443e-04\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 7.6762e-05 - mse: 1.5352e-04 - val_loss: 6.7565e-05 - val_mse: 1.3513e-04\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 7.1687e-05 - mse: 1.4337e-04 - val_loss: 6.6592e-05 - val_mse: 1.3318e-04\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 7.4690e-05 - mse: 1.4938e-04 - val_loss: 9.1968e-05 - val_mse: 1.8394e-04\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 7.2908e-05 - mse: 1.4582e-04 - val_loss: 7.2800e-05 - val_mse: 1.4560e-04\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 2s 18ms/step - loss: 7.2345e-05 - mse: 1.4469e-04 - val_loss: 6.3516e-05 - val_mse: 1.2703e-04\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 7.1454e-05 - mse: 1.4291e-04 - val_loss: 7.0701e-05 - val_mse: 1.4140e-04\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 7.7009e-05 - mse: 1.5402e-04 - val_loss: 1.3162e-04 - val_mse: 2.6323e-04\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 7.3522e-05 - mse: 1.4704e-04 - val_loss: 8.8413e-05 - val_mse: 1.7683e-04\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 7.1533e-05 - mse: 1.4307e-04 - val_loss: 6.7757e-05 - val_mse: 1.3551e-04\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 6.6697e-05 - mse: 1.3339e-04 - val_loss: 6.0326e-05 - val_mse: 1.2065e-04\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 6.8724e-05 - mse: 1.3745e-04 - val_loss: 5.8394e-05 - val_mse: 1.1679e-04\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 6.8445e-05 - mse: 1.3689e-04 - val_loss: 1.3964e-04 - val_mse: 2.7928e-04\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 8.6025e-05 - mse: 1.7205e-04 - val_loss: 5.9481e-05 - val_mse: 1.1896e-04\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 6.3483e-05 - mse: 1.2697e-04 - val_loss: 6.5239e-05 - val_mse: 1.3048e-04\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 6.6885e-05 - mse: 1.3377e-04 - val_loss: 7.8112e-05 - val_mse: 1.5622e-04\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 7.5033e-05 - mse: 1.5007e-04 - val_loss: 5.5955e-05 - val_mse: 1.1191e-04\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 6.8024e-05 - mse: 1.3605e-04 - val_loss: 6.3082e-05 - val_mse: 1.2616e-04\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 6.5624e-05 - mse: 1.3125e-04 - val_loss: 5.5315e-05 - val_mse: 1.1063e-04\n",
      "pred.shape : (880, 1) , y_test.shape : (900,)\n",
      "4500길이의 데이터 적용 완료\n",
      " 길이: 4500, RMSE:972.9068908976415\n",
      "train set 확인:  (3680, 4) (3680,) test set 확인:  (920, 4) (920,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "115/115 [==============================] - 5s 19ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 2.2223e-04 - val_mse: 4.4446e-04\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.5468e-04 - mse: 3.0936e-04 - val_loss: 1.8440e-04 - val_mse: 3.6880e-04\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.4981e-04 - mse: 2.9962e-04 - val_loss: 1.6539e-04 - val_mse: 3.3077e-04\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 1.4012e-04 - mse: 2.8025e-04 - val_loss: 1.6169e-04 - val_mse: 3.2338e-04\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.4909e-04 - mse: 2.9818e-04 - val_loss: 2.2162e-04 - val_mse: 4.4325e-04\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.3818e-04 - mse: 2.7636e-04 - val_loss: 1.5292e-04 - val_mse: 3.0584e-04\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 1.3530e-04 - mse: 2.7059e-04 - val_loss: 1.4581e-04 - val_mse: 2.9162e-04\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.3507e-04 - mse: 2.7014e-04 - val_loss: 1.5953e-04 - val_mse: 3.1906e-04\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.2479e-04 - mse: 2.4958e-04 - val_loss: 2.2923e-04 - val_mse: 4.5846e-04\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 1.1851e-04 - mse: 2.3702e-04 - val_loss: 2.4036e-04 - val_mse: 4.8072e-04\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 1.2035e-04 - mse: 2.4069e-04 - val_loss: 1.5023e-04 - val_mse: 3.0045e-04\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.1618e-04 - mse: 2.3235e-04 - val_loss: 1.2632e-04 - val_mse: 2.5264e-04\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 1.2769e-04 - mse: 2.5537e-04 - val_loss: 1.2286e-04 - val_mse: 2.4572e-04\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 1.0774e-04 - mse: 2.1548e-04 - val_loss: 1.3184e-04 - val_mse: 2.6368e-04\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.1091e-04 - mse: 2.2181e-04 - val_loss: 1.1553e-04 - val_mse: 2.3106e-04\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.1195e-04 - mse: 2.2391e-04 - val_loss: 2.3054e-04 - val_mse: 4.6109e-04\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 1.0432e-04 - mse: 2.0863e-04 - val_loss: 1.0669e-04 - val_mse: 2.1338e-04\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 9.9064e-05 - mse: 1.9813e-04 - val_loss: 1.1708e-04 - val_mse: 2.3416e-04\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 1.0034e-04 - mse: 2.0067e-04 - val_loss: 1.4320e-04 - val_mse: 2.8640e-04\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 1.0157e-04 - mse: 2.0313e-04 - val_loss: 1.0578e-04 - val_mse: 2.1156e-04\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 9.9536e-05 - mse: 1.9907e-04 - val_loss: 1.1369e-04 - val_mse: 2.2739e-04\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 1.0432e-04 - mse: 2.0864e-04 - val_loss: 1.4066e-04 - val_mse: 2.8132e-04\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 9.1014e-05 - mse: 1.8203e-04 - val_loss: 1.1881e-04 - val_mse: 2.3761e-04\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 9.7479e-05 - mse: 1.9496e-04 - val_loss: 1.0285e-04 - val_mse: 2.0570e-04\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 8.9665e-05 - mse: 1.7933e-04 - val_loss: 9.0280e-05 - val_mse: 1.8056e-04\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 8.8258e-05 - mse: 1.7652e-04 - val_loss: 8.8083e-05 - val_mse: 1.7617e-04\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 8.9474e-05 - mse: 1.7895e-04 - val_loss: 1.8130e-04 - val_mse: 3.6260e-04\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 8.9842e-05 - mse: 1.7968e-04 - val_loss: 9.2266e-05 - val_mse: 1.8453e-04\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 8.3457e-05 - mse: 1.6691e-04 - val_loss: 1.1950e-04 - val_mse: 2.3899e-04\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 8.7088e-05 - mse: 1.7418e-04 - val_loss: 8.9945e-05 - val_mse: 1.7989e-04\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 8.1851e-05 - mse: 1.6370e-04 - val_loss: 1.2886e-04 - val_mse: 2.5773e-04\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 8.0785e-05 - mse: 1.6157e-04 - val_loss: 8.6190e-05 - val_mse: 1.7238e-04\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 8.0828e-05 - mse: 1.6166e-04 - val_loss: 1.1288e-04 - val_mse: 2.2577e-04\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 9.0185e-05 - mse: 1.8037e-04 - val_loss: 7.9516e-05 - val_mse: 1.5903e-04\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 8.3179e-05 - mse: 1.6636e-04 - val_loss: 7.7466e-05 - val_mse: 1.5493e-04\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 7.7885e-05 - mse: 1.5577e-04 - val_loss: 7.6121e-05 - val_mse: 1.5224e-04\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 7.4584e-05 - mse: 1.4917e-04 - val_loss: 9.7700e-05 - val_mse: 1.9540e-04\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 7.7084e-05 - mse: 1.5417e-04 - val_loss: 1.3195e-04 - val_mse: 2.6390e-04\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 8.2700e-05 - mse: 1.6540e-04 - val_loss: 9.0376e-05 - val_mse: 1.8075e-04\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 7.4004e-05 - mse: 1.4801e-04 - val_loss: 7.0943e-05 - val_mse: 1.4189e-04\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 7.4671e-05 - mse: 1.4934e-04 - val_loss: 6.9897e-05 - val_mse: 1.3979e-04\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 7.5810e-05 - mse: 1.5162e-04 - val_loss: 6.9879e-05 - val_mse: 1.3976e-04\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 6.9784e-05 - mse: 1.3957e-04 - val_loss: 6.8787e-05 - val_mse: 1.3757e-04\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 6.9299e-05 - mse: 1.3860e-04 - val_loss: 1.2567e-04 - val_mse: 2.5133e-04\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 2s 15ms/step - loss: 7.3813e-05 - mse: 1.4763e-04 - val_loss: 6.9263e-05 - val_mse: 1.3853e-04\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 7.3491e-05 - mse: 1.4698e-04 - val_loss: 1.9641e-04 - val_mse: 3.9282e-04\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 2s 16ms/step - loss: 7.2782e-05 - mse: 1.4556e-04 - val_loss: 7.7339e-05 - val_mse: 1.5468e-04\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 6.8238e-05 - mse: 1.3648e-04 - val_loss: 9.2099e-05 - val_mse: 1.8420e-04\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 6.7437e-05 - mse: 1.3487e-04 - val_loss: 8.0715e-05 - val_mse: 1.6143e-04\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 2s 19ms/step - loss: 6.8366e-05 - mse: 1.3673e-04 - val_loss: 7.6237e-05 - val_mse: 1.5247e-04\n",
      "pred.shape : (900, 1) , y_test.shape : (920,)\n",
      "4600길이의 데이터 적용 완료\n",
      " 길이: 4600, RMSE:1176.0496917134292\n",
      "train set 확인:  (3760, 4) (3760,) test set 확인:  (940, 4) (940,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 5s 21ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 1.9698e-04 - val_mse: 3.9397e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.7131e-04 - mse: 3.4262e-04 - val_loss: 2.0271e-04 - val_mse: 4.0542e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.5624e-04 - mse: 3.1248e-04 - val_loss: 2.7791e-04 - val_mse: 5.5583e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.5380e-04 - mse: 3.0760e-04 - val_loss: 1.7677e-04 - val_mse: 3.5353e-04\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.4491e-04 - mse: 2.8982e-04 - val_loss: 1.6661e-04 - val_mse: 3.3323e-04\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.4206e-04 - mse: 2.8412e-04 - val_loss: 1.7753e-04 - val_mse: 3.5506e-04\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.2891e-04 - mse: 2.5783e-04 - val_loss: 1.6355e-04 - val_mse: 3.2711e-04\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 1.3262e-04 - mse: 2.6524e-04 - val_loss: 2.4741e-04 - val_mse: 4.9483e-04\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 1.2043e-04 - mse: 2.4087e-04 - val_loss: 2.7656e-04 - val_mse: 5.5313e-04\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 1.3487e-04 - mse: 2.6974e-04 - val_loss: 3.7146e-04 - val_mse: 7.4293e-04\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.2277e-04 - mse: 2.4553e-04 - val_loss: 1.2872e-04 - val_mse: 2.5744e-04\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.1193e-04 - mse: 2.2386e-04 - val_loss: 1.2596e-04 - val_mse: 2.5193e-04\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.0401e-04 - mse: 2.0803e-04 - val_loss: 1.4813e-04 - val_mse: 2.9626e-04\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.0759e-04 - mse: 2.1518e-04 - val_loss: 1.4687e-04 - val_mse: 2.9375e-04\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 1.1368e-04 - mse: 2.2737e-04 - val_loss: 1.9691e-04 - val_mse: 3.9381e-04\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 1.1600e-04 - mse: 2.3201e-04 - val_loss: 1.0426e-04 - val_mse: 2.0853e-04\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 9.9756e-05 - mse: 1.9951e-04 - val_loss: 1.1573e-04 - val_mse: 2.3145e-04\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 9.2949e-05 - mse: 1.8590e-04 - val_loss: 1.2260e-04 - val_mse: 2.4521e-04\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 9.5097e-05 - mse: 1.9019e-04 - val_loss: 2.1333e-04 - val_mse: 4.2666e-04\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 9.0418e-05 - mse: 1.8084e-04 - val_loss: 9.4773e-05 - val_mse: 1.8955e-04\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 8.4951e-05 - mse: 1.6990e-04 - val_loss: 1.0367e-04 - val_mse: 2.0733e-04\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 8.4407e-05 - mse: 1.6881e-04 - val_loss: 1.3446e-04 - val_mse: 2.6892e-04\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 8.1277e-05 - mse: 1.6255e-04 - val_loss: 8.7099e-05 - val_mse: 1.7420e-04\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 8.0300e-05 - mse: 1.6060e-04 - val_loss: 8.8131e-05 - val_mse: 1.7626e-04\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 8.3065e-05 - mse: 1.6613e-04 - val_loss: 7.7651e-05 - val_mse: 1.5530e-04\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 7.5208e-05 - mse: 1.5042e-04 - val_loss: 9.9234e-05 - val_mse: 1.9847e-04\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.8486e-05 - mse: 1.5697e-04 - val_loss: 8.4342e-05 - val_mse: 1.6868e-04\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 8.0707e-05 - mse: 1.6141e-04 - val_loss: 9.3454e-05 - val_mse: 1.8691e-04\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.9670e-05 - mse: 1.5934e-04 - val_loss: 1.9016e-04 - val_mse: 3.8032e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 7.0543e-05 - mse: 1.4109e-04 - val_loss: 7.1204e-05 - val_mse: 1.4241e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.9083e-05 - mse: 1.5817e-04 - val_loss: 9.9170e-05 - val_mse: 1.9834e-04\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 7.1770e-05 - mse: 1.4354e-04 - val_loss: 6.8226e-05 - val_mse: 1.3645e-04\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.9300e-05 - mse: 1.5860e-04 - val_loss: 6.6576e-05 - val_mse: 1.3315e-04\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.5135e-05 - mse: 1.5027e-04 - val_loss: 6.8787e-05 - val_mse: 1.3757e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 7.1576e-05 - mse: 1.4315e-04 - val_loss: 6.9425e-05 - val_mse: 1.3885e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 7.5866e-05 - mse: 1.5173e-04 - val_loss: 1.3982e-04 - val_mse: 2.7963e-04\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 6.7929e-05 - mse: 1.3586e-04 - val_loss: 7.0665e-05 - val_mse: 1.4133e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.6220e-05 - mse: 1.3244e-04 - val_loss: 7.0710e-05 - val_mse: 1.4142e-04\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 7.3939e-05 - mse: 1.4788e-04 - val_loss: 8.7940e-05 - val_mse: 1.7588e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 6.5811e-05 - mse: 1.3162e-04 - val_loss: 9.3943e-05 - val_mse: 1.8789e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 6.3597e-05 - mse: 1.2719e-04 - val_loss: 6.1509e-05 - val_mse: 1.2302e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 6.7435e-05 - mse: 1.3487e-04 - val_loss: 1.0029e-04 - val_mse: 2.0058e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.1729e-05 - mse: 1.2346e-04 - val_loss: 6.4342e-05 - val_mse: 1.2868e-04\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.7202e-05 - mse: 1.3440e-04 - val_loss: 9.3343e-05 - val_mse: 1.8669e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.3776e-05 - mse: 1.2755e-04 - val_loss: 6.1111e-05 - val_mse: 1.2222e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.0721e-05 - mse: 1.2144e-04 - val_loss: 5.8922e-05 - val_mse: 1.1784e-04\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.3637e-05 - mse: 1.2727e-04 - val_loss: 8.1520e-05 - val_mse: 1.6304e-04\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 5.9926e-05 - mse: 1.1985e-04 - val_loss: 7.4439e-05 - val_mse: 1.4888e-04\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.4075e-05 - mse: 1.2815e-04 - val_loss: 1.4163e-04 - val_mse: 2.8327e-04\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 6.5852e-05 - mse: 1.3170e-04 - val_loss: 5.5975e-05 - val_mse: 1.1195e-04\n",
      "pred.shape : (920, 1) , y_test.shape : (940,)\n",
      "4700길이의 데이터 적용 완료\n",
      " 길이: 4700, RMSE:1020.9895199716765\n",
      "train set 확인:  (3840, 4) (3840,) test set 확인:  (960, 4) (960,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 6s 19ms/step - loss: 0.0056 - mse: 0.0113 - val_loss: 2.2576e-04 - val_mse: 4.5151e-04\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.7482e-04 - mse: 3.4963e-04 - val_loss: 2.1003e-04 - val_mse: 4.2005e-04\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.6230e-04 - mse: 3.2459e-04 - val_loss: 1.7797e-04 - val_mse: 3.5594e-04\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 1.6231e-04 - mse: 3.2461e-04 - val_loss: 2.3459e-04 - val_mse: 4.6919e-04\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 1.4157e-04 - mse: 2.8314e-04 - val_loss: 1.7438e-04 - val_mse: 3.4876e-04\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.3837e-04 - mse: 2.7674e-04 - val_loss: 2.0085e-04 - val_mse: 4.0171e-04\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.2750e-04 - mse: 2.5500e-04 - val_loss: 1.7994e-04 - val_mse: 3.5987e-04\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.2656e-04 - mse: 2.5311e-04 - val_loss: 3.5069e-04 - val_mse: 7.0139e-04\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 1.2842e-04 - mse: 2.5683e-04 - val_loss: 1.4659e-04 - val_mse: 2.9318e-04\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.2890e-04 - mse: 2.5780e-04 - val_loss: 1.9819e-04 - val_mse: 3.9639e-04\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.2536e-04 - mse: 2.5072e-04 - val_loss: 1.4354e-04 - val_mse: 2.8708e-04\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.1183e-04 - mse: 2.2367e-04 - val_loss: 1.2806e-04 - val_mse: 2.5613e-04\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.0743e-04 - mse: 2.1486e-04 - val_loss: 1.4801e-04 - val_mse: 2.9602e-04\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.1601e-04 - mse: 2.3201e-04 - val_loss: 1.3705e-04 - val_mse: 2.7410e-04\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.0457e-04 - mse: 2.0915e-04 - val_loss: 2.3138e-04 - val_mse: 4.6276e-04\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 1.0455e-04 - mse: 2.0910e-04 - val_loss: 1.1259e-04 - val_mse: 2.2518e-04\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 9.9230e-05 - mse: 1.9846e-04 - val_loss: 1.2392e-04 - val_mse: 2.4785e-04\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 9.3112e-05 - mse: 1.8622e-04 - val_loss: 1.4581e-04 - val_mse: 2.9162e-04\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 9.3973e-05 - mse: 1.8795e-04 - val_loss: 1.9902e-04 - val_mse: 3.9805e-04\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 9.9308e-05 - mse: 1.9862e-04 - val_loss: 1.3386e-04 - val_mse: 2.6772e-04\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 9.5184e-05 - mse: 1.9037e-04 - val_loss: 1.0040e-04 - val_mse: 2.0080e-04\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 9.2103e-05 - mse: 1.8421e-04 - val_loss: 1.6579e-04 - val_mse: 3.3159e-04\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 9.6562e-05 - mse: 1.9312e-04 - val_loss: 1.2040e-04 - val_mse: 2.4080e-04\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.8988e-05 - mse: 1.7798e-04 - val_loss: 1.0236e-04 - val_mse: 2.0473e-04\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 8.8938e-05 - mse: 1.7788e-04 - val_loss: 1.1461e-04 - val_mse: 2.2923e-04\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.3548e-05 - mse: 1.6710e-04 - val_loss: 1.3554e-04 - val_mse: 2.7109e-04\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 8.6165e-05 - mse: 1.7233e-04 - val_loss: 1.5462e-04 - val_mse: 3.0923e-04\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 8.5230e-05 - mse: 1.7046e-04 - val_loss: 8.6611e-05 - val_mse: 1.7322e-04\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.2744e-05 - mse: 1.6549e-04 - val_loss: 1.0103e-04 - val_mse: 2.0206e-04\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.6110e-05 - mse: 1.7222e-04 - val_loss: 1.1595e-04 - val_mse: 2.3190e-04\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 9.2808e-05 - mse: 1.8562e-04 - val_loss: 8.7780e-05 - val_mse: 1.7556e-04\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 8.6172e-05 - mse: 1.7234e-04 - val_loss: 8.4118e-05 - val_mse: 1.6824e-04\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 8.0027e-05 - mse: 1.6005e-04 - val_loss: 3.0033e-04 - val_mse: 6.0065e-04\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 8.6775e-05 - mse: 1.7355e-04 - val_loss: 9.2306e-05 - val_mse: 1.8461e-04\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 7.8304e-05 - mse: 1.5661e-04 - val_loss: 2.1115e-04 - val_mse: 4.2231e-04\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.8353e-05 - mse: 1.7671e-04 - val_loss: 1.0490e-04 - val_mse: 2.0981e-04\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.9780e-05 - mse: 1.5956e-04 - val_loss: 7.7013e-05 - val_mse: 1.5403e-04\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 7.4845e-05 - mse: 1.4969e-04 - val_loss: 1.2742e-04 - val_mse: 2.5484e-04\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.4651e-05 - mse: 1.4930e-04 - val_loss: 8.7666e-05 - val_mse: 1.7533e-04\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 7.3169e-05 - mse: 1.4634e-04 - val_loss: 8.6581e-05 - val_mse: 1.7316e-04\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.6508e-05 - mse: 1.5302e-04 - val_loss: 1.4257e-04 - val_mse: 2.8513e-04\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.8053e-05 - mse: 1.5611e-04 - val_loss: 8.4977e-05 - val_mse: 1.6995e-04\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.6438e-05 - mse: 1.5288e-04 - val_loss: 7.2736e-05 - val_mse: 1.4547e-04\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 8.1740e-05 - mse: 1.6348e-04 - val_loss: 8.6428e-05 - val_mse: 1.7286e-04\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 7.8097e-05 - mse: 1.5619e-04 - val_loss: 7.1396e-05 - val_mse: 1.4279e-04\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.0368e-05 - mse: 1.4074e-04 - val_loss: 9.3228e-05 - val_mse: 1.8646e-04\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.7148e-05 - mse: 1.5430e-04 - val_loss: 7.9503e-05 - val_mse: 1.5901e-04\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 8.0829e-05 - mse: 1.6166e-04 - val_loss: 8.6618e-05 - val_mse: 1.7324e-04\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 7.1542e-05 - mse: 1.4308e-04 - val_loss: 1.2692e-04 - val_mse: 2.5384e-04\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 7.4814e-05 - mse: 1.4963e-04 - val_loss: 1.5645e-04 - val_mse: 3.1291e-04\n",
      "pred.shape : (940, 1) , y_test.shape : (960,)\n",
      "4800길이의 데이터 적용 완료\n",
      " 길이: 4800, RMSE:1721.7352767749737\n",
      "train set 확인:  (3920, 4) (3920,) test set 확인:  (980, 4) (980,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 [==============================] - 5s 19ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 1.6861e-04 - val_mse: 3.3723e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.5399e-04 - mse: 3.0798e-04 - val_loss: 3.0568e-04 - val_mse: 6.1137e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.3867e-04 - mse: 2.7735e-04 - val_loss: 2.6702e-04 - val_mse: 5.3403e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.3247e-04 - mse: 2.6494e-04 - val_loss: 2.8340e-04 - val_mse: 5.6680e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.2913e-04 - mse: 2.5826e-04 - val_loss: 1.6418e-04 - val_mse: 3.2837e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.2634e-04 - mse: 2.5268e-04 - val_loss: 2.1248e-04 - val_mse: 4.2495e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.3386e-04 - mse: 2.6772e-04 - val_loss: 2.0275e-04 - val_mse: 4.0550e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.3674e-04 - mse: 2.7348e-04 - val_loss: 2.2772e-04 - val_mse: 4.5544e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.3465e-04 - mse: 2.6929e-04 - val_loss: 2.2749e-04 - val_mse: 4.5498e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.2150e-04 - mse: 2.4299e-04 - val_loss: 1.7047e-04 - val_mse: 3.4095e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.2161e-04 - mse: 2.4322e-04 - val_loss: 2.1414e-04 - val_mse: 4.2828e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.1606e-04 - mse: 2.3213e-04 - val_loss: 1.3791e-04 - val_mse: 2.7582e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 1.1546e-04 - mse: 2.3092e-04 - val_loss: 1.5149e-04 - val_mse: 3.0298e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.1244e-04 - mse: 2.2487e-04 - val_loss: 1.4209e-04 - val_mse: 2.8417e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.1785e-04 - mse: 2.3570e-04 - val_loss: 1.5241e-04 - val_mse: 3.0483e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.1241e-04 - mse: 2.2482e-04 - val_loss: 1.4444e-04 - val_mse: 2.8888e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.0960e-04 - mse: 2.1919e-04 - val_loss: 1.2963e-04 - val_mse: 2.5926e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.0991e-04 - mse: 2.1982e-04 - val_loss: 1.8811e-04 - val_mse: 3.7623e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.1272e-04 - mse: 2.2543e-04 - val_loss: 1.4690e-04 - val_mse: 2.9379e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.1027e-04 - mse: 2.2053e-04 - val_loss: 1.2172e-04 - val_mse: 2.4344e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.1663e-04 - mse: 2.3327e-04 - val_loss: 1.1895e-04 - val_mse: 2.3791e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.0196e-04 - mse: 2.0391e-04 - val_loss: 1.1802e-04 - val_mse: 2.3603e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 1.0215e-04 - mse: 2.0431e-04 - val_loss: 1.2157e-04 - val_mse: 2.4313e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 9.5897e-05 - mse: 1.9179e-04 - val_loss: 1.2227e-04 - val_mse: 2.4453e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.0137e-04 - mse: 2.0274e-04 - val_loss: 2.1082e-04 - val_mse: 4.2163e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.0507e-04 - mse: 2.1014e-04 - val_loss: 2.4335e-04 - val_mse: 4.8669e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 9.4035e-05 - mse: 1.8807e-04 - val_loss: 1.0830e-04 - val_mse: 2.1660e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 9.0819e-05 - mse: 1.8164e-04 - val_loss: 1.0632e-04 - val_mse: 2.1265e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 9.6639e-05 - mse: 1.9328e-04 - val_loss: 2.2160e-04 - val_mse: 4.4320e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.7957e-05 - mse: 1.7591e-04 - val_loss: 1.0436e-04 - val_mse: 2.0873e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 8.7236e-05 - mse: 1.7447e-04 - val_loss: 1.5909e-04 - val_mse: 3.1819e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 9.4672e-05 - mse: 1.8934e-04 - val_loss: 1.3855e-04 - val_mse: 2.7711e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 9.4724e-05 - mse: 1.8945e-04 - val_loss: 9.7660e-05 - val_mse: 1.9532e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.8326e-05 - mse: 1.7665e-04 - val_loss: 1.1040e-04 - val_mse: 2.2079e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.8063e-05 - mse: 1.7613e-04 - val_loss: 1.1695e-04 - val_mse: 2.3390e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 8.1912e-05 - mse: 1.6382e-04 - val_loss: 1.0531e-04 - val_mse: 2.1062e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.2556e-05 - mse: 1.6511e-04 - val_loss: 1.6033e-04 - val_mse: 3.2066e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 9.1371e-05 - mse: 1.8274e-04 - val_loss: 1.0365e-04 - val_mse: 2.0729e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 8.3743e-05 - mse: 1.6749e-04 - val_loss: 1.1409e-04 - val_mse: 2.2818e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 9.2641e-05 - mse: 1.8528e-04 - val_loss: 1.4573e-04 - val_mse: 2.9146e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.7664e-05 - mse: 1.5533e-04 - val_loss: 8.9356e-05 - val_mse: 1.7871e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.8265e-05 - mse: 1.5653e-04 - val_loss: 1.4278e-04 - val_mse: 2.8556e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 8.6560e-05 - mse: 1.7312e-04 - val_loss: 2.4386e-04 - val_mse: 4.8773e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 7.9066e-05 - mse: 1.5813e-04 - val_loss: 8.3251e-05 - val_mse: 1.6650e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.5152e-05 - mse: 1.5030e-04 - val_loss: 1.9128e-04 - val_mse: 3.8255e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.5837e-05 - mse: 1.5167e-04 - val_loss: 8.0199e-05 - val_mse: 1.6040e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.5991e-05 - mse: 1.5198e-04 - val_loss: 1.4001e-04 - val_mse: 2.8001e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.5016e-05 - mse: 1.5003e-04 - val_loss: 1.1294e-04 - val_mse: 2.2588e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.2868e-05 - mse: 1.4574e-04 - val_loss: 1.0160e-04 - val_mse: 2.0320e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.1220e-05 - mse: 1.4244e-04 - val_loss: 9.9896e-05 - val_mse: 1.9979e-04\n",
      "pred.shape : (960, 1) , y_test.shape : (980,)\n",
      "4900길이의 데이터 적용 완료\n",
      " 길이: 4900, RMSE:1383.237040372974\n",
      "train set 확인:  (4000, 4) (4000,) test set 확인:  (1000, 4) (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 5s 18ms/step - loss: 0.0435 - mse: 0.0869 - val_loss: 0.0060 - val_mse: 0.0120\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 2.6569e-04 - val_mse: 5.3139e-04\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.8825e-04 - mse: 3.7651e-04 - val_loss: 2.8737e-04 - val_mse: 5.7473e-04\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.5080e-04 - mse: 3.0159e-04 - val_loss: 1.8206e-04 - val_mse: 3.6413e-04\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.3404e-04 - mse: 2.6809e-04 - val_loss: 1.8366e-04 - val_mse: 3.6732e-04\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2841e-04 - mse: 2.5681e-04 - val_loss: 1.7941e-04 - val_mse: 3.5882e-04\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.3185e-04 - mse: 2.6371e-04 - val_loss: 1.8661e-04 - val_mse: 3.7322e-04\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 1.2393e-04 - mse: 2.4786e-04 - val_loss: 1.9157e-04 - val_mse: 3.8315e-04\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.1972e-04 - mse: 2.3944e-04 - val_loss: 2.0964e-04 - val_mse: 4.1927e-04\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2368e-04 - mse: 2.4737e-04 - val_loss: 2.9502e-04 - val_mse: 5.9005e-04\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.2164e-04 - mse: 2.4327e-04 - val_loss: 2.1767e-04 - val_mse: 4.3535e-04\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.1586e-04 - mse: 2.3172e-04 - val_loss: 1.5489e-04 - val_mse: 3.0977e-04\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 1.1455e-04 - mse: 2.2909e-04 - val_loss: 1.5386e-04 - val_mse: 3.0772e-04\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 1.0671e-04 - mse: 2.1342e-04 - val_loss: 1.4853e-04 - val_mse: 2.9706e-04\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.0716e-04 - mse: 2.1432e-04 - val_loss: 1.4484e-04 - val_mse: 2.8967e-04\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0611e-04 - mse: 2.1222e-04 - val_loss: 1.4929e-04 - val_mse: 2.9859e-04\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.1064e-04 - mse: 2.2128e-04 - val_loss: 1.3185e-04 - val_mse: 2.6369e-04\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0083e-04 - mse: 2.0166e-04 - val_loss: 1.2884e-04 - val_mse: 2.5768e-04\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 1.0384e-04 - mse: 2.0769e-04 - val_loss: 1.3757e-04 - val_mse: 2.7514e-04\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0186e-04 - mse: 2.0372e-04 - val_loss: 1.2912e-04 - val_mse: 2.5824e-04\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0241e-04 - mse: 2.0483e-04 - val_loss: 1.3321e-04 - val_mse: 2.6642e-04\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0525e-04 - mse: 2.1049e-04 - val_loss: 1.1823e-04 - val_mse: 2.3647e-04\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 9.5693e-05 - mse: 1.9139e-04 - val_loss: 1.2534e-04 - val_mse: 2.5069e-04\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 9.1971e-05 - mse: 1.8394e-04 - val_loss: 1.1244e-04 - val_mse: 2.2488e-04\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 9.3569e-05 - mse: 1.8714e-04 - val_loss: 1.4969e-04 - val_mse: 2.9938e-04\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 9.3784e-05 - mse: 1.8757e-04 - val_loss: 1.1078e-04 - val_mse: 2.2156e-04\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 8.8513e-05 - mse: 1.7703e-04 - val_loss: 1.1665e-04 - val_mse: 2.3331e-04\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 8.5554e-05 - mse: 1.7111e-04 - val_loss: 1.0353e-04 - val_mse: 2.0706e-04\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.6973e-05 - mse: 1.7395e-04 - val_loss: 1.6744e-04 - val_mse: 3.3489e-04\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.3949e-05 - mse: 1.6790e-04 - val_loss: 1.6447e-04 - val_mse: 3.2894e-04\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 8.3961e-05 - mse: 1.6792e-04 - val_loss: 2.1380e-04 - val_mse: 4.2761e-04\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 8.4300e-05 - mse: 1.6860e-04 - val_loss: 1.2698e-04 - val_mse: 2.5396e-04\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.9238e-05 - mse: 1.5848e-04 - val_loss: 1.0044e-04 - val_mse: 2.0088e-04\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.9687e-05 - mse: 1.5937e-04 - val_loss: 9.2239e-05 - val_mse: 1.8448e-04\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 8.4385e-05 - mse: 1.6877e-04 - val_loss: 3.6830e-04 - val_mse: 7.3661e-04\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.8280e-05 - mse: 1.7656e-04 - val_loss: 8.9628e-05 - val_mse: 1.7926e-04\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 8.0284e-05 - mse: 1.6057e-04 - val_loss: 8.9601e-05 - val_mse: 1.7920e-04\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.8863e-05 - mse: 1.5773e-04 - val_loss: 8.6045e-05 - val_mse: 1.7209e-04\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.8129e-05 - mse: 1.5626e-04 - val_loss: 8.8013e-05 - val_mse: 1.7603e-04\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.3131e-05 - mse: 1.6626e-04 - val_loss: 1.1779e-04 - val_mse: 2.3559e-04\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.6732e-05 - mse: 1.5346e-04 - val_loss: 8.1672e-05 - val_mse: 1.6334e-04\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 6.9367e-05 - mse: 1.3873e-04 - val_loss: 8.7874e-05 - val_mse: 1.7575e-04\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 6.8246e-05 - mse: 1.3649e-04 - val_loss: 7.6423e-05 - val_mse: 1.5285e-04\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 6.9551e-05 - mse: 1.3910e-04 - val_loss: 9.1766e-05 - val_mse: 1.8353e-04\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 7.1118e-05 - mse: 1.4224e-04 - val_loss: 1.0855e-04 - val_mse: 2.1709e-04\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.3884e-05 - mse: 1.4777e-04 - val_loss: 1.4820e-04 - val_mse: 2.9641e-04\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 6.4356e-05 - mse: 1.2871e-04 - val_loss: 1.0686e-04 - val_mse: 2.1371e-04\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 6.8539e-05 - mse: 1.3708e-04 - val_loss: 6.9760e-05 - val_mse: 1.3952e-04\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 6.2253e-05 - mse: 1.2451e-04 - val_loss: 7.2268e-05 - val_mse: 1.4454e-04\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 6.1870e-05 - mse: 1.2374e-04 - val_loss: 7.7674e-05 - val_mse: 1.5535e-04\n",
      "pred.shape : (980, 1) , y_test.shape : (1000,)\n",
      "5000길이의 데이터 적용 완료\n",
      " 길이: 5000, RMSE:1229.303117463796\n",
      "train set 확인:  (4080, 4) (4080,) test set 확인:  (1020, 4) (1020,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 7s 22ms/step - loss: 4.8063e-04 - mse: 9.6126e-04 - val_loss: 1.7180e-04 - val_mse: 3.4359e-04\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 1.4056e-04 - mse: 2.8112e-04 - val_loss: 1.5496e-04 - val_mse: 3.0991e-04\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 1.1051e-04 - mse: 2.2103e-04 - val_loss: 1.6992e-04 - val_mse: 3.3984e-04\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 1.1001e-04 - mse: 2.2002e-04 - val_loss: 2.3222e-04 - val_mse: 4.6444e-04\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 1.0392e-04 - mse: 2.0783e-04 - val_loss: 1.3410e-04 - val_mse: 2.6821e-04\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 1.0039e-04 - mse: 2.0078e-04 - val_loss: 1.2647e-04 - val_mse: 2.5293e-04\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 1.0165e-04 - mse: 2.0331e-04 - val_loss: 1.2371e-04 - val_mse: 2.4743e-04\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 9.9509e-05 - mse: 1.9902e-04 - val_loss: 1.2772e-04 - val_mse: 2.5543e-04\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 9.1537e-05 - mse: 1.8307e-04 - val_loss: 1.1599e-04 - val_mse: 2.3198e-04\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 9.3196e-05 - mse: 1.8639e-04 - val_loss: 1.1298e-04 - val_mse: 2.2597e-04\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 2s 16ms/step - loss: 9.5581e-05 - mse: 1.9116e-04 - val_loss: 1.3541e-04 - val_mse: 2.7082e-04\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 9.4253e-05 - mse: 1.8851e-04 - val_loss: 1.7306e-04 - val_mse: 3.4612e-04\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 2s 16ms/step - loss: 8.7146e-05 - mse: 1.7429e-04 - val_loss: 1.2957e-04 - val_mse: 2.5915e-04\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 8.8394e-05 - mse: 1.7679e-04 - val_loss: 1.0034e-04 - val_mse: 2.0067e-04\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 2s 17ms/step - loss: 8.9320e-05 - mse: 1.7864e-04 - val_loss: 1.3219e-04 - val_mse: 2.6439e-04\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 8.5366e-05 - mse: 1.7073e-04 - val_loss: 1.1994e-04 - val_mse: 2.3989e-04\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 2s 13ms/step - loss: 7.8966e-05 - mse: 1.5793e-04 - val_loss: 9.9165e-05 - val_mse: 1.9833e-04\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 7.2467e-05 - mse: 1.4493e-04 - val_loss: 8.6136e-05 - val_mse: 1.7227e-04\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 7.1413e-05 - mse: 1.4283e-04 - val_loss: 1.6238e-04 - val_mse: 3.2475e-04\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 6.9157e-05 - mse: 1.3831e-04 - val_loss: 9.1902e-05 - val_mse: 1.8380e-04\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 6.5857e-05 - mse: 1.3171e-04 - val_loss: 1.4152e-04 - val_mse: 2.8304e-04\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 6.9737e-05 - mse: 1.3947e-04 - val_loss: 7.6254e-05 - val_mse: 1.5251e-04\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 6.4335e-05 - mse: 1.2867e-04 - val_loss: 1.2541e-04 - val_mse: 2.5082e-04\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 6.2088e-05 - mse: 1.2418e-04 - val_loss: 7.0643e-05 - val_mse: 1.4129e-04\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 6.0731e-05 - mse: 1.2146e-04 - val_loss: 7.2492e-05 - val_mse: 1.4498e-04\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 6.2994e-05 - mse: 1.2599e-04 - val_loss: 7.9348e-05 - val_mse: 1.5870e-04\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 6.2642e-05 - mse: 1.2528e-04 - val_loss: 7.3899e-05 - val_mse: 1.4780e-04\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 2s 17ms/step - loss: 6.6211e-05 - mse: 1.3242e-04 - val_loss: 7.5704e-05 - val_mse: 1.5141e-04\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 2s 17ms/step - loss: 5.6740e-05 - mse: 1.1348e-04 - val_loss: 6.3190e-05 - val_mse: 1.2638e-04\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.5257e-05 - mse: 1.1051e-04 - val_loss: 8.9522e-05 - val_mse: 1.7904e-04\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.5878e-05 - mse: 1.1176e-04 - val_loss: 8.7313e-05 - val_mse: 1.7463e-04\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.6215e-05 - mse: 1.1243e-04 - val_loss: 1.1118e-04 - val_mse: 2.2235e-04\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 6.2686e-05 - mse: 1.2537e-04 - val_loss: 8.9677e-05 - val_mse: 1.7935e-04\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 2s 13ms/step - loss: 5.2840e-05 - mse: 1.0568e-04 - val_loss: 1.3481e-04 - val_mse: 2.6962e-04\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 5.3346e-05 - mse: 1.0669e-04 - val_loss: 5.9941e-05 - val_mse: 1.1988e-04\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.2443e-05 - mse: 1.0489e-04 - val_loss: 6.4136e-05 - val_mse: 1.2827e-04\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.0698e-05 - mse: 1.0140e-04 - val_loss: 5.7976e-05 - val_mse: 1.1595e-04\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 4.8605e-05 - mse: 9.7209e-05 - val_loss: 6.1311e-05 - val_mse: 1.2262e-04\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.3294e-05 - mse: 1.0659e-04 - val_loss: 5.5048e-05 - val_mse: 1.1010e-04\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.0656e-05 - mse: 1.0131e-04 - val_loss: 1.4645e-04 - val_mse: 2.9289e-04\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.3447e-05 - mse: 1.0689e-04 - val_loss: 5.4356e-05 - val_mse: 1.0871e-04\n",
      "Epoch 42/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 4.7948e-05 - mse: 9.5895e-05 - val_loss: 5.6600e-05 - val_mse: 1.1320e-04\n",
      "Epoch 43/50\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 5.2595e-05 - mse: 1.0519e-04 - val_loss: 8.5133e-05 - val_mse: 1.7027e-04\n",
      "Epoch 44/50\n",
      "127/127 [==============================] - 2s 17ms/step - loss: 5.0741e-05 - mse: 1.0148e-04 - val_loss: 1.1589e-04 - val_mse: 2.3179e-04\n",
      "Epoch 45/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 4.9242e-05 - mse: 9.8484e-05 - val_loss: 6.8730e-05 - val_mse: 1.3746e-04\n",
      "Epoch 46/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 4.8554e-05 - mse: 9.7108e-05 - val_loss: 6.3765e-05 - val_mse: 1.2753e-04\n",
      "Epoch 47/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.0319e-05 - mse: 1.0064e-04 - val_loss: 5.1048e-05 - val_mse: 1.0210e-04\n",
      "Epoch 48/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 5.3171e-05 - mse: 1.0634e-04 - val_loss: 5.1248e-05 - val_mse: 1.0250e-04\n",
      "Epoch 49/50\n",
      "127/127 [==============================] - 2s 14ms/step - loss: 4.9003e-05 - mse: 9.8006e-05 - val_loss: 6.4767e-05 - val_mse: 1.2953e-04\n",
      "Epoch 50/50\n",
      "127/127 [==============================] - 2s 15ms/step - loss: 4.6273e-05 - mse: 9.2547e-05 - val_loss: 5.0519e-05 - val_mse: 1.0104e-04\n",
      "pred.shape : (1000, 1) , y_test.shape : (1020,)\n",
      "5100길이의 데이터 적용 완료\n",
      " 길이: 5100, RMSE:991.4013876637882\n",
      "train set 확인:  (4160, 4) (4160,) test set 확인:  (1040, 4) (1040,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 6s 24ms/step - loss: 5.1799e-04 - mse: 0.0010 - val_loss: 1.5657e-04 - val_mse: 3.1315e-04\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 1.2169e-04 - mse: 2.4338e-04 - val_loss: 1.5407e-04 - val_mse: 3.0814e-04\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 1.0595e-04 - mse: 2.1189e-04 - val_loss: 1.4406e-04 - val_mse: 2.8812e-04\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 1.0948e-04 - mse: 2.1895e-04 - val_loss: 1.7742e-04 - val_mse: 3.5485e-04\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 2s 17ms/step - loss: 9.8940e-05 - mse: 1.9788e-04 - val_loss: 1.4662e-04 - val_mse: 2.9323e-04\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 2s 17ms/step - loss: 9.7868e-05 - mse: 1.9574e-04 - val_loss: 1.2415e-04 - val_mse: 2.4830e-04\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 2s 16ms/step - loss: 9.6013e-05 - mse: 1.9203e-04 - val_loss: 1.4147e-04 - val_mse: 2.8293e-04\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 9.1148e-05 - mse: 1.8230e-04 - val_loss: 1.1328e-04 - val_mse: 2.2657e-04\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 8.9385e-05 - mse: 1.7877e-04 - val_loss: 1.2818e-04 - val_mse: 2.5636e-04\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 8.3188e-05 - mse: 1.6638e-04 - val_loss: 1.0846e-04 - val_mse: 2.1692e-04\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 8.1324e-05 - mse: 1.6265e-04 - val_loss: 1.4702e-04 - val_mse: 2.9405e-04\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 8.4116e-05 - mse: 1.6823e-04 - val_loss: 1.0090e-04 - val_mse: 2.0179e-04\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 7.5982e-05 - mse: 1.5196e-04 - val_loss: 1.4110e-04 - val_mse: 2.8220e-04\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 7.5385e-05 - mse: 1.5077e-04 - val_loss: 9.2915e-05 - val_mse: 1.8583e-04\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 8.3856e-05 - mse: 1.6771e-04 - val_loss: 9.5015e-05 - val_mse: 1.9003e-04\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 7.3207e-05 - mse: 1.4641e-04 - val_loss: 8.8230e-05 - val_mse: 1.7646e-04\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 7.2293e-05 - mse: 1.4459e-04 - val_loss: 8.5074e-05 - val_mse: 1.7015e-04\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 7.5527e-05 - mse: 1.5105e-04 - val_loss: 2.1904e-04 - val_mse: 4.3807e-04\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 7.4920e-05 - mse: 1.4984e-04 - val_loss: 8.3296e-05 - val_mse: 1.6659e-04\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 2s 18ms/step - loss: 7.8541e-05 - mse: 1.5708e-04 - val_loss: 1.3047e-04 - val_mse: 2.6095e-04\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 2s 16ms/step - loss: 6.4017e-05 - mse: 1.2803e-04 - val_loss: 1.2631e-04 - val_mse: 2.5262e-04\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 2s 17ms/step - loss: 6.1790e-05 - mse: 1.2358e-04 - val_loss: 7.6500e-05 - val_mse: 1.5300e-04\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 6.6253e-05 - mse: 1.3251e-04 - val_loss: 9.0910e-05 - val_mse: 1.8182e-04\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 2s 13ms/step - loss: 6.3828e-05 - mse: 1.2766e-04 - val_loss: 7.6550e-05 - val_mse: 1.5310e-04\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 2s 13ms/step - loss: 6.7898e-05 - mse: 1.3580e-04 - val_loss: 1.6810e-04 - val_mse: 3.3620e-04\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 6.0244e-05 - mse: 1.2049e-04 - val_loss: 7.3717e-05 - val_mse: 1.4743e-04\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.7849e-05 - mse: 1.1570e-04 - val_loss: 9.0420e-05 - val_mse: 1.8084e-04\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 6.1452e-05 - mse: 1.2290e-04 - val_loss: 8.8638e-05 - val_mse: 1.7728e-04\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.6753e-05 - mse: 1.1351e-04 - val_loss: 1.4808e-04 - val_mse: 2.9616e-04\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.8796e-05 - mse: 1.1759e-04 - val_loss: 6.5488e-05 - val_mse: 1.3098e-04\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.8598e-05 - mse: 1.1720e-04 - val_loss: 8.7991e-05 - val_mse: 1.7598e-04\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.8238e-05 - mse: 1.1648e-04 - val_loss: 9.7759e-05 - val_mse: 1.9552e-04\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.8961e-05 - mse: 1.1792e-04 - val_loss: 8.8284e-05 - val_mse: 1.7657e-04\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.7652e-05 - mse: 1.1530e-04 - val_loss: 7.4976e-05 - val_mse: 1.4995e-04\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.5677e-05 - mse: 1.1135e-04 - val_loss: 6.3530e-05 - val_mse: 1.2706e-04\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.9207e-05 - mse: 1.1841e-04 - val_loss: 6.1827e-05 - val_mse: 1.2365e-04\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.1309e-05 - mse: 1.0262e-04 - val_loss: 1.5329e-04 - val_mse: 3.0658e-04\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 6.2863e-05 - mse: 1.2573e-04 - val_loss: 9.6022e-05 - val_mse: 1.9204e-04\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 2s 18ms/step - loss: 5.7729e-05 - mse: 1.1546e-04 - val_loss: 6.5682e-05 - val_mse: 1.3136e-04\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.1284e-05 - mse: 1.0257e-04 - val_loss: 5.9788e-05 - val_mse: 1.1958e-04\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.1667e-05 - mse: 1.0333e-04 - val_loss: 7.6364e-05 - val_mse: 1.5273e-04\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.1053e-05 - mse: 1.0211e-04 - val_loss: 5.8899e-05 - val_mse: 1.1780e-04\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 6.1997e-05 - mse: 1.2399e-04 - val_loss: 7.1242e-05 - val_mse: 1.4248e-04\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.1368e-05 - mse: 1.0274e-04 - val_loss: 6.1113e-05 - val_mse: 1.2223e-04\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 2s 15ms/step - loss: 5.3030e-05 - mse: 1.0606e-04 - val_loss: 6.0149e-05 - val_mse: 1.2030e-04\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.6487e-05 - mse: 1.1297e-04 - val_loss: 6.0527e-05 - val_mse: 1.2105e-04\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 2s 14ms/step - loss: 5.1954e-05 - mse: 1.0391e-04 - val_loss: 1.2020e-04 - val_mse: 2.4040e-04\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 2s 16ms/step - loss: 6.0493e-05 - mse: 1.2099e-04 - val_loss: 1.1449e-04 - val_mse: 2.2898e-04\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 3s 18ms/step - loss: 4.8678e-05 - mse: 9.7356e-05 - val_loss: 5.7737e-05 - val_mse: 1.1547e-04\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 2s 17ms/step - loss: 4.8548e-05 - mse: 9.7097e-05 - val_loss: 6.9987e-05 - val_mse: 1.3997e-04\n",
      "pred.shape : (1020, 1) , y_test.shape : (1040,)\n",
      "5200길이의 데이터 적용 완료\n",
      " 길이: 5200, RMSE:1170.5895994430143\n",
      "train set 확인:  (4240, 4) (4240,) test set 확인:  (1060, 4) (1060,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 5s 20ms/step - loss: 1.8494e-04 - mse: 3.6989e-04 - val_loss: 1.6155e-04 - val_mse: 3.2310e-04\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 1.2959e-04 - mse: 2.5917e-04 - val_loss: 1.5395e-04 - val_mse: 3.0791e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 1.1891e-04 - mse: 2.3781e-04 - val_loss: 2.9358e-04 - val_mse: 5.8716e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 1.1288e-04 - mse: 2.2576e-04 - val_loss: 2.0140e-04 - val_mse: 4.0280e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 1.0502e-04 - mse: 2.1004e-04 - val_loss: 1.7114e-04 - val_mse: 3.4227e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 1.1204e-04 - mse: 2.2407e-04 - val_loss: 1.3639e-04 - val_mse: 2.7279e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 2s 18ms/step - loss: 9.8916e-05 - mse: 1.9783e-04 - val_loss: 1.3596e-04 - val_mse: 2.7192e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 9.9307e-05 - mse: 1.9861e-04 - val_loss: 1.2637e-04 - val_mse: 2.5275e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 9.3205e-05 - mse: 1.8641e-04 - val_loss: 1.2584e-04 - val_mse: 2.5168e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 9.9950e-05 - mse: 1.9990e-04 - val_loss: 1.5247e-04 - val_mse: 3.0494e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 9.1626e-05 - mse: 1.8325e-04 - val_loss: 1.1183e-04 - val_mse: 2.2366e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 8.8903e-05 - mse: 1.7781e-04 - val_loss: 1.4520e-04 - val_mse: 2.9040e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 8.4475e-05 - mse: 1.6895e-04 - val_loss: 1.0717e-04 - val_mse: 2.1434e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 8.0503e-05 - mse: 1.6101e-04 - val_loss: 9.4007e-05 - val_mse: 1.8801e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 7.1948e-05 - mse: 1.4390e-04 - val_loss: 9.3104e-05 - val_mse: 1.8621e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 6.9465e-05 - mse: 1.3893e-04 - val_loss: 9.3652e-05 - val_mse: 1.8730e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 7.4615e-05 - mse: 1.4923e-04 - val_loss: 8.0534e-05 - val_mse: 1.6107e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 6.8015e-05 - mse: 1.3603e-04 - val_loss: 9.3758e-05 - val_mse: 1.8752e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 6.5626e-05 - mse: 1.3125e-04 - val_loss: 1.0480e-04 - val_mse: 2.0961e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 6.3901e-05 - mse: 1.2780e-04 - val_loss: 7.6369e-05 - val_mse: 1.5274e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 5.7649e-05 - mse: 1.1530e-04 - val_loss: 7.6817e-05 - val_mse: 1.5363e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 6.2093e-05 - mse: 1.2419e-04 - val_loss: 6.6467e-05 - val_mse: 1.3293e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.7458e-05 - mse: 1.1492e-04 - val_loss: 9.6300e-05 - val_mse: 1.9260e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 5.5561e-05 - mse: 1.1112e-04 - val_loss: 6.0131e-05 - val_mse: 1.2026e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 5.7657e-05 - mse: 1.1531e-04 - val_loss: 8.8652e-05 - val_mse: 1.7730e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 5.4924e-05 - mse: 1.0985e-04 - val_loss: 6.4112e-05 - val_mse: 1.2822e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.1286e-05 - mse: 1.0257e-04 - val_loss: 8.2854e-05 - val_mse: 1.6571e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.7362e-05 - mse: 9.4723e-05 - val_loss: 5.5772e-05 - val_mse: 1.1154e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.6384e-05 - mse: 1.1277e-04 - val_loss: 6.2521e-05 - val_mse: 1.2504e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 4.7741e-05 - mse: 9.5482e-05 - val_loss: 6.4902e-05 - val_mse: 1.2980e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.5636e-05 - mse: 9.1271e-05 - val_loss: 5.2537e-05 - val_mse: 1.0507e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.1224e-05 - mse: 1.0245e-04 - val_loss: 1.2559e-04 - val_mse: 2.5118e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.9782e-05 - mse: 9.9564e-05 - val_loss: 9.4585e-05 - val_mse: 1.8917e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.1109e-05 - mse: 1.0222e-04 - val_loss: 1.0269e-04 - val_mse: 2.0539e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 4.7365e-05 - mse: 9.4731e-05 - val_loss: 7.8176e-05 - val_mse: 1.5635e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 4.5935e-05 - mse: 9.1870e-05 - val_loss: 5.0092e-05 - val_mse: 1.0018e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 4.5971e-05 - mse: 9.1941e-05 - val_loss: 5.0846e-05 - val_mse: 1.0169e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.4342e-05 - mse: 8.8685e-05 - val_loss: 9.8333e-05 - val_mse: 1.9667e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 4.3890e-05 - mse: 8.7780e-05 - val_loss: 7.5524e-05 - val_mse: 1.5105e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 4.7598e-05 - mse: 9.5197e-05 - val_loss: 4.9069e-05 - val_mse: 9.8139e-05\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 4.3943e-05 - mse: 8.7887e-05 - val_loss: 5.0263e-05 - val_mse: 1.0053e-04\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.7208e-05 - mse: 9.4415e-05 - val_loss: 8.4707e-05 - val_mse: 1.6941e-04\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.6881e-05 - mse: 9.3762e-05 - val_loss: 8.4192e-05 - val_mse: 1.6838e-04\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.3233e-05 - mse: 8.6467e-05 - val_loss: 9.8433e-05 - val_mse: 1.9687e-04\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.1491e-05 - mse: 8.2981e-05 - val_loss: 4.9578e-05 - val_mse: 9.9156e-05\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.6146e-05 - mse: 9.2291e-05 - val_loss: 6.7207e-05 - val_mse: 1.3441e-04\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.4504e-05 - mse: 8.9009e-05 - val_loss: 4.8331e-05 - val_mse: 9.6662e-05\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.4870e-05 - mse: 8.9740e-05 - val_loss: 4.7013e-05 - val_mse: 9.4027e-05\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.2067e-05 - mse: 1.0413e-04 - val_loss: 2.3361e-04 - val_mse: 4.6722e-04\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 5.6664e-05 - mse: 1.1333e-04 - val_loss: 7.1044e-05 - val_mse: 1.4209e-04\n",
      "pred.shape : (1040, 1) , y_test.shape : (1060,)\n",
      "5300길이의 데이터 적용 완료\n",
      " 길이: 5300, RMSE:1183.6814589012838\n",
      "train set 확인:  (4320, 4) (4320,) test set 확인:  (1080, 4) (1080,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "135/135 [==============================] - 5s 18ms/step - loss: 3.1116e-04 - mse: 6.2232e-04 - val_loss: 4.6854e-04 - val_mse: 9.3709e-04\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 1.2762e-04 - mse: 2.5525e-04 - val_loss: 3.1199e-04 - val_mse: 6.2398e-04\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 1.1555e-04 - mse: 2.3110e-04 - val_loss: 1.8403e-04 - val_mse: 3.6806e-04\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 1.1182e-04 - mse: 2.2363e-04 - val_loss: 1.4978e-04 - val_mse: 2.9956e-04\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.1773e-04 - mse: 2.3546e-04 - val_loss: 1.4752e-04 - val_mse: 2.9503e-04\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.0798e-04 - mse: 2.1596e-04 - val_loss: 1.4288e-04 - val_mse: 2.8576e-04\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.0327e-04 - mse: 2.0653e-04 - val_loss: 1.3738e-04 - val_mse: 2.7475e-04\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 1.0169e-04 - mse: 2.0338e-04 - val_loss: 1.4297e-04 - val_mse: 2.8593e-04\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 9.0777e-05 - mse: 1.8155e-04 - val_loss: 1.2618e-04 - val_mse: 2.5236e-04\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 9.0962e-05 - mse: 1.8192e-04 - val_loss: 1.4619e-04 - val_mse: 2.9238e-04\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 9.2199e-05 - mse: 1.8440e-04 - val_loss: 1.3052e-04 - val_mse: 2.6105e-04\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 8.3933e-05 - mse: 1.6787e-04 - val_loss: 1.1478e-04 - val_mse: 2.2956e-04\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 8.7153e-05 - mse: 1.7431e-04 - val_loss: 1.3475e-04 - val_mse: 2.6951e-04\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 7.9427e-05 - mse: 1.5885e-04 - val_loss: 1.1673e-04 - val_mse: 2.3345e-04\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 7.9091e-05 - mse: 1.5818e-04 - val_loss: 1.0506e-04 - val_mse: 2.1013e-04\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 2s 18ms/step - loss: 8.3392e-05 - mse: 1.6678e-04 - val_loss: 1.0194e-04 - val_mse: 2.0388e-04\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 3s 19ms/step - loss: 7.7283e-05 - mse: 1.5457e-04 - val_loss: 1.6939e-04 - val_mse: 3.3877e-04\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 3s 21ms/step - loss: 8.0968e-05 - mse: 1.6194e-04 - val_loss: 9.6503e-05 - val_mse: 1.9301e-04\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 7.8521e-05 - mse: 1.5704e-04 - val_loss: 1.1985e-04 - val_mse: 2.3971e-04\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 8.1350e-05 - mse: 1.6270e-04 - val_loss: 1.5180e-04 - val_mse: 3.0359e-04\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 2s 17ms/step - loss: 7.6411e-05 - mse: 1.5282e-04 - val_loss: 9.8919e-05 - val_mse: 1.9784e-04\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 2s 17ms/step - loss: 7.0916e-05 - mse: 1.4183e-04 - val_loss: 8.8228e-05 - val_mse: 1.7646e-04\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 3s 18ms/step - loss: 6.9015e-05 - mse: 1.3803e-04 - val_loss: 1.0448e-04 - val_mse: 2.0897e-04\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 6.5072e-05 - mse: 1.3014e-04 - val_loss: 1.4424e-04 - val_mse: 2.8847e-04\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 6.5970e-05 - mse: 1.3194e-04 - val_loss: 7.9681e-05 - val_mse: 1.5936e-04\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 6.4407e-05 - mse: 1.2881e-04 - val_loss: 8.1429e-05 - val_mse: 1.6286e-04\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.9074e-05 - mse: 1.1815e-04 - val_loss: 2.0901e-04 - val_mse: 4.1802e-04\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 7.3579e-05 - mse: 1.4716e-04 - val_loss: 1.5612e-04 - val_mse: 3.1224e-04\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 3s 18ms/step - loss: 6.0409e-05 - mse: 1.2082e-04 - val_loss: 8.4639e-05 - val_mse: 1.6928e-04\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 5.7547e-05 - mse: 1.1509e-04 - val_loss: 7.8786e-05 - val_mse: 1.5757e-04\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.5248e-05 - mse: 1.1050e-04 - val_loss: 6.6773e-05 - val_mse: 1.3355e-04\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 5.8474e-05 - mse: 1.1695e-04 - val_loss: 6.4225e-05 - val_mse: 1.2845e-04\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.2232e-05 - mse: 1.0446e-04 - val_loss: 6.2774e-05 - val_mse: 1.2555e-04\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.3854e-05 - mse: 1.0771e-04 - val_loss: 6.1902e-05 - val_mse: 1.2380e-04\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.4831e-05 - mse: 1.0966e-04 - val_loss: 8.7085e-05 - val_mse: 1.7417e-04\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.4089e-05 - mse: 1.0818e-04 - val_loss: 5.9771e-05 - val_mse: 1.1954e-04\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.4435e-05 - mse: 1.0887e-04 - val_loss: 1.1817e-04 - val_mse: 2.3633e-04\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 4.8723e-05 - mse: 9.7446e-05 - val_loss: 7.4069e-05 - val_mse: 1.4814e-04\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.1517e-05 - mse: 1.0303e-04 - val_loss: 1.4803e-04 - val_mse: 2.9605e-04\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.4549e-05 - mse: 1.0910e-04 - val_loss: 6.1006e-05 - val_mse: 1.2201e-04\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.2907e-05 - mse: 1.0581e-04 - val_loss: 7.2651e-05 - val_mse: 1.4530e-04\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 2s 18ms/step - loss: 4.4321e-05 - mse: 8.8642e-05 - val_loss: 5.5249e-05 - val_mse: 1.1050e-04\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 3s 18ms/step - loss: 5.0772e-05 - mse: 1.0154e-04 - val_loss: 7.7894e-05 - val_mse: 1.5579e-04\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 4.5947e-05 - mse: 9.1894e-05 - val_loss: 6.4641e-05 - val_mse: 1.2928e-04\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 4.6116e-05 - mse: 9.2231e-05 - val_loss: 5.8584e-05 - val_mse: 1.1717e-04\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 5.2750e-05 - mse: 1.0550e-04 - val_loss: 5.1095e-05 - val_mse: 1.0219e-04\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 4.8898e-05 - mse: 9.7796e-05 - val_loss: 5.0712e-05 - val_mse: 1.0142e-04\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 4.4652e-05 - mse: 8.9305e-05 - val_loss: 5.2503e-05 - val_mse: 1.0501e-04\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 4.3602e-05 - mse: 8.7204e-05 - val_loss: 4.9453e-05 - val_mse: 9.8905e-05\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 4.2393e-05 - mse: 8.4785e-05 - val_loss: 5.7619e-05 - val_mse: 1.1524e-04\n",
      "pred.shape : (1060, 1) , y_test.shape : (1080,)\n",
      "5400길이의 데이터 적용 완료\n",
      " 길이: 5400, RMSE:1068.6334907803816\n",
      "train set 확인:  (4400, 4) (4400,) test set 확인:  (1100, 4) (1100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "137/137 [==============================] - 5s 19ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 1.8821e-04 - val_mse: 3.7642e-04\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2711e-04 - mse: 2.5422e-04 - val_loss: 2.4070e-04 - val_mse: 4.8141e-04\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.1562e-04 - mse: 2.3123e-04 - val_loss: 1.6050e-04 - val_mse: 3.2100e-04\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.1082e-04 - mse: 2.2164e-04 - val_loss: 1.5487e-04 - val_mse: 3.0975e-04\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.0004e-04 - mse: 2.0008e-04 - val_loss: 1.6951e-04 - val_mse: 3.3902e-04\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 9.5231e-05 - mse: 1.9046e-04 - val_loss: 1.4179e-04 - val_mse: 2.8358e-04\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 9.1729e-05 - mse: 1.8346e-04 - val_loss: 1.5294e-04 - val_mse: 3.0587e-04\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 9.1646e-05 - mse: 1.8329e-04 - val_loss: 1.3494e-04 - val_mse: 2.6988e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 8.4906e-05 - mse: 1.6981e-04 - val_loss: 1.9598e-04 - val_mse: 3.9197e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 8.5204e-05 - mse: 1.7041e-04 - val_loss: 1.1331e-04 - val_mse: 2.2663e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 8.1280e-05 - mse: 1.6256e-04 - val_loss: 1.8714e-04 - val_mse: 3.7429e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 7.6439e-05 - mse: 1.5288e-04 - val_loss: 1.3932e-04 - val_mse: 2.7865e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 7.5038e-05 - mse: 1.5008e-04 - val_loss: 9.9749e-05 - val_mse: 1.9950e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 7.0211e-05 - mse: 1.4042e-04 - val_loss: 1.0559e-04 - val_mse: 2.1118e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 6.6283e-05 - mse: 1.3257e-04 - val_loss: 8.7049e-05 - val_mse: 1.7410e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 6.7449e-05 - mse: 1.3490e-04 - val_loss: 8.9547e-05 - val_mse: 1.7909e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 6.4213e-05 - mse: 1.2843e-04 - val_loss: 2.4423e-04 - val_mse: 4.8847e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 6.2907e-05 - mse: 1.2581e-04 - val_loss: 9.1766e-05 - val_mse: 1.8353e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 5.9263e-05 - mse: 1.1853e-04 - val_loss: 9.9173e-05 - val_mse: 1.9835e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 5.7564e-05 - mse: 1.1513e-04 - val_loss: 8.2409e-05 - val_mse: 1.6482e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.8704e-05 - mse: 1.1741e-04 - val_loss: 9.0946e-05 - val_mse: 1.8189e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.5694e-05 - mse: 1.1139e-04 - val_loss: 1.0785e-04 - val_mse: 2.1570e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.9738e-05 - mse: 1.1948e-04 - val_loss: 7.6914e-05 - val_mse: 1.5383e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 6.1072e-05 - mse: 1.2214e-04 - val_loss: 7.7800e-05 - val_mse: 1.5560e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 7.0235e-05 - mse: 1.4047e-04 - val_loss: 2.8911e-04 - val_mse: 5.7823e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.5545e-05 - mse: 1.1109e-04 - val_loss: 6.9670e-05 - val_mse: 1.3934e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.6504e-05 - mse: 1.1301e-04 - val_loss: 2.3988e-04 - val_mse: 4.7976e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.3465e-05 - mse: 1.0693e-04 - val_loss: 1.0051e-04 - val_mse: 2.0102e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.9963e-05 - mse: 1.1993e-04 - val_loss: 1.0932e-04 - val_mse: 2.1864e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 5.2808e-05 - mse: 1.0562e-04 - val_loss: 1.0999e-04 - val_mse: 2.1999e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 5.4540e-05 - mse: 1.0908e-04 - val_loss: 8.2137e-05 - val_mse: 1.6427e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.0749e-05 - mse: 1.0150e-04 - val_loss: 9.1378e-05 - val_mse: 1.8276e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.6086e-05 - mse: 1.1217e-04 - val_loss: 7.5948e-05 - val_mse: 1.5190e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.4029e-05 - mse: 1.0806e-04 - val_loss: 1.3481e-04 - val_mse: 2.6963e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 5.2160e-05 - mse: 1.0432e-04 - val_loss: 7.4591e-05 - val_mse: 1.4918e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 4.9932e-05 - mse: 9.9864e-05 - val_loss: 9.5144e-05 - val_mse: 1.9029e-04\n",
      "pred.shape : (1080, 1) , y_test.shape : (1100,)\n",
      "5500길이의 데이터 적용 완료\n",
      " 길이: 5500, RMSE:1373.2122303417332\n",
      "train set 확인:  (4480, 4) (4480,) test set 확인:  (1120, 4) (1120,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 5s 18ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 2.7136e-04 - val_mse: 5.4272e-04\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.4248e-04 - mse: 2.8496e-04 - val_loss: 2.6173e-04 - val_mse: 5.2346e-04\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 1.1249e-04 - mse: 2.2497e-04 - val_loss: 1.7611e-04 - val_mse: 3.5222e-04\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 1.1177e-04 - mse: 2.2353e-04 - val_loss: 2.1476e-04 - val_mse: 4.2951e-04\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 1.1138e-04 - mse: 2.2277e-04 - val_loss: 3.6103e-04 - val_mse: 7.2206e-04\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 3s 17ms/step - loss: 1.0751e-04 - mse: 2.1503e-04 - val_loss: 1.5116e-04 - val_mse: 3.0233e-04\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 9.5978e-05 - mse: 1.9196e-04 - val_loss: 1.6658e-04 - val_mse: 3.3315e-04\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 9.8177e-05 - mse: 1.9635e-04 - val_loss: 1.7125e-04 - val_mse: 3.4251e-04\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 9.8404e-05 - mse: 1.9681e-04 - val_loss: 1.3673e-04 - val_mse: 2.7347e-04\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 9.7034e-05 - mse: 1.9407e-04 - val_loss: 1.3748e-04 - val_mse: 2.7497e-04\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 8.9863e-05 - mse: 1.7973e-04 - val_loss: 1.2377e-04 - val_mse: 2.4753e-04\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 8.4480e-05 - mse: 1.6896e-04 - val_loss: 1.2936e-04 - val_mse: 2.5872e-04\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 8.0982e-05 - mse: 1.6196e-04 - val_loss: 1.2142e-04 - val_mse: 2.4284e-04\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 8.6491e-05 - mse: 1.7298e-04 - val_loss: 1.6257e-04 - val_mse: 3.2514e-04\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 9.2401e-05 - mse: 1.8480e-04 - val_loss: 1.0939e-04 - val_mse: 2.1877e-04\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 7.5016e-05 - mse: 1.5003e-04 - val_loss: 1.1775e-04 - val_mse: 2.3550e-04\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 7.2174e-05 - mse: 1.4435e-04 - val_loss: 1.0559e-04 - val_mse: 2.1117e-04\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 7.5454e-05 - mse: 1.5091e-04 - val_loss: 1.3124e-04 - val_mse: 2.6249e-04\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 3s 18ms/step - loss: 7.4412e-05 - mse: 1.4882e-04 - val_loss: 1.0243e-04 - val_mse: 2.0485e-04\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 6.7285e-05 - mse: 1.3457e-04 - val_loss: 1.0310e-04 - val_mse: 2.0620e-04\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 6.7753e-05 - mse: 1.3551e-04 - val_loss: 1.3093e-04 - val_mse: 2.6186e-04\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 6.7746e-05 - mse: 1.3549e-04 - val_loss: 9.4013e-05 - val_mse: 1.8803e-04\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 7.2942e-05 - mse: 1.4588e-04 - val_loss: 1.3361e-04 - val_mse: 2.6722e-04\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 7.3699e-05 - mse: 1.4740e-04 - val_loss: 9.6165e-05 - val_mse: 1.9233e-04\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 8.0610e-05 - mse: 1.6122e-04 - val_loss: 1.3813e-04 - val_mse: 2.7626e-04\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 7.5766e-05 - mse: 1.5153e-04 - val_loss: 1.7788e-04 - val_mse: 3.5576e-04\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 6.6062e-05 - mse: 1.3212e-04 - val_loss: 8.8855e-05 - val_mse: 1.7771e-04\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 6.3499e-05 - mse: 1.2700e-04 - val_loss: 1.1963e-04 - val_mse: 2.3926e-04\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 6.6837e-05 - mse: 1.3367e-04 - val_loss: 1.2871e-04 - val_mse: 2.5741e-04\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 7.3217e-05 - mse: 1.4643e-04 - val_loss: 9.1153e-05 - val_mse: 1.8231e-04\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 3s 17ms/step - loss: 6.1273e-05 - mse: 1.2255e-04 - val_loss: 8.2480e-05 - val_mse: 1.6496e-04\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 3s 18ms/step - loss: 5.9776e-05 - mse: 1.1955e-04 - val_loss: 8.6949e-05 - val_mse: 1.7390e-04\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.8823e-05 - mse: 1.1765e-04 - val_loss: 8.4401e-05 - val_mse: 1.6880e-04\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 6.3703e-05 - mse: 1.2741e-04 - val_loss: 1.5170e-04 - val_mse: 3.0339e-04\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.9176e-05 - mse: 1.1835e-04 - val_loss: 1.0275e-04 - val_mse: 2.0550e-04\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 6.0744e-05 - mse: 1.2149e-04 - val_loss: 7.6907e-05 - val_mse: 1.5381e-04\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 5.5591e-05 - mse: 1.1118e-04 - val_loss: 1.2133e-04 - val_mse: 2.4266e-04\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 6.0120e-05 - mse: 1.2024e-04 - val_loss: 7.6138e-05 - val_mse: 1.5228e-04\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 7.1234e-05 - mse: 1.4247e-04 - val_loss: 1.5958e-04 - val_mse: 3.1915e-04\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.3694e-05 - mse: 1.0739e-04 - val_loss: 1.5685e-04 - val_mse: 3.1371e-04\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 5.7412e-05 - mse: 1.1482e-04 - val_loss: 8.3123e-05 - val_mse: 1.6625e-04\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.7585e-05 - mse: 1.1517e-04 - val_loss: 9.5493e-05 - val_mse: 1.9099e-04\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 3s 18ms/step - loss: 5.4825e-05 - mse: 1.0965e-04 - val_loss: 7.1296e-05 - val_mse: 1.4259e-04\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 5.7253e-05 - mse: 1.1451e-04 - val_loss: 8.7678e-05 - val_mse: 1.7536e-04\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 3s 19ms/step - loss: 6.4102e-05 - mse: 1.2820e-04 - val_loss: 7.8768e-05 - val_mse: 1.5754e-04\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 2s 16ms/step - loss: 5.7275e-05 - mse: 1.1455e-04 - val_loss: 1.3238e-04 - val_mse: 2.6476e-04\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.3467e-05 - mse: 1.0693e-04 - val_loss: 9.6789e-05 - val_mse: 1.9358e-04\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 6.2358e-05 - mse: 1.2472e-04 - val_loss: 7.5027e-05 - val_mse: 1.5005e-04\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 5.7704e-05 - mse: 1.1541e-04 - val_loss: 1.1580e-04 - val_mse: 2.3161e-04\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 5.1580e-05 - mse: 1.0316e-04 - val_loss: 8.9850e-05 - val_mse: 1.7970e-04\n",
      "pred.shape : (1100, 1) , y_test.shape : (1120,)\n",
      "5600길이의 데이터 적용 완료\n",
      " 길이: 5600, RMSE:1334.458802678908\n",
      "train set 확인:  (4507, 4) (4507,) test set 확인:  (1127, 4) (1127,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\216166328.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - 6s 19ms/step - loss: 2.4954e-04 - mse: 4.9907e-04 - val_loss: 1.5299e-04 - val_mse: 3.0597e-04\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 1.0780e-04 - mse: 2.1561e-04 - val_loss: 1.5141e-04 - val_mse: 3.0282e-04\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 9.4011e-05 - mse: 1.8802e-04 - val_loss: 1.3630e-04 - val_mse: 2.7261e-04\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 8.8472e-05 - mse: 1.7694e-04 - val_loss: 1.9005e-04 - val_mse: 3.8011e-04\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 8.7049e-05 - mse: 1.7410e-04 - val_loss: 1.3969e-04 - val_mse: 2.7938e-04\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 8.6271e-05 - mse: 1.7254e-04 - val_loss: 1.3792e-04 - val_mse: 2.7585e-04\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 7.9445e-05 - mse: 1.5889e-04 - val_loss: 1.1646e-04 - val_mse: 2.3292e-04\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 8.0281e-05 - mse: 1.6056e-04 - val_loss: 2.1249e-04 - val_mse: 4.2498e-04\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 7.9499e-05 - mse: 1.5900e-04 - val_loss: 1.4674e-04 - val_mse: 2.9349e-04\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 7.3155e-05 - mse: 1.4631e-04 - val_loss: 1.1840e-04 - val_mse: 2.3680e-04\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 3s 17ms/step - loss: 7.4631e-05 - mse: 1.4926e-04 - val_loss: 1.2690e-04 - val_mse: 2.5379e-04\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 7.5506e-05 - mse: 1.5101e-04 - val_loss: 1.2209e-04 - val_mse: 2.4418e-04\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 3s 17ms/step - loss: 6.4769e-05 - mse: 1.2954e-04 - val_loss: 9.0096e-05 - val_mse: 1.8019e-04\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 6.6839e-05 - mse: 1.3368e-04 - val_loss: 8.7294e-05 - val_mse: 1.7459e-04\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 6.2566e-05 - mse: 1.2513e-04 - val_loss: 1.4214e-04 - val_mse: 2.8429e-04\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 6.2792e-05 - mse: 1.2558e-04 - val_loss: 9.0065e-05 - val_mse: 1.8013e-04\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 6.5483e-05 - mse: 1.3097e-04 - val_loss: 1.4347e-04 - val_mse: 2.8694e-04\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 2s 17ms/step - loss: 5.8953e-05 - mse: 1.1791e-04 - val_loss: 9.0228e-05 - val_mse: 1.8046e-04\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 5.7682e-05 - mse: 1.1536e-04 - val_loss: 8.0028e-05 - val_mse: 1.6006e-04\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 2s 14ms/step - loss: 5.3075e-05 - mse: 1.0615e-04 - val_loss: 7.9490e-05 - val_mse: 1.5898e-04\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 5.2550e-05 - mse: 1.0510e-04 - val_loss: 7.0724e-05 - val_mse: 1.4145e-04\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.9242e-05 - mse: 9.8485e-05 - val_loss: 8.8506e-05 - val_mse: 1.7701e-04\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.7903e-05 - mse: 9.5805e-05 - val_loss: 9.3224e-05 - val_mse: 1.8645e-04\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 5.1517e-05 - mse: 1.0303e-04 - val_loss: 1.1613e-04 - val_mse: 2.3226e-04\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.8149e-05 - mse: 9.6299e-05 - val_loss: 6.0641e-05 - val_mse: 1.2128e-04\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 2s 17ms/step - loss: 4.8868e-05 - mse: 9.7735e-05 - val_loss: 6.2631e-05 - val_mse: 1.2526e-04\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 5.0685e-05 - mse: 1.0137e-04 - val_loss: 5.6650e-05 - val_mse: 1.1330e-04\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 5.1832e-05 - mse: 1.0366e-04 - val_loss: 5.5619e-05 - val_mse: 1.1124e-04\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.5947e-05 - mse: 9.1894e-05 - val_loss: 5.7633e-05 - val_mse: 1.1527e-04\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.2345e-05 - mse: 8.4691e-05 - val_loss: 8.0611e-05 - val_mse: 1.6122e-04\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.4622e-05 - mse: 8.9245e-05 - val_loss: 6.0316e-05 - val_mse: 1.2063e-04\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.9809e-05 - mse: 9.9617e-05 - val_loss: 8.2389e-05 - val_mse: 1.6478e-04\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.7957e-05 - mse: 9.5915e-05 - val_loss: 5.3436e-05 - val_mse: 1.0687e-04\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.2831e-05 - mse: 8.5663e-05 - val_loss: 2.2996e-04 - val_mse: 4.5992e-04\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.5347e-05 - mse: 9.0693e-05 - val_loss: 1.0830e-04 - val_mse: 2.1661e-04\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 4.4889e-05 - mse: 8.9777e-05 - val_loss: 1.2731e-04 - val_mse: 2.5463e-04\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.4521e-05 - mse: 8.9042e-05 - val_loss: 1.2676e-04 - val_mse: 2.5352e-04\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 5.0535e-05 - mse: 1.0107e-04 - val_loss: 9.3809e-05 - val_mse: 1.8762e-04\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 4.7336e-05 - mse: 9.4673e-05 - val_loss: 6.5825e-05 - val_mse: 1.3165e-04\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 3s 17ms/step - loss: 4.1451e-05 - mse: 8.2902e-05 - val_loss: 5.4936e-05 - val_mse: 1.0987e-04\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 2s 17ms/step - loss: 4.1267e-05 - mse: 8.2533e-05 - val_loss: 7.8469e-05 - val_mse: 1.5694e-04\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 3.9688e-05 - mse: 7.9375e-05 - val_loss: 1.7392e-04 - val_mse: 3.4785e-04\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 4.2587e-05 - mse: 8.5174e-05 - val_loss: 5.5935e-05 - val_mse: 1.1187e-04\n",
      "pred.shape : (1107, 1) , y_test.shape : (1127,)\n",
      "5700길이의 데이터 적용 완료\n",
      " 길이: 5700, RMSE:1052.8990116699704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2000.1874048673167,\n",
       " 992.6352116071897,\n",
       " 1310.980702912059,\n",
       " 892.4851355080455,\n",
       " 2443.799214538378,\n",
       " 746.4808251993071,\n",
       " 809.669413453167,\n",
       " 690.354535421328,\n",
       " 735.9243993092067,\n",
       " 759.9160038522459,\n",
       " 611.1530732524569,\n",
       " 644.4335079523909,\n",
       " 616.4122345630259,\n",
       " 711.715252716196,\n",
       " 640.9997477265415,\n",
       " 602.9435542442767,\n",
       " 680.2545695018231,\n",
       " 594.4011921230186,\n",
       " 743.485634446954,\n",
       " 690.4013866390744,\n",
       " 669.0602954657662,\n",
       " 758.065361279851,\n",
       " 812.2081652872217,\n",
       " 1022.944393040216,\n",
       " 830.7767734294065,\n",
       " 1066.824267637055,\n",
       " 1054.9744041495994,\n",
       " 1152.0796199526499,\n",
       " 1157.02745821256,\n",
       " 1175.3136008579515,\n",
       " 995.431417967325,\n",
       " 1071.5864048476176,\n",
       " 1377.799622509745,\n",
       " 1153.0869891641162,\n",
       " 1088.1386426684091,\n",
       " 1152.0099160077332,\n",
       " 1103.7574482595073,\n",
       " 927.0544520119569,\n",
       " 1141.2562457375145,\n",
       " 1025.0851638414542,\n",
       " 995.6080381356913,\n",
       " 1081.4743433103451,\n",
       " 977.8036161716806,\n",
       " 972.9068908976415,\n",
       " 1176.0496917134292,\n",
       " 1020.9895199716765,\n",
       " 1721.7352767749737,\n",
       " 1383.237040372974,\n",
       " 1229.303117463796,\n",
       " 991.4013876637882,\n",
       " 1170.5895994430143,\n",
       " 1183.6814589012838,\n",
       " 1068.6334907803816,\n",
       " 1373.2122303417332,\n",
       " 1334.458802678908,\n",
       " 1052.8990116699704]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)\n",
    "\n",
    "WINDOW_SIZE=20\n",
    "BATCH_SIZE=32\n",
    "\n",
    "result = []\n",
    "df_origin = pd.read_csv('leader_stocks_data/KT&G_기타제조업.csv')\n",
    "for i in range(2, len(df_origin)//100+2):\n",
    "    # 데이터 불러오기\n",
    "    df = pd.read_csv('leader_stocks_data/KT&G_기타제조업.csv')\n",
    "    df = df.set_index(keys=['Date'], inplace=False, drop=True)\n",
    "    df = df.drop('Close', axis = 1)\n",
    "    df.rename(columns ={'Adj Close':'Close'}, inplace = True)\n",
    "    # 원하는 크기로 데이터 자르기\n",
    "    df = df[-i*100:]\n",
    "    # 피처값, 타켓 스케일링\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['High','Low','Open', 'Volume']] = scaler.fit_transform(df[['High','Low','Open', 'Volume']])\n",
    "    df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1,1))\n",
    "    # train, test set 분리\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n",
    "    print('train set 확인: ' ,  x_train.shape, y_train.shape, 'test set 확인: ',  x_test.shape, y_test.shape)\n",
    "\n",
    "    train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "    test_data = windowed_dataset(y_test, WINDOW_SIZE, BATCH_SIZE, False) \n",
    "    # lstm 모델링\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=5,\n",
    "               padding=\"causal\",\n",
    "               activation=\"relu\",\n",
    "               input_shape=[WINDOW_SIZE, 1]),\n",
    "        LSTM(16, activation='tanh'),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1),\n",
    "    ])\n",
    "    loss = Huber()\n",
    "    optimizer = Adam(0.0005)\n",
    "    model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse']) \n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=10) \n",
    "    # lstm 적용                                        \n",
    "    history = model.fit(train_data, \n",
    "                        validation_data=(test_data), \n",
    "                        epochs=50, \n",
    "                        callbacks=[earlystopping])\n",
    "    pred = model.predict(test_data)\n",
    "    print(f\"pred.shape : {pred.shape} , y_test.shape : {y_test.shape}\")\n",
    "    # rescaleing 작업\n",
    "    rescaled_y_test = scaler.inverse_transform(np.array(y_test).reshape(-1, 1))\n",
    "    rescaled_pred = scaler.inverse_transform(np.array(pred).reshape(-1,1))\n",
    "    # 평가지표(RMSE) 계산\n",
    "    RMSE = np.sqrt(mean_squared_error(rescaled_y_test[20:], rescaled_pred))\n",
    "    result.append(RMSE)\n",
    "    print(f\"{i * 100}길이의 데이터 적용 완료\\n 길이: {i * 100}, RMSE:{RMSE}\")\n",
    "    result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_origin = pd.read_csv('leader_stocks_data/KT&G_기타제조업.csv')\n",
    "data_size = list(range(200, len(df_origin), 100))\n",
    "data_size.append(len(df_origin))\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(data_size, result)\n",
    "plt.tick_params(axis='x', labelcolor='white')\n",
    "plt.tick_params(axis='y', labelcolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-12-25</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33765.574219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-12-26</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33765.574219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-12-27</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33765.574219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-12-28</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>47745.351562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33765.574219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>48723.742188</td>\n",
       "      <td>48723.742188</td>\n",
       "      <td>48723.742188</td>\n",
       "      <td>48723.742188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34457.492188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>52800.000000</td>\n",
       "      <td>51100.000000</td>\n",
       "      <td>52600.000000</td>\n",
       "      <td>51400.000000</td>\n",
       "      <td>879936.0</td>\n",
       "      <td>51400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>51500.000000</td>\n",
       "      <td>50600.000000</td>\n",
       "      <td>51400.000000</td>\n",
       "      <td>50800.000000</td>\n",
       "      <td>1269827.0</td>\n",
       "      <td>50800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>48500.000000</td>\n",
       "      <td>51000.000000</td>\n",
       "      <td>48650.000000</td>\n",
       "      <td>2174679.0</td>\n",
       "      <td>48650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>49050.000000</td>\n",
       "      <td>47750.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>2092984.0</td>\n",
       "      <td>47900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>47500.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>49000.000000</td>\n",
       "      <td>1710049.0</td>\n",
       "      <td>49000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5128 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          High           Low          Open         Close  \\\n",
       "0     2001-12-25  47745.351562  47745.351562  47745.351562  47745.351562   \n",
       "1     2001-12-26  47745.351562  47745.351562  47745.351562  47745.351562   \n",
       "2     2001-12-27  47745.351562  47745.351562  47745.351562  47745.351562   \n",
       "3     2001-12-28  47745.351562  47745.351562  47745.351562  47745.351562   \n",
       "4     2001-12-31  48723.742188  48723.742188  48723.742188  48723.742188   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "5123  2022-06-20  52800.000000  51100.000000  52600.000000  51400.000000   \n",
       "5124  2022-06-21  51500.000000  50600.000000  51400.000000  50800.000000   \n",
       "5125  2022-06-22  51200.000000  48500.000000  51000.000000  48650.000000   \n",
       "5126  2022-06-23  49050.000000  47750.000000  48000.000000  47900.000000   \n",
       "5127  2022-06-24  49500.000000  47500.000000  47900.000000  49000.000000   \n",
       "\n",
       "         Volume     Adj Close  \n",
       "0           0.0  33765.574219  \n",
       "1           0.0  33765.574219  \n",
       "2           0.0  33765.574219  \n",
       "3           0.0  33765.574219  \n",
       "4           0.0  34457.492188  \n",
       "...         ...           ...  \n",
       "5123   879936.0  51400.000000  \n",
       "5124  1269827.0  50800.000000  \n",
       "5125  2174679.0  48650.000000  \n",
       "5126  2092984.0  47900.000000  \n",
       "5127  1710049.0  49000.000000  \n",
       "\n",
       "[5128 rows x 7 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = pd.read_csv(f'leader_stocks_data/{file_list[4]}')\n",
    "df_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>2008-10-10</td>\n",
       "      <td>47109.402344</td>\n",
       "      <td>40065.003906</td>\n",
       "      <td>47109.402344</td>\n",
       "      <td>45984.253906</td>\n",
       "      <td>13291017.0</td>\n",
       "      <td>32520.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>2008-10-13</td>\n",
       "      <td>50387.000000</td>\n",
       "      <td>45543.980469</td>\n",
       "      <td>47109.402344</td>\n",
       "      <td>49604.289062</td>\n",
       "      <td>3246863.0</td>\n",
       "      <td>35080.214844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>2008-10-14</td>\n",
       "      <td>54789.750000</td>\n",
       "      <td>50680.519531</td>\n",
       "      <td>52832.972656</td>\n",
       "      <td>51463.230469</td>\n",
       "      <td>4044980.0</td>\n",
       "      <td>36394.863281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2008-10-15</td>\n",
       "      <td>50191.324219</td>\n",
       "      <td>48625.902344</td>\n",
       "      <td>49115.097656</td>\n",
       "      <td>49897.808594</td>\n",
       "      <td>2914254.0</td>\n",
       "      <td>35287.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>2008-10-16</td>\n",
       "      <td>44956.945312</td>\n",
       "      <td>42462.054688</td>\n",
       "      <td>44663.429688</td>\n",
       "      <td>42462.054688</td>\n",
       "      <td>4028134.0</td>\n",
       "      <td>30029.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>52800.000000</td>\n",
       "      <td>51100.000000</td>\n",
       "      <td>52600.000000</td>\n",
       "      <td>51400.000000</td>\n",
       "      <td>879936.0</td>\n",
       "      <td>51400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>51500.000000</td>\n",
       "      <td>50600.000000</td>\n",
       "      <td>51400.000000</td>\n",
       "      <td>50800.000000</td>\n",
       "      <td>1269827.0</td>\n",
       "      <td>50800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>48500.000000</td>\n",
       "      <td>51000.000000</td>\n",
       "      <td>48650.000000</td>\n",
       "      <td>2174679.0</td>\n",
       "      <td>48650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>49050.000000</td>\n",
       "      <td>47750.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>2092984.0</td>\n",
       "      <td>47900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>47500.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>49000.000000</td>\n",
       "      <td>1710049.0</td>\n",
       "      <td>49000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3366 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          High           Low          Open         Close  \\\n",
       "1740  2008-10-10  47109.402344  40065.003906  47109.402344  45984.253906   \n",
       "1741  2008-10-13  50387.000000  45543.980469  47109.402344  49604.289062   \n",
       "1742  2008-10-14  54789.750000  50680.519531  52832.972656  51463.230469   \n",
       "1743  2008-10-15  50191.324219  48625.902344  49115.097656  49897.808594   \n",
       "1744  2008-10-16  44956.945312  42462.054688  44663.429688  42462.054688   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "5123  2022-06-20  52800.000000  51100.000000  52600.000000  51400.000000   \n",
       "5124  2022-06-21  51500.000000  50600.000000  51400.000000  50800.000000   \n",
       "5125  2022-06-22  51200.000000  48500.000000  51000.000000  48650.000000   \n",
       "5126  2022-06-23  49050.000000  47750.000000  48000.000000  47900.000000   \n",
       "5127  2022-06-24  49500.000000  47500.000000  47900.000000  49000.000000   \n",
       "\n",
       "          Volume     Adj Close  \n",
       "1740  13291017.0  32520.121094  \n",
       "1741   3246863.0  35080.214844  \n",
       "1742   4044980.0  36394.863281  \n",
       "1743   2914254.0  35287.789062  \n",
       "1744   4028134.0  30029.220703  \n",
       "...          ...           ...  \n",
       "5123    879936.0  51400.000000  \n",
       "5124   1269827.0  50800.000000  \n",
       "5125   2174679.0  48650.000000  \n",
       "5126   2092984.0  47900.000000  \n",
       "5127   1710049.0  49000.000000  \n",
       "\n",
       "[3366 rows x 7 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = pd.read_csv(f'leader_stocks_data/{file_list[4]}')\n",
    "for column in df_origin.columns[1:]:\n",
    "    df_origin= df_origin.loc[df_origin[f'{column}'] != 0, :]\n",
    "df_origin.loc[df_origin['Close'] > 100000, ['High','Low','Open', 'Close', 'Volume','Adj Close' ]] %= 100\n",
    "df_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin= df_origin.loc[df_origin['High'] != 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           2008-10-10\n",
       "High         24655.386719\n",
       "Low          21182.109375\n",
       "Open         22600.771484\n",
       "Close        22307.255859\n",
       "Volume           287818.0\n",
       "Adj Close     15775.71875\n",
       "dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.title(\"kb증권\", fontsize=15, color = 'white')\n",
    "plt.plot(df_origin[2500:]['Close'], \"-\", label=\"Close\")\n",
    "plt.tick_params(axis='x', labelcolor='white')\n",
    "plt.tick_params(axis='y', labelcolor='white')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(200))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 8s 104ms/step - loss: 0.1134 - mse: 0.2269 - val_loss: 0.0985 - val_mse: 0.1971\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0270 - mse: 0.0540 - val_loss: 8.3646e-04 - val_mse: 0.0017\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0037 - mse: 0.0074 - val_loss: 8.6190e-04 - val_mse: 0.0017\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 8.3540e-04 - val_mse: 0.0017\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 9.7225e-04 - mse: 0.0019 - val_loss: 0.0013 - val_mse: 0.0025\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 9.3879e-04 - mse: 0.0019 - val_loss: 8.3036e-04 - val_mse: 0.0017\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 9.5835e-04 - mse: 0.0019 - val_loss: 7.7164e-04 - val_mse: 0.0015\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 8.7280e-04 - mse: 0.0017 - val_loss: 9.7056e-04 - val_mse: 0.0019\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 8.5534e-04 - mse: 0.0017 - val_loss: 8.9205e-04 - val_mse: 0.0018\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 8.1862e-04 - mse: 0.0016 - val_loss: 7.3295e-04 - val_mse: 0.0015\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 7.9630e-04 - mse: 0.0016 - val_loss: 7.0884e-04 - val_mse: 0.0014\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 7.9413e-04 - mse: 0.0016 - val_loss: 7.6054e-04 - val_mse: 0.0015\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 7.3305e-04 - mse: 0.0015 - val_loss: 6.6984e-04 - val_mse: 0.0013\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 7.2245e-04 - mse: 0.0014 - val_loss: 6.1243e-04 - val_mse: 0.0012\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 6.6244e-04 - mse: 0.0013 - val_loss: 5.7377e-04 - val_mse: 0.0011\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 6.7648e-04 - mse: 0.0014 - val_loss: 5.6710e-04 - val_mse: 0.0011\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 6.4993e-04 - mse: 0.0013 - val_loss: 5.2691e-04 - val_mse: 0.0011\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 5.8174e-04 - mse: 0.0012 - val_loss: 5.1621e-04 - val_mse: 0.0010\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 5.6305e-04 - mse: 0.0011 - val_loss: 6.3843e-04 - val_mse: 0.0013\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 5.5666e-04 - mse: 0.0011 - val_loss: 4.5836e-04 - val_mse: 9.1672e-04\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 4.9754e-04 - mse: 9.9508e-04 - val_loss: 7.1747e-04 - val_mse: 0.0014\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 5.1327e-04 - mse: 0.0010 - val_loss: 4.7932e-04 - val_mse: 9.5863e-04\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 4.6426e-04 - mse: 9.2852e-04 - val_loss: 5.7893e-04 - val_mse: 0.0012\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 4.5761e-04 - mse: 9.1523e-04 - val_loss: 4.0377e-04 - val_mse: 8.0755e-04\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 4.3514e-04 - mse: 8.7028e-04 - val_loss: 4.4772e-04 - val_mse: 8.9543e-04\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 4.1603e-04 - mse: 8.3205e-04 - val_loss: 3.6275e-04 - val_mse: 7.2550e-04\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.9350e-04 - mse: 7.8700e-04 - val_loss: 4.4085e-04 - val_mse: 8.8170e-04\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 4.0378e-04 - mse: 8.0756e-04 - val_loss: 3.5926e-04 - val_mse: 7.1852e-04\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 4.1106e-04 - mse: 8.2211e-04 - val_loss: 3.4432e-04 - val_mse: 6.8864e-04\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 3.7489e-04 - mse: 7.4977e-04 - val_loss: 5.0925e-04 - val_mse: 0.0010\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 3.6912e-04 - mse: 7.3823e-04 - val_loss: 3.2993e-04 - val_mse: 6.5986e-04\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 3.6016e-04 - mse: 7.2032e-04 - val_loss: 4.3530e-04 - val_mse: 8.7060e-04\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 3.9410e-04 - mse: 7.8820e-04 - val_loss: 3.9032e-04 - val_mse: 7.8064e-04\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 3.7393e-04 - mse: 7.4786e-04 - val_loss: 3.2680e-04 - val_mse: 6.5361e-04\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.3546e-04 - mse: 6.7091e-04 - val_loss: 3.4205e-04 - val_mse: 6.8410e-04\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.2875e-04 - mse: 6.5750e-04 - val_loss: 4.9747e-04 - val_mse: 9.9494e-04\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 3.5658e-04 - mse: 7.1317e-04 - val_loss: 3.4309e-04 - val_mse: 6.8618e-04\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 3.3201e-04 - mse: 6.6402e-04 - val_loss: 3.0853e-04 - val_mse: 6.1705e-04\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 3.1296e-04 - mse: 6.2593e-04 - val_loss: 2.9485e-04 - val_mse: 5.8970e-04\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 3.1235e-04 - mse: 6.2470e-04 - val_loss: 3.5273e-04 - val_mse: 7.0546e-04\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1390e-04 - mse: 6.2780e-04 - val_loss: 3.3866e-04 - val_mse: 6.7732e-04\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1725e-04 - mse: 6.3451e-04 - val_loss: 5.3037e-04 - val_mse: 0.0011\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.1770e-04 - mse: 6.3540e-04 - val_loss: 3.4286e-04 - val_mse: 6.8573e-04\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 3.2566e-04 - mse: 6.5132e-04 - val_loss: 2.8240e-04 - val_mse: 5.6480e-04\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.9032e-04 - mse: 5.8063e-04 - val_loss: 3.0960e-04 - val_mse: 6.1920e-04\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 3.0716e-04 - mse: 6.1432e-04 - val_loss: 3.1773e-04 - val_mse: 6.3546e-04\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.9858e-04 - mse: 5.9715e-04 - val_loss: 2.8101e-04 - val_mse: 5.6203e-04\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 3.0437e-04 - mse: 6.0874e-04 - val_loss: 4.1535e-04 - val_mse: 8.3071e-04\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 3.0357e-04 - mse: 6.0714e-04 - val_loss: 3.7002e-04 - val_mse: 7.4005e-04\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 3.0332e-04 - mse: 6.0665e-04 - val_loss: 2.7734e-04 - val_mse: 5.5467e-04\n",
      "CJ제일제당_음식료품.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:7863.761196639242\n",
      "[7863.761196639242]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 6s 35ms/step - loss: 0.0986 - mse: 0.1973 - val_loss: 0.0650 - val_mse: 0.1300\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0083 - val_mse: 0.0167\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0056 - val_mse: 0.0112\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0035 - val_mse: 0.0070\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0037 - val_mse: 0.0073\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 9.3432e-04 - mse: 0.0019 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 8.3118e-04 - mse: 0.0017 - val_loss: 0.0014 - val_mse: 0.0027\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 7.8892e-04 - mse: 0.0016 - val_loss: 0.0013 - val_mse: 0.0026\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 7.7328e-04 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 7.5967e-04 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0023\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 7.4266e-04 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0023\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 7.3449e-04 - mse: 0.0015 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 7.1962e-04 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0023\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 7.0693e-04 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.9035e-04 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0027\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 6.7310e-04 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.6328e-04 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0025\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.4021e-04 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0028\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.3115e-04 - mse: 0.0013 - val_loss: 9.4525e-04 - val_mse: 0.0019\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 6.2068e-04 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 6.1124e-04 - mse: 0.0012 - val_loss: 9.4906e-04 - val_mse: 0.0019\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 5.8840e-04 - mse: 0.0012 - val_loss: 9.2537e-04 - val_mse: 0.0019\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 5.7382e-04 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0026\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 5.6519e-04 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0023\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.4895e-04 - mse: 0.0011 - val_loss: 9.9566e-04 - val_mse: 0.0020\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.2698e-04 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.1409e-04 - mse: 0.0010 - val_loss: 8.5710e-04 - val_mse: 0.0017\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.0434e-04 - mse: 0.0010 - val_loss: 8.2879e-04 - val_mse: 0.0017\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.9004e-04 - mse: 9.8008e-04 - val_loss: 7.7249e-04 - val_mse: 0.0015\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.8387e-04 - mse: 9.6774e-04 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.6367e-04 - mse: 9.2735e-04 - val_loss: 7.2443e-04 - val_mse: 0.0014\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.4606e-04 - mse: 8.9211e-04 - val_loss: 9.4679e-04 - val_mse: 0.0019\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 4.3430e-04 - mse: 8.6860e-04 - val_loss: 8.9624e-04 - val_mse: 0.0018\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 4.2825e-04 - mse: 8.5651e-04 - val_loss: 7.1394e-04 - val_mse: 0.0014\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.0979e-04 - mse: 8.1957e-04 - val_loss: 9.9689e-04 - val_mse: 0.0020\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 3.9978e-04 - mse: 7.9957e-04 - val_loss: 7.6015e-04 - val_mse: 0.0015\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 3.8059e-04 - mse: 7.6117e-04 - val_loss: 8.3332e-04 - val_mse: 0.0017\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 3.7450e-04 - mse: 7.4899e-04 - val_loss: 6.7437e-04 - val_mse: 0.0013\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 3.6520e-04 - mse: 7.3041e-04 - val_loss: 5.6095e-04 - val_mse: 0.0011\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 3.7413e-04 - mse: 7.4825e-04 - val_loss: 6.7153e-04 - val_mse: 0.0013\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 3.4794e-04 - mse: 6.9589e-04 - val_loss: 5.1380e-04 - val_mse: 0.0010\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 3.6143e-04 - mse: 7.2287e-04 - val_loss: 7.9601e-04 - val_mse: 0.0016\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 3.3372e-04 - mse: 6.6744e-04 - val_loss: 7.2078e-04 - val_mse: 0.0014\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 3.3951e-04 - mse: 6.7901e-04 - val_loss: 6.8405e-04 - val_mse: 0.0014\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 3.2459e-04 - mse: 6.4917e-04 - val_loss: 7.2398e-04 - val_mse: 0.0014\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 3.1432e-04 - mse: 6.2864e-04 - val_loss: 7.7022e-04 - val_mse: 0.0015\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 3.1130e-04 - mse: 6.2259e-04 - val_loss: 8.4722e-04 - val_mse: 0.0017\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 3.1003e-04 - mse: 6.2006e-04 - val_loss: 7.2174e-04 - val_mse: 0.0014\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 3.1171e-04 - mse: 6.2342e-04 - val_loss: 5.7948e-04 - val_mse: 0.0012\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 2.9804e-04 - mse: 5.9607e-04 - val_loss: 6.0562e-04 - val_mse: 0.0012\n",
      "CJ제일제당_음식료품.csv\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:11620.603590460132\n",
      "[7863.761196639242, 11620.603590460132]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 7s 32ms/step - loss: 0.0168 - mse: 0.0336 - val_loss: 0.0084 - val_mse: 0.0168\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0039 - val_mse: 0.0078\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 7.1968e-04 - mse: 0.0014 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 6.5694e-04 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 6.3224e-04 - mse: 0.0013 - val_loss: 0.0017 - val_mse: 0.0035\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 6.0856e-04 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0035\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 5.6938e-04 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 5.4990e-04 - mse: 0.0011 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 5.3069e-04 - mse: 0.0011 - val_loss: 0.0015 - val_mse: 0.0031\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 5.2125e-04 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 4.8436e-04 - mse: 9.6871e-04 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 4.4772e-04 - mse: 8.9544e-04 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 4.4133e-04 - mse: 8.8267e-04 - val_loss: 9.9766e-04 - val_mse: 0.0020\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 4.0777e-04 - mse: 8.1553e-04 - val_loss: 8.6498e-04 - val_mse: 0.0017\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.9385e-04 - mse: 7.8771e-04 - val_loss: 8.7860e-04 - val_mse: 0.0018\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.6868e-04 - mse: 7.3735e-04 - val_loss: 8.4352e-04 - val_mse: 0.0017\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.9327e-04 - mse: 7.8655e-04 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.6574e-04 - mse: 7.3149e-04 - val_loss: 8.1177e-04 - val_mse: 0.0016\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.3461e-04 - mse: 6.6923e-04 - val_loss: 7.6190e-04 - val_mse: 0.0015\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.3090e-04 - mse: 6.6181e-04 - val_loss: 0.0010 - val_mse: 0.0021\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.2532e-04 - mse: 6.5063e-04 - val_loss: 7.2227e-04 - val_mse: 0.0014\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.9844e-04 - mse: 5.9687e-04 - val_loss: 8.1940e-04 - val_mse: 0.0016\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.9256e-04 - mse: 5.8513e-04 - val_loss: 7.5936e-04 - val_mse: 0.0015\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.9058e-04 - mse: 5.8116e-04 - val_loss: 8.1286e-04 - val_mse: 0.0016\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.8029e-04 - mse: 5.6059e-04 - val_loss: 5.7553e-04 - val_mse: 0.0012\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6985e-04 - mse: 5.3970e-04 - val_loss: 5.9153e-04 - val_mse: 0.0012\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6154e-04 - mse: 5.2308e-04 - val_loss: 7.0344e-04 - val_mse: 0.0014\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.6488e-04 - mse: 5.2977e-04 - val_loss: 5.6270e-04 - val_mse: 0.0011\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.5298e-04 - mse: 5.0596e-04 - val_loss: 5.3406e-04 - val_mse: 0.0011\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4582e-04 - mse: 4.9164e-04 - val_loss: 5.0819e-04 - val_mse: 0.0010\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6144e-04 - mse: 5.2287e-04 - val_loss: 6.3695e-04 - val_mse: 0.0013\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4161e-04 - mse: 4.8321e-04 - val_loss: 7.0169e-04 - val_mse: 0.0014\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4659e-04 - mse: 4.9317e-04 - val_loss: 5.5727e-04 - val_mse: 0.0011\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.2635e-04 - mse: 4.5270e-04 - val_loss: 6.5099e-04 - val_mse: 0.0013\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.3158e-04 - mse: 4.6316e-04 - val_loss: 6.0956e-04 - val_mse: 0.0012\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.2319e-04 - mse: 4.4637e-04 - val_loss: 4.5931e-04 - val_mse: 9.1862e-04\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 2.2168e-04 - mse: 4.4336e-04 - val_loss: 4.7789e-04 - val_mse: 9.5578e-04\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.2019e-04 - mse: 4.4038e-04 - val_loss: 6.0732e-04 - val_mse: 0.0012\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 2.1535e-04 - mse: 4.3070e-04 - val_loss: 5.5053e-04 - val_mse: 0.0011\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.1445e-04 - mse: 4.2891e-04 - val_loss: 4.5988e-04 - val_mse: 9.1976e-04\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.0765e-04 - mse: 4.1530e-04 - val_loss: 4.2862e-04 - val_mse: 8.5724e-04\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.1064e-04 - mse: 4.2129e-04 - val_loss: 5.0078e-04 - val_mse: 0.0010\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.1259e-04 - mse: 4.2518e-04 - val_loss: 4.5145e-04 - val_mse: 9.0289e-04\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.1373e-04 - mse: 4.2746e-04 - val_loss: 4.7856e-04 - val_mse: 9.5711e-04\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.0596e-04 - mse: 4.1192e-04 - val_loss: 4.4392e-04 - val_mse: 8.8784e-04\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.0218e-04 - mse: 4.0436e-04 - val_loss: 4.1417e-04 - val_mse: 8.2834e-04\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.0195e-04 - mse: 4.0389e-04 - val_loss: 5.1634e-04 - val_mse: 0.0010\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.0985e-04 - mse: 4.1970e-04 - val_loss: 5.8697e-04 - val_mse: 0.0012\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.0173e-04 - mse: 4.0347e-04 - val_loss: 3.9950e-04 - val_mse: 7.9900e-04\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.0074e-04 - mse: 4.0148e-04 - val_loss: 4.2565e-04 - val_mse: 8.5130e-04\n",
      "CJ제일제당_음식료품.csv\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:9742.098396097666\n",
      "[7863.761196639242, 11620.603590460132, 9742.098396097666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 7s 29ms/step - loss: 0.0152 - mse: 0.0304 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 5.8683e-04 - mse: 0.0012 - val_loss: 8.0254e-04 - val_mse: 0.0016\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 3.4280e-04 - mse: 6.8560e-04 - val_loss: 6.9876e-04 - val_mse: 0.0014\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 3.2828e-04 - mse: 6.5656e-04 - val_loss: 7.3273e-04 - val_mse: 0.0015\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 3.1776e-04 - mse: 6.3551e-04 - val_loss: 6.5019e-04 - val_mse: 0.0013\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 3.1243e-04 - mse: 6.2485e-04 - val_loss: 6.6292e-04 - val_mse: 0.0013\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 2s 16ms/step - loss: 2.9998e-04 - mse: 5.9996e-04 - val_loss: 6.9618e-04 - val_mse: 0.0014\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 2s 16ms/step - loss: 2.9040e-04 - mse: 5.8080e-04 - val_loss: 7.1095e-04 - val_mse: 0.0014\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 2.8341e-04 - mse: 5.6682e-04 - val_loss: 6.3851e-04 - val_mse: 0.0013\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 2.7851e-04 - mse: 5.5703e-04 - val_loss: 5.6218e-04 - val_mse: 0.0011\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.6428e-04 - mse: 5.2856e-04 - val_loss: 5.5946e-04 - val_mse: 0.0011\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 2.5013e-04 - mse: 5.0026e-04 - val_loss: 5.0089e-04 - val_mse: 0.0010\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 2.4035e-04 - mse: 4.8070e-04 - val_loss: 4.9856e-04 - val_mse: 9.9713e-04\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 3s 27ms/step - loss: 2.3790e-04 - mse: 4.7580e-04 - val_loss: 4.7504e-04 - val_mse: 9.5009e-04\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 2.2991e-04 - mse: 4.5983e-04 - val_loss: 4.3645e-04 - val_mse: 8.7290e-04\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.1929e-04 - mse: 4.3858e-04 - val_loss: 4.1878e-04 - val_mse: 8.3755e-04\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 2.1637e-04 - mse: 4.3275e-04 - val_loss: 4.2929e-04 - val_mse: 8.5859e-04\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.1156e-04 - mse: 4.2313e-04 - val_loss: 3.8835e-04 - val_mse: 7.7670e-04\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.9881e-04 - mse: 3.9762e-04 - val_loss: 3.7373e-04 - val_mse: 7.4746e-04\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 2.1400e-04 - mse: 4.2799e-04 - val_loss: 3.8580e-04 - val_mse: 7.7160e-04\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.9720e-04 - mse: 3.9441e-04 - val_loss: 5.1099e-04 - val_mse: 0.0010\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.8387e-04 - mse: 3.6774e-04 - val_loss: 3.3548e-04 - val_mse: 6.7095e-04\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.7753e-04 - mse: 3.5507e-04 - val_loss: 4.3798e-04 - val_mse: 8.7596e-04\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.7210e-04 - mse: 3.4420e-04 - val_loss: 3.2275e-04 - val_mse: 6.4551e-04\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.6716e-04 - mse: 3.3433e-04 - val_loss: 3.1147e-04 - val_mse: 6.2294e-04\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.7649e-04 - mse: 3.5298e-04 - val_loss: 3.0477e-04 - val_mse: 6.0954e-04\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.6371e-04 - mse: 3.2742e-04 - val_loss: 2.9301e-04 - val_mse: 5.8603e-04\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.6029e-04 - mse: 3.2059e-04 - val_loss: 3.2519e-04 - val_mse: 6.5038e-04\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.7529e-04 - mse: 3.5059e-04 - val_loss: 3.3521e-04 - val_mse: 6.7041e-04\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5041e-04 - mse: 3.0083e-04 - val_loss: 3.0030e-04 - val_mse: 6.0060e-04\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5599e-04 - mse: 3.1197e-04 - val_loss: 2.7990e-04 - val_mse: 5.5980e-04\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.4970e-04 - mse: 2.9939e-04 - val_loss: 4.4223e-04 - val_mse: 8.8446e-04\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.6273e-04 - mse: 3.2546e-04 - val_loss: 2.6367e-04 - val_mse: 5.2734e-04\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5138e-04 - mse: 3.0276e-04 - val_loss: 2.9348e-04 - val_mse: 5.8696e-04\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 1.4588e-04 - mse: 2.9175e-04 - val_loss: 2.8133e-04 - val_mse: 5.6266e-04\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 2s 23ms/step - loss: 1.4262e-04 - mse: 2.8524e-04 - val_loss: 2.6523e-04 - val_mse: 5.3045e-04\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.3734e-04 - mse: 2.7468e-04 - val_loss: 2.4200e-04 - val_mse: 4.8400e-04\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.4046e-04 - mse: 2.8091e-04 - val_loss: 2.5008e-04 - val_mse: 5.0017e-04\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.3237e-04 - mse: 2.6474e-04 - val_loss: 2.7464e-04 - val_mse: 5.4927e-04\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.3328e-04 - mse: 2.6656e-04 - val_loss: 2.3488e-04 - val_mse: 4.6977e-04\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2999e-04 - mse: 2.5998e-04 - val_loss: 3.7007e-04 - val_mse: 7.4015e-04\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.3718e-04 - mse: 2.7435e-04 - val_loss: 3.3324e-04 - val_mse: 6.6648e-04\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.3098e-04 - mse: 2.6197e-04 - val_loss: 2.4384e-04 - val_mse: 4.8768e-04\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.4190e-04 - mse: 2.8380e-04 - val_loss: 2.6781e-04 - val_mse: 5.3561e-04\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.3189e-04 - mse: 2.6379e-04 - val_loss: 2.3556e-04 - val_mse: 4.7112e-04\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.3874e-04 - mse: 2.7747e-04 - val_loss: 2.8908e-04 - val_mse: 5.7816e-04\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.3107e-04 - mse: 2.6214e-04 - val_loss: 2.1866e-04 - val_mse: 4.3733e-04\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2545e-04 - mse: 2.5090e-04 - val_loss: 2.4336e-04 - val_mse: 4.8671e-04\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2421e-04 - mse: 2.4841e-04 - val_loss: 2.1270e-04 - val_mse: 4.2540e-04\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2176e-04 - mse: 2.4351e-04 - val_loss: 2.4311e-04 - val_mse: 4.8622e-04\n",
      "CJ제일제당_음식료품.csv\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:8753.875184922617\n",
      "[7863.761196639242, 11620.603590460132, 9742.098396097666, 8753.875184922617]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 211ms/step - loss: 0.4025 - mse: 0.8130 - val_loss: 0.1773 - val_mse: 0.3546\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3427 - mse: 0.6874 - val_loss: 0.1478 - val_mse: 0.2957\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2942 - mse: 0.5887 - val_loss: 0.1235 - val_mse: 0.2469\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2535 - mse: 0.5071 - val_loss: 0.1033 - val_mse: 0.2065\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2187 - mse: 0.4373 - val_loss: 0.0891 - val_mse: 0.1782\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1922 - mse: 0.3844 - val_loss: 0.0829 - val_mse: 0.1657\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1737 - mse: 0.3473 - val_loss: 0.0788 - val_mse: 0.1575\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1638 - mse: 0.3276 - val_loss: 0.0729 - val_mse: 0.1457\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1528 - mse: 0.3056 - val_loss: 0.0659 - val_mse: 0.1317\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1412 - mse: 0.2824 - val_loss: 0.0588 - val_mse: 0.1177\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1298 - mse: 0.2596 - val_loss: 0.0520 - val_mse: 0.1040\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1172 - mse: 0.2344 - val_loss: 0.0449 - val_mse: 0.0898\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1036 - mse: 0.2072 - val_loss: 0.0371 - val_mse: 0.0742\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0889 - mse: 0.1777 - val_loss: 0.0291 - val_mse: 0.0581\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0737 - mse: 0.1473 - val_loss: 0.0212 - val_mse: 0.0424\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0584 - mse: 0.1168 - val_loss: 0.0137 - val_mse: 0.0275\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0433 - mse: 0.0867 - val_loss: 0.0075 - val_mse: 0.0150\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0298 - mse: 0.0597 - val_loss: 0.0033 - val_mse: 0.0067\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0185 - mse: 0.0370 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0110 - mse: 0.0220 - val_loss: 0.0035 - val_mse: 0.0070\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0072 - val_mse: 0.0144\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0053 - mse: 0.0105 - val_loss: 0.0106 - val_mse: 0.0213\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0055 - mse: 0.0109 - val_loss: 0.0122 - val_mse: 0.0244\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0053 - mse: 0.0106 - val_loss: 0.0109 - val_mse: 0.0219\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0049 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0047 - mse: 0.0094 - val_loss: 0.0075 - val_mse: 0.0150\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0045 - mse: 0.0090 - val_loss: 0.0070 - val_mse: 0.0140\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0072 - val_mse: 0.0144\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0072 - val_mse: 0.0144\n",
      "F&F_섬유의복.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:13630.086352208707\n",
      "[13630.086352208707]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 12s 53ms/step - loss: 0.0139 - mse: 0.0278 - val_loss: 0.0406 - val_mse: 0.0811\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0107 - val_mse: 0.0213\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0039 - val_mse: 0.0077\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0061 - val_mse: 0.0121\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 9.4939e-04 - mse: 0.0019 - val_loss: 0.0092 - val_mse: 0.0183\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 9.0748e-04 - mse: 0.0018 - val_loss: 0.0085 - val_mse: 0.0171\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 8.7378e-04 - mse: 0.0017 - val_loss: 0.0076 - val_mse: 0.0152\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 7.8297e-04 - mse: 0.0016 - val_loss: 0.0079 - val_mse: 0.0157\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 7.2275e-04 - mse: 0.0014 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 6.9083e-04 - mse: 0.0014 - val_loss: 0.0063 - val_mse: 0.0127\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 6.5072e-04 - mse: 0.0013 - val_loss: 0.0064 - val_mse: 0.0127\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 6.1506e-04 - mse: 0.0012 - val_loss: 0.0053 - val_mse: 0.0105\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 5.8556e-04 - mse: 0.0012 - val_loss: 0.0040 - val_mse: 0.0079\n",
      "HLB글로벌_광업.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:2871.555275639465\n",
      "[2871.555275639465]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 5s 36ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0063 - val_mse: 0.0126\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.1783e-04 - mse: 4.3567e-04 - val_loss: 0.0051 - val_mse: 0.0101\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 1.9036e-04 - mse: 3.8071e-04 - val_loss: 0.0051 - val_mse: 0.0101\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 1.8226e-04 - mse: 3.6453e-04 - val_loss: 0.0042 - val_mse: 0.0084\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 1.6918e-04 - mse: 3.3836e-04 - val_loss: 0.0037 - val_mse: 0.0075\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 1.5977e-04 - mse: 3.1955e-04 - val_loss: 0.0032 - val_mse: 0.0063\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 1.5326e-04 - mse: 3.0652e-04 - val_loss: 0.0035 - val_mse: 0.0069\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 1.4516e-04 - mse: 2.9032e-04 - val_loss: 0.0032 - val_mse: 0.0065\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 1.3305e-04 - mse: 2.6611e-04 - val_loss: 0.0034 - val_mse: 0.0067\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 1.2964e-04 - mse: 2.5928e-04 - val_loss: 0.0034 - val_mse: 0.0067\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 1.1676e-04 - mse: 2.3353e-04 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 1.0813e-04 - mse: 2.1626e-04 - val_loss: 0.0025 - val_mse: 0.0051\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 1.0661e-04 - mse: 2.1323e-04 - val_loss: 0.0021 - val_mse: 0.0043\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 1.0700e-04 - mse: 2.1400e-04 - val_loss: 0.0028 - val_mse: 0.0057\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 9.3012e-05 - mse: 1.8602e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 8.7870e-05 - mse: 1.7574e-04 - val_loss: 0.0018 - val_mse: 0.0035\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 8.4678e-05 - mse: 1.6936e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 7.8696e-05 - mse: 1.5739e-04 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 8.6149e-05 - mse: 1.7230e-04 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 7.6391e-05 - mse: 1.5278e-04 - val_loss: 0.0024 - val_mse: 0.0048\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 6.9862e-05 - mse: 1.3972e-04 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 6.7145e-05 - mse: 1.3429e-04 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 6.5953e-05 - mse: 1.3191e-04 - val_loss: 0.0023 - val_mse: 0.0047\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 7.0672e-05 - mse: 1.4134e-04 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 6.2675e-05 - mse: 1.2535e-04 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.4792e-05 - mse: 1.2958e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "HLB글로벌_광업.csv\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:2109.1211967168515\n",
      "[2871.555275639465, 2109.1211967168515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 7s 31ms/step - loss: 2.9959e-04 - mse: 5.9918e-04 - val_loss: 0.0064 - val_mse: 0.0128\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.1847e-04 - mse: 2.3695e-04 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.0959e-04 - mse: 2.1919e-04 - val_loss: 0.0049 - val_mse: 0.0097\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.0470e-04 - mse: 2.0940e-04 - val_loss: 0.0040 - val_mse: 0.0080\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9.5803e-05 - mse: 1.9161e-04 - val_loss: 0.0037 - val_mse: 0.0075\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 8.8705e-05 - mse: 1.7741e-04 - val_loss: 0.0030 - val_mse: 0.0059\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 8.0487e-05 - mse: 1.6097e-04 - val_loss: 0.0033 - val_mse: 0.0065\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 7.6240e-05 - mse: 1.5248e-04 - val_loss: 0.0034 - val_mse: 0.0069\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 7.5116e-05 - mse: 1.5023e-04 - val_loss: 0.0027 - val_mse: 0.0055\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 6.8330e-05 - mse: 1.3666e-04 - val_loss: 0.0026 - val_mse: 0.0052\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 6.5744e-05 - mse: 1.3149e-04 - val_loss: 0.0026 - val_mse: 0.0051\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 6.0159e-05 - mse: 1.2032e-04 - val_loss: 0.0030 - val_mse: 0.0060\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 6.1451e-05 - mse: 1.2290e-04 - val_loss: 0.0031 - val_mse: 0.0063\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 5.6647e-05 - mse: 1.1329e-04 - val_loss: 0.0023 - val_mse: 0.0047\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 5.5179e-05 - mse: 1.1036e-04 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 5.1934e-05 - mse: 1.0387e-04 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 5.2285e-05 - mse: 1.0457e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 4.7303e-05 - mse: 9.4606e-05 - val_loss: 0.0023 - val_mse: 0.0047\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 4.8530e-05 - mse: 9.7060e-05 - val_loss: 0.0024 - val_mse: 0.0049\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 4.8450e-05 - mse: 9.6900e-05 - val_loss: 0.0026 - val_mse: 0.0052\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 4.5429e-05 - mse: 9.0859e-05 - val_loss: 0.0022 - val_mse: 0.0044\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 4.2411e-05 - mse: 8.4823e-05 - val_loss: 0.0025 - val_mse: 0.0049\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 4.1338e-05 - mse: 8.2675e-05 - val_loss: 0.0022 - val_mse: 0.0045\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 3.9870e-05 - mse: 7.9740e-05 - val_loss: 0.0015 - val_mse: 0.0030\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.9286e-05 - mse: 7.8571e-05 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 4.2871e-05 - mse: 8.5742e-05 - val_loss: 0.0020 - val_mse: 0.0041\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.9956e-05 - mse: 7.9913e-05 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 3.6722e-05 - mse: 7.3443e-05 - val_loss: 0.0019 - val_mse: 0.0039\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.4606e-05 - mse: 6.9211e-05 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.4504e-05 - mse: 6.9009e-05 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.3848e-05 - mse: 6.7695e-05 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.6770e-05 - mse: 7.3539e-05 - val_loss: 9.8227e-04 - val_mse: 0.0020\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.2662e-05 - mse: 6.5324e-05 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.8744e-05 - mse: 7.7488e-05 - val_loss: 0.0019 - val_mse: 0.0037\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 2s 31ms/step - loss: 3.3626e-05 - mse: 6.7252e-05 - val_loss: 0.0019 - val_mse: 0.0039\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 3.0657e-05 - mse: 6.1313e-05 - val_loss: 0.0015 - val_mse: 0.0031\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 2.9233e-05 - mse: 5.8467e-05 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.1625e-05 - mse: 6.3251e-05 - val_loss: 0.0015 - val_mse: 0.0030\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 2.9670e-05 - mse: 5.9340e-05 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.9741e-05 - mse: 5.9481e-05 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.8074e-05 - mse: 5.6148e-05 - val_loss: 0.0019 - val_mse: 0.0038\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.8678e-05 - mse: 5.7356e-05 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "HLB글로벌_광업.csv\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:1638.0154717155062\n",
      "[2871.555275639465, 2109.1211967168515, 1638.0154717155062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 7s 27ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0028 - val_mse: 0.0055\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1357e-04 - mse: 2.2714e-04 - val_loss: 0.0027 - val_mse: 0.0053\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.0124e-04 - mse: 2.0248e-04 - val_loss: 0.0022 - val_mse: 0.0044\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 9.3253e-05 - mse: 1.8651e-04 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 8.6829e-05 - mse: 1.7366e-04 - val_loss: 0.0022 - val_mse: 0.0043\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 8.1569e-05 - mse: 1.6314e-04 - val_loss: 0.0016 - val_mse: 0.0031\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 7.2930e-05 - mse: 1.4586e-04 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 6.8463e-05 - mse: 1.3693e-04 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 6.2136e-05 - mse: 1.2427e-04 - val_loss: 0.0013 - val_mse: 0.0025\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 5.8603e-05 - mse: 1.1721e-04 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 5.4310e-05 - mse: 1.0862e-04 - val_loss: 0.0011 - val_mse: 0.0021\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 5.3225e-05 - mse: 1.0645e-04 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 3s 24ms/step - loss: 4.8722e-05 - mse: 9.7443e-05 - val_loss: 0.0010 - val_mse: 0.0021\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.5942e-05 - mse: 9.1883e-05 - val_loss: 9.2279e-04 - val_mse: 0.0018\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.4812e-05 - mse: 8.9624e-05 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2124e-05 - mse: 8.4249e-05 - val_loss: 9.2288e-04 - val_mse: 0.0018\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2165e-05 - mse: 8.4330e-05 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 3.9196e-05 - mse: 7.8391e-05 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 3.7713e-05 - mse: 7.5427e-05 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 3.7454e-05 - mse: 7.4909e-05 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 3.4357e-05 - mse: 6.8714e-05 - val_loss: 0.0016 - val_mse: 0.0033\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 3.4987e-05 - mse: 6.9975e-05 - val_loss: 0.0015 - val_mse: 0.0031\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 3.2373e-05 - mse: 6.4746e-05 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 3.1790e-05 - mse: 6.3580e-05 - val_loss: 0.0013 - val_mse: 0.0027\n",
      "HLB글로벌_광업.csv\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:1716.040448736939\n",
      "[2871.555275639465, 2109.1211967168515, 1638.0154717155062, 1716.040448736939]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 7s 23ms/step - loss: 0.0033 - mse: 0.0067 - val_loss: 0.0044 - val_mse: 0.0089\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.4967e-04 - mse: 2.9934e-04 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 8.3531e-05 - mse: 1.6706e-04 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 8.2566e-05 - mse: 1.6513e-04 - val_loss: 0.0015 - val_mse: 0.0031\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 7.9686e-05 - mse: 1.5937e-04 - val_loss: 0.0015 - val_mse: 0.0030\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 7.4808e-05 - mse: 1.4962e-04 - val_loss: 0.0014 - val_mse: 0.0028\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 7.0462e-05 - mse: 1.4092e-04 - val_loss: 0.0013 - val_mse: 0.0027\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 6.9312e-05 - mse: 1.3862e-04 - val_loss: 0.0013 - val_mse: 0.0025\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 6.7994e-05 - mse: 1.3599e-04 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.1482e-05 - mse: 1.2296e-04 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 3s 19ms/step - loss: 5.8687e-05 - mse: 1.1737e-04 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 5.5831e-05 - mse: 1.1166e-04 - val_loss: 0.0010 - val_mse: 0.0021\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.1994e-05 - mse: 1.0399e-04 - val_loss: 9.6137e-04 - val_mse: 0.0019\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 4.8399e-05 - mse: 9.6799e-05 - val_loss: 9.9692e-04 - val_mse: 0.0020\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 5.0498e-05 - mse: 1.0100e-04 - val_loss: 8.8167e-04 - val_mse: 0.0018\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 4.7586e-05 - mse: 9.5171e-05 - val_loss: 8.4510e-04 - val_mse: 0.0017\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 4.3579e-05 - mse: 8.7158e-05 - val_loss: 7.8993e-04 - val_mse: 0.0016\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 4.2662e-05 - mse: 8.5325e-05 - val_loss: 8.7191e-04 - val_mse: 0.0017\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 3.9027e-05 - mse: 7.8054e-05 - val_loss: 7.6926e-04 - val_mse: 0.0015\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 4s 27ms/step - loss: 4.0198e-05 - mse: 8.0396e-05 - val_loss: 7.1005e-04 - val_mse: 0.0014\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 3.8171e-05 - mse: 7.6342e-05 - val_loss: 6.8445e-04 - val_mse: 0.0014\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 3.6323e-05 - mse: 7.2646e-05 - val_loss: 6.4619e-04 - val_mse: 0.0013\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 3.4036e-05 - mse: 6.8072e-05 - val_loss: 6.3001e-04 - val_mse: 0.0013\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 3.6746e-05 - mse: 7.3491e-05 - val_loss: 6.2406e-04 - val_mse: 0.0012\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 3.2317e-05 - mse: 6.4634e-05 - val_loss: 5.9643e-04 - val_mse: 0.0012\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 3.5810e-05 - mse: 7.1620e-05 - val_loss: 6.3074e-04 - val_mse: 0.0013\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 3.2047e-05 - mse: 6.4094e-05 - val_loss: 5.7398e-04 - val_mse: 0.0011\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 3.2027e-05 - mse: 6.4055e-05 - val_loss: 5.4064e-04 - val_mse: 0.0011\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 3.3328e-05 - mse: 6.6657e-05 - val_loss: 5.2898e-04 - val_mse: 0.0011\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.9828e-05 - mse: 5.9657e-05 - val_loss: 5.0527e-04 - val_mse: 0.0010\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.9567e-05 - mse: 5.9134e-05 - val_loss: 5.0956e-04 - val_mse: 0.0010\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 3.0669e-05 - mse: 6.1339e-05 - val_loss: 4.9302e-04 - val_mse: 9.8603e-04\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 2.8083e-05 - mse: 5.6167e-05 - val_loss: 4.7816e-04 - val_mse: 9.5633e-04\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 2.7665e-05 - mse: 5.5329e-05 - val_loss: 4.7485e-04 - val_mse: 9.4969e-04\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.6742e-05 - mse: 5.3484e-05 - val_loss: 4.5838e-04 - val_mse: 9.1677e-04\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.9652e-05 - mse: 5.9303e-05 - val_loss: 4.5537e-04 - val_mse: 9.1075e-04\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 2.6623e-05 - mse: 5.3247e-05 - val_loss: 4.5888e-04 - val_mse: 9.1775e-04\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.8649e-05 - mse: 5.7297e-05 - val_loss: 4.4255e-04 - val_mse: 8.8510e-04\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 3s 18ms/step - loss: 2.5410e-05 - mse: 5.0820e-05 - val_loss: 4.5114e-04 - val_mse: 9.0228e-04\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 2.5359e-05 - mse: 5.0718e-05 - val_loss: 4.3310e-04 - val_mse: 8.6621e-04\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.4752e-05 - mse: 4.9505e-05 - val_loss: 4.1936e-04 - val_mse: 8.3871e-04\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.6883e-05 - mse: 5.3767e-05 - val_loss: 4.4584e-04 - val_mse: 8.9168e-04\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.6107e-05 - mse: 5.2214e-05 - val_loss: 4.5313e-04 - val_mse: 9.0625e-04\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.5288e-05 - mse: 5.0576e-05 - val_loss: 4.4546e-04 - val_mse: 8.9091e-04\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.4015e-05 - mse: 4.8031e-05 - val_loss: 4.1497e-04 - val_mse: 8.2993e-04\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.3499e-05 - mse: 4.6998e-05 - val_loss: 4.1742e-04 - val_mse: 8.3484e-04\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 2.4548e-05 - mse: 4.9095e-05 - val_loss: 4.1021e-04 - val_mse: 8.2041e-04\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.4416e-05 - mse: 4.8832e-05 - val_loss: 4.0690e-04 - val_mse: 8.1380e-04\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.3388e-05 - mse: 4.6776e-05 - val_loss: 4.1236e-04 - val_mse: 8.2472e-04\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 2.3186e-05 - mse: 4.6372e-05 - val_loss: 4.1469e-04 - val_mse: 8.2938e-04\n",
      "HLB글로벌_광업.csv\n",
      "5000길이의 데이터 적용 완료\n",
      " 길이: 5000, RMSE:959.7994256541389\n",
      "[2871.555275639465, 2109.1211967168515, 1638.0154717155062, 1716.040448736939, 959.7994256541389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "137/137 [==============================] - 6s 21ms/step - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0021 - val_mse: 0.0042\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.7275e-04 - mse: 5.4550e-04 - val_loss: 0.0013 - val_mse: 0.0026\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.2526e-04 - mse: 4.5052e-04 - val_loss: 0.0012 - val_mse: 0.0024\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.1882e-04 - mse: 4.3763e-04 - val_loss: 0.0011 - val_mse: 0.0023\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 1.9845e-04 - mse: 3.9690e-04 - val_loss: 0.0010 - val_mse: 0.0021\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 1.9228e-04 - mse: 3.8456e-04 - val_loss: 9.9831e-04 - val_mse: 0.0020\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.8071e-04 - mse: 3.6142e-04 - val_loss: 9.5450e-04 - val_mse: 0.0019\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.6578e-04 - mse: 3.3156e-04 - val_loss: 9.5553e-04 - val_mse: 0.0019\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.5710e-04 - mse: 3.1421e-04 - val_loss: 8.7240e-04 - val_mse: 0.0017\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.5033e-04 - mse: 3.0065e-04 - val_loss: 7.9499e-04 - val_mse: 0.0016\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.5101e-04 - mse: 3.0203e-04 - val_loss: 8.0363e-04 - val_mse: 0.0016\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4712e-04 - mse: 2.9424e-04 - val_loss: 7.4934e-04 - val_mse: 0.0015\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4066e-04 - mse: 2.8133e-04 - val_loss: 7.2881e-04 - val_mse: 0.0015\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.3790e-04 - mse: 2.7579e-04 - val_loss: 6.6520e-04 - val_mse: 0.0013\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.3097e-04 - mse: 2.6195e-04 - val_loss: 7.4126e-04 - val_mse: 0.0015\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.2115e-04 - mse: 2.4231e-04 - val_loss: 6.3771e-04 - val_mse: 0.0013\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4133e-04 - mse: 2.8267e-04 - val_loss: 6.2887e-04 - val_mse: 0.0013\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1432e-04 - mse: 2.2863e-04 - val_loss: 6.1514e-04 - val_mse: 0.0012\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2523e-04 - mse: 2.5045e-04 - val_loss: 5.9386e-04 - val_mse: 0.0012\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 1.0441e-04 - mse: 2.0881e-04 - val_loss: 5.8305e-04 - val_mse: 0.0012\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.0436e-04 - mse: 2.0872e-04 - val_loss: 6.0577e-04 - val_mse: 0.0012\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.0002e-04 - mse: 2.0004e-04 - val_loss: 5.3898e-04 - val_mse: 0.0011\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 9.3830e-05 - mse: 1.8766e-04 - val_loss: 4.9668e-04 - val_mse: 9.9336e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 9.9530e-05 - mse: 1.9906e-04 - val_loss: 5.4561e-04 - val_mse: 0.0011\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 9.3672e-05 - mse: 1.8734e-04 - val_loss: 5.0301e-04 - val_mse: 0.0010\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.0664e-04 - mse: 2.1329e-04 - val_loss: 4.7983e-04 - val_mse: 9.5965e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 3s 17ms/step - loss: 1.1324e-04 - mse: 2.2648e-04 - val_loss: 4.7154e-04 - val_mse: 9.4308e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 9.1345e-05 - mse: 1.8269e-04 - val_loss: 4.7735e-04 - val_mse: 9.5469e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 3s 21ms/step - loss: 8.7082e-05 - mse: 1.7416e-04 - val_loss: 5.5960e-04 - val_mse: 0.0011\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.0349e-04 - mse: 2.0698e-04 - val_loss: 4.5625e-04 - val_mse: 9.1250e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 9.3899e-05 - mse: 1.8780e-04 - val_loss: 4.6600e-04 - val_mse: 9.3201e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 9.4964e-05 - mse: 1.8993e-04 - val_loss: 4.6964e-04 - val_mse: 9.3929e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 8.5111e-05 - mse: 1.7022e-04 - val_loss: 4.2104e-04 - val_mse: 8.4209e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 8.0578e-05 - mse: 1.6116e-04 - val_loss: 4.0957e-04 - val_mse: 8.1914e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 8.2317e-05 - mse: 1.6463e-04 - val_loss: 4.1219e-04 - val_mse: 8.2437e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 8.0441e-05 - mse: 1.6088e-04 - val_loss: 4.1112e-04 - val_mse: 8.2224e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 8.0847e-05 - mse: 1.6169e-04 - val_loss: 4.6622e-04 - val_mse: 9.3245e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 7.5450e-05 - mse: 1.5090e-04 - val_loss: 4.4143e-04 - val_mse: 8.8287e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 7.9927e-05 - mse: 1.5985e-04 - val_loss: 3.8571e-04 - val_mse: 7.7141e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 7.5833e-05 - mse: 1.5167e-04 - val_loss: 4.0036e-04 - val_mse: 8.0073e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 7.2704e-05 - mse: 1.4541e-04 - val_loss: 4.0616e-04 - val_mse: 8.1233e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 7.4181e-05 - mse: 1.4836e-04 - val_loss: 4.2128e-04 - val_mse: 8.4257e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 7.1228e-05 - mse: 1.4246e-04 - val_loss: 3.7565e-04 - val_mse: 7.5129e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 7.2148e-05 - mse: 1.4430e-04 - val_loss: 3.6838e-04 - val_mse: 7.3676e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 7.6810e-05 - mse: 1.5362e-04 - val_loss: 3.8137e-04 - val_mse: 7.6275e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 6.7639e-05 - mse: 1.3528e-04 - val_loss: 3.5679e-04 - val_mse: 7.1359e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 4s 31ms/step - loss: 6.8705e-05 - mse: 1.3741e-04 - val_loss: 3.6665e-04 - val_mse: 7.3331e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 7.1912e-05 - mse: 1.4382e-04 - val_loss: 3.5071e-04 - val_mse: 7.0143e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 4s 27ms/step - loss: 7.4530e-05 - mse: 1.4906e-04 - val_loss: 3.5739e-04 - val_mse: 7.1479e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 3s 24ms/step - loss: 6.8791e-05 - mse: 1.3758e-04 - val_loss: 3.5453e-04 - val_mse: 7.0907e-04\n",
      "HLB글로벌_광업.csv\n",
      "6000길이의 데이터 적용 완료\n",
      " 길이: 6000, RMSE:887.4553793383943\n",
      "[2871.555275639465, 2109.1211967168515, 1638.0154717155062, 1716.040448736939, 959.7994256541389, 887.4553793383943]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 5s 53ms/step - loss: 0.0384 - mse: 0.0768 - val_loss: 0.0638 - val_mse: 0.1276\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0133 - mse: 0.0266 - val_loss: 0.0078 - val_mse: 0.0156\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0038 - mse: 0.0075 - val_loss: 0.0022 - val_mse: 0.0043\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 4.9230e-04 - mse: 9.8459e-04 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 3.2064e-04 - mse: 6.4128e-04 - val_loss: 0.0064 - val_mse: 0.0128\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.9943e-04 - mse: 5.9886e-04 - val_loss: 0.0069 - val_mse: 0.0138\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.9939e-04 - mse: 5.9878e-04 - val_loss: 0.0067 - val_mse: 0.0134\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 2.9295e-04 - mse: 5.8590e-04 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 2.9249e-04 - mse: 5.8498e-04 - val_loss: 0.0048 - val_mse: 0.0095\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 2.8605e-04 - mse: 5.7210e-04 - val_loss: 0.0069 - val_mse: 0.0139\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 3.0595e-04 - mse: 6.1190e-04 - val_loss: 0.0059 - val_mse: 0.0117\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.8726e-04 - mse: 5.7451e-04 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 2.8442e-04 - mse: 5.6884e-04 - val_loss: 0.0048 - val_mse: 0.0096\n",
      "HMM_운수창고업.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:4637.910037047648\n",
      "[4637.910037047648]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 6s 45ms/step - loss: 0.0169 - mse: 0.0338 - val_loss: 0.0011 - val_mse: 0.0022\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 5.0489e-04 - mse: 0.0010 - val_loss: 5.3263e-04 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 2s 26ms/step - loss: 3.5310e-04 - mse: 7.0619e-04 - val_loss: 6.1468e-04 - val_mse: 0.0012\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 3.3800e-04 - mse: 6.7601e-04 - val_loss: 6.9514e-04 - val_mse: 0.0014\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 3.2548e-04 - mse: 6.5095e-04 - val_loss: 5.4082e-04 - val_mse: 0.0011\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 3.2768e-04 - mse: 6.5536e-04 - val_loss: 5.8494e-04 - val_mse: 0.0012\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 3.1182e-04 - mse: 6.2363e-04 - val_loss: 5.7177e-04 - val_mse: 0.0011\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 2s 26ms/step - loss: 3.0537e-04 - mse: 6.1075e-04 - val_loss: 6.0663e-04 - val_mse: 0.0012\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 2.9978e-04 - mse: 5.9955e-04 - val_loss: 5.5892e-04 - val_mse: 0.0011\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 2.8981e-04 - mse: 5.7961e-04 - val_loss: 5.3861e-04 - val_mse: 0.0011\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 2.8718e-04 - mse: 5.7436e-04 - val_loss: 4.5846e-04 - val_mse: 9.1693e-04\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 2.8514e-04 - mse: 5.7028e-04 - val_loss: 4.5381e-04 - val_mse: 9.0762e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.7984e-04 - mse: 5.5967e-04 - val_loss: 4.3373e-04 - val_mse: 8.6746e-04\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.7336e-04 - mse: 5.4672e-04 - val_loss: 4.4711e-04 - val_mse: 8.9422e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 2.6002e-04 - mse: 5.2004e-04 - val_loss: 4.7193e-04 - val_mse: 9.4386e-04\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 2.7297e-04 - mse: 5.4595e-04 - val_loss: 3.7996e-04 - val_mse: 7.5992e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 2.8075e-04 - mse: 5.6150e-04 - val_loss: 3.7307e-04 - val_mse: 7.4613e-04\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 2.5463e-04 - mse: 5.0926e-04 - val_loss: 6.7249e-04 - val_mse: 0.0013\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 2.6419e-04 - mse: 5.2839e-04 - val_loss: 3.7403e-04 - val_mse: 7.4805e-04\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 2.3673e-04 - mse: 4.7347e-04 - val_loss: 3.5846e-04 - val_mse: 7.1693e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 2.4882e-04 - mse: 4.9764e-04 - val_loss: 3.9879e-04 - val_mse: 7.9757e-04\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 2.3228e-04 - mse: 4.6456e-04 - val_loss: 3.2003e-04 - val_mse: 6.4006e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 2.2319e-04 - mse: 4.4637e-04 - val_loss: 4.2438e-04 - val_mse: 8.4875e-04\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.2640e-04 - mse: 4.5279e-04 - val_loss: 3.4383e-04 - val_mse: 6.8767e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 2.1130e-04 - mse: 4.2261e-04 - val_loss: 3.0867e-04 - val_mse: 6.1734e-04\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.1804e-04 - mse: 4.3609e-04 - val_loss: 2.8464e-04 - val_mse: 5.6928e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 2.0977e-04 - mse: 4.1953e-04 - val_loss: 3.2257e-04 - val_mse: 6.4514e-04\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 2.1820e-04 - mse: 4.3640e-04 - val_loss: 3.1594e-04 - val_mse: 6.3188e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 2.0010e-04 - mse: 4.0020e-04 - val_loss: 2.8512e-04 - val_mse: 5.7025e-04\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.9427e-04 - mse: 3.8854e-04 - val_loss: 3.2386e-04 - val_mse: 6.4772e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.9734e-04 - mse: 3.9467e-04 - val_loss: 3.9539e-04 - val_mse: 7.9078e-04\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 1.9416e-04 - mse: 3.8832e-04 - val_loss: 2.9553e-04 - val_mse: 5.9107e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 25ms/step - loss: 1.8664e-04 - mse: 3.7328e-04 - val_loss: 2.6321e-04 - val_mse: 5.2641e-04\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.8351e-04 - mse: 3.6702e-04 - val_loss: 2.8203e-04 - val_mse: 5.6406e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 1.8269e-04 - mse: 3.6538e-04 - val_loss: 2.5217e-04 - val_mse: 5.0433e-04\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 1.8658e-04 - mse: 3.7315e-04 - val_loss: 2.3290e-04 - val_mse: 4.6579e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 2s 27ms/step - loss: 1.8612e-04 - mse: 3.7224e-04 - val_loss: 3.5546e-04 - val_mse: 7.1092e-04\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 1.6825e-04 - mse: 3.3649e-04 - val_loss: 3.2234e-04 - val_mse: 6.4468e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.7968e-04 - mse: 3.5936e-04 - val_loss: 2.2144e-04 - val_mse: 4.4288e-04\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 25ms/step - loss: 1.6678e-04 - mse: 3.3356e-04 - val_loss: 2.2921e-04 - val_mse: 4.5841e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 3s 45ms/step - loss: 1.5991e-04 - mse: 3.1983e-04 - val_loss: 2.1485e-04 - val_mse: 4.2971e-04\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.5728e-04 - mse: 3.1455e-04 - val_loss: 2.4513e-04 - val_mse: 4.9026e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 25ms/step - loss: 1.5747e-04 - mse: 3.1494e-04 - val_loss: 2.0504e-04 - val_mse: 4.1009e-04\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 1.7706e-04 - mse: 3.5413e-04 - val_loss: 2.5473e-04 - val_mse: 5.0945e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 1.5269e-04 - mse: 3.0539e-04 - val_loss: 2.0338e-04 - val_mse: 4.0676e-04\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 1.5014e-04 - mse: 3.0029e-04 - val_loss: 2.0030e-04 - val_mse: 4.0061e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.4482e-04 - mse: 2.8964e-04 - val_loss: 2.2865e-04 - val_mse: 4.5730e-04\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 1.4429e-04 - mse: 2.8857e-04 - val_loss: 1.9099e-04 - val_mse: 3.8198e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 1.4412e-04 - mse: 2.8824e-04 - val_loss: 1.9007e-04 - val_mse: 3.8013e-04\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 1.4463e-04 - mse: 2.8926e-04 - val_loss: 2.0468e-04 - val_mse: 4.0936e-04\n",
      "HMM_운수창고업.csv\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:1545.7214371684267\n",
      "[4637.910037047648, 1545.7214371684267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 12s 67ms/step - loss: 0.0444 - mse: 0.0887 - val_loss: 0.0016 - val_mse: 0.0033\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 2.9393e-04 - val_mse: 5.8786e-04\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.7113e-04 - mse: 7.4227e-04 - val_loss: 6.5139e-05 - val_mse: 1.3028e-04\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.4623e-04 - mse: 6.9247e-04 - val_loss: 5.0241e-05 - val_mse: 1.0048e-04\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 3.3126e-04 - mse: 6.6253e-04 - val_loss: 4.8717e-05 - val_mse: 9.7433e-05\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 3.1759e-04 - mse: 6.3518e-04 - val_loss: 4.8575e-05 - val_mse: 9.7151e-05\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 3.2022e-04 - mse: 6.4044e-04 - val_loss: 3.1018e-05 - val_mse: 6.2036e-05\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 3.1839e-04 - mse: 6.3677e-04 - val_loss: 3.3504e-05 - val_mse: 6.7007e-05\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 3.0440e-04 - mse: 6.0879e-04 - val_loss: 3.1971e-05 - val_mse: 6.3941e-05\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.9554e-04 - mse: 5.9109e-04 - val_loss: 3.6333e-05 - val_mse: 7.2667e-05\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.8162e-04 - mse: 5.6323e-04 - val_loss: 3.1702e-05 - val_mse: 6.3403e-05\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.8081e-04 - mse: 5.6162e-04 - val_loss: 3.0737e-05 - val_mse: 6.1474e-05\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.8505e-04 - mse: 5.7010e-04 - val_loss: 2.6277e-05 - val_mse: 5.2553e-05\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.6706e-04 - mse: 5.3411e-04 - val_loss: 2.8587e-05 - val_mse: 5.7175e-05\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.5552e-04 - mse: 5.1104e-04 - val_loss: 3.1254e-05 - val_mse: 6.2508e-05\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.5240e-04 - mse: 5.0480e-04 - val_loss: 2.7696e-05 - val_mse: 5.5393e-05\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4372e-04 - mse: 4.8743e-04 - val_loss: 2.3446e-05 - val_mse: 4.6893e-05\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 2.3556e-04 - mse: 4.7111e-04 - val_loss: 3.4166e-05 - val_mse: 6.8333e-05\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 2.2383e-04 - mse: 4.4766e-04 - val_loss: 2.3783e-05 - val_mse: 4.7567e-05\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.2420e-04 - mse: 4.4841e-04 - val_loss: 2.4059e-05 - val_mse: 4.8118e-05\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.1933e-04 - mse: 4.3866e-04 - val_loss: 2.1847e-05 - val_mse: 4.3695e-05\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.1526e-04 - mse: 4.3053e-04 - val_loss: 3.0358e-05 - val_mse: 6.0717e-05\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.9924e-04 - mse: 3.9849e-04 - val_loss: 2.3370e-05 - val_mse: 4.6740e-05\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.0318e-04 - mse: 4.0635e-04 - val_loss: 2.4352e-05 - val_mse: 4.8704e-05\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.8596e-04 - mse: 3.7191e-04 - val_loss: 2.0957e-05 - val_mse: 4.1914e-05\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 1.7642e-04 - mse: 3.5284e-04 - val_loss: 1.9497e-05 - val_mse: 3.8994e-05\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.6927e-04 - mse: 3.3853e-04 - val_loss: 2.2969e-05 - val_mse: 4.5938e-05\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.6023e-04 - mse: 3.2046e-04 - val_loss: 2.1627e-05 - val_mse: 4.3253e-05\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.6128e-04 - mse: 3.2256e-04 - val_loss: 1.8384e-05 - val_mse: 3.6767e-05\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.6837e-04 - mse: 3.3674e-04 - val_loss: 2.2485e-05 - val_mse: 4.4971e-05\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.4795e-04 - mse: 2.9591e-04 - val_loss: 1.8590e-05 - val_mse: 3.7181e-05\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.4453e-04 - mse: 2.8905e-04 - val_loss: 1.8854e-05 - val_mse: 3.7707e-05\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 1.3960e-04 - mse: 2.7921e-04 - val_loss: 2.7036e-05 - val_mse: 5.4072e-05\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.4356e-04 - mse: 2.8712e-04 - val_loss: 1.5396e-05 - val_mse: 3.0793e-05\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.4171e-04 - mse: 2.8343e-04 - val_loss: 2.2741e-05 - val_mse: 4.5481e-05\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.3207e-04 - mse: 2.6414e-04 - val_loss: 1.5724e-05 - val_mse: 3.1447e-05\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.2683e-04 - mse: 2.5365e-04 - val_loss: 1.6149e-05 - val_mse: 3.2299e-05\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.2588e-04 - mse: 2.5176e-04 - val_loss: 3.8793e-05 - val_mse: 7.7586e-05\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.3375e-04 - mse: 2.6751e-04 - val_loss: 4.7582e-05 - val_mse: 9.5164e-05\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.2477e-04 - mse: 2.4954e-04 - val_loss: 1.6121e-05 - val_mse: 3.2242e-05\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.1693e-04 - mse: 2.3387e-04 - val_loss: 1.7943e-05 - val_mse: 3.5886e-05\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 1.2035e-04 - mse: 2.4069e-04 - val_loss: 1.3857e-05 - val_mse: 2.7714e-05\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.2114e-04 - mse: 2.4229e-04 - val_loss: 3.5353e-05 - val_mse: 7.0705e-05\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.1840e-04 - mse: 2.3681e-04 - val_loss: 2.2314e-05 - val_mse: 4.4628e-05\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.1731e-04 - mse: 2.3463e-04 - val_loss: 1.7224e-05 - val_mse: 3.4448e-05\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.1033e-04 - mse: 2.2067e-04 - val_loss: 4.4633e-05 - val_mse: 8.9267e-05\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.2103e-04 - mse: 2.4206e-04 - val_loss: 1.3982e-05 - val_mse: 2.7965e-05\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.0821e-04 - mse: 2.1643e-04 - val_loss: 1.2874e-05 - val_mse: 2.5749e-05\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.1246e-04 - mse: 2.2493e-04 - val_loss: 1.3464e-05 - val_mse: 2.6929e-05\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.0944e-04 - mse: 2.1887e-04 - val_loss: 1.7668e-05 - val_mse: 3.5335e-05\n",
      "HMM_운수창고업.csv\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:1649.5571988962656\n",
      "[4637.910037047648, 1545.7214371684267, 1649.5571988962656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 6s 25ms/step - loss: 0.0405 - mse: 0.0809 - val_loss: 4.9159e-04 - val_mse: 9.8317e-04\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 5.7565e-04 - mse: 0.0012 - val_loss: 2.2982e-05 - val_mse: 4.5964e-05\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.7271e-04 - mse: 9.4542e-04 - val_loss: 2.3266e-05 - val_mse: 4.6533e-05\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.5096e-04 - mse: 9.0192e-04 - val_loss: 2.3066e-05 - val_mse: 4.6133e-05\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2955e-04 - mse: 8.5911e-04 - val_loss: 2.5013e-05 - val_mse: 5.0025e-05\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.1766e-04 - mse: 8.3532e-04 - val_loss: 2.4179e-05 - val_mse: 4.8359e-05\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.0054e-04 - mse: 8.0108e-04 - val_loss: 2.2316e-05 - val_mse: 4.4633e-05\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 3.8653e-04 - mse: 7.7306e-04 - val_loss: 1.7654e-05 - val_mse: 3.5309e-05\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 3.5524e-04 - mse: 7.1047e-04 - val_loss: 1.8952e-05 - val_mse: 3.7905e-05\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 3.4384e-04 - mse: 6.8768e-04 - val_loss: 1.9623e-05 - val_mse: 3.9246e-05\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 3.2482e-04 - mse: 6.4963e-04 - val_loss: 3.9110e-05 - val_mse: 7.8219e-05\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 3s 24ms/step - loss: 3.2042e-04 - mse: 6.4085e-04 - val_loss: 3.1455e-05 - val_mse: 6.2910e-05\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 3.0767e-04 - mse: 6.1533e-04 - val_loss: 1.6495e-05 - val_mse: 3.2989e-05\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.9347e-04 - mse: 5.8694e-04 - val_loss: 1.4159e-05 - val_mse: 2.8317e-05\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.8351e-04 - mse: 5.6703e-04 - val_loss: 1.7859e-05 - val_mse: 3.5719e-05\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.7299e-04 - mse: 5.4598e-04 - val_loss: 1.2106e-05 - val_mse: 2.4213e-05\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.6566e-04 - mse: 5.3131e-04 - val_loss: 1.2062e-05 - val_mse: 2.4124e-05\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.5509e-04 - mse: 5.1018e-04 - val_loss: 1.0876e-05 - val_mse: 2.1751e-05\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.6632e-04 - mse: 5.3264e-04 - val_loss: 1.1722e-05 - val_mse: 2.3445e-05\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.5845e-04 - mse: 5.1691e-04 - val_loss: 1.2746e-05 - val_mse: 2.5492e-05\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.3367e-04 - mse: 4.6735e-04 - val_loss: 1.2516e-05 - val_mse: 2.5033e-05\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.6001e-04 - mse: 5.2001e-04 - val_loss: 1.4677e-05 - val_mse: 2.9353e-05\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.3400e-04 - mse: 4.6800e-04 - val_loss: 3.1355e-05 - val_mse: 6.2710e-05\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.3341e-04 - mse: 4.6683e-04 - val_loss: 9.8888e-06 - val_mse: 1.9778e-05\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.4027e-04 - mse: 4.8054e-04 - val_loss: 1.5712e-05 - val_mse: 3.1424e-05\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.6782e-04 - mse: 5.3563e-04 - val_loss: 1.4109e-05 - val_mse: 2.8218e-05\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.3142e-04 - mse: 4.6283e-04 - val_loss: 1.6452e-05 - val_mse: 3.2904e-05\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.3551e-04 - mse: 4.7101e-04 - val_loss: 1.1207e-05 - val_mse: 2.2415e-05\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 2s 14ms/step - loss: 2.1295e-04 - mse: 4.2589e-04 - val_loss: 1.4550e-05 - val_mse: 2.9100e-05\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.2103e-04 - mse: 4.4205e-04 - val_loss: 1.8927e-05 - val_mse: 3.7855e-05\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.1661e-04 - mse: 4.3321e-04 - val_loss: 9.1279e-06 - val_mse: 1.8256e-05\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.1154e-04 - mse: 4.2308e-04 - val_loss: 1.1303e-05 - val_mse: 2.2606e-05\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.1016e-04 - mse: 4.2032e-04 - val_loss: 9.5125e-06 - val_mse: 1.9025e-05\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.0373e-04 - mse: 4.0746e-04 - val_loss: 1.8377e-05 - val_mse: 3.6753e-05\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.0321e-04 - mse: 4.0642e-04 - val_loss: 9.4980e-06 - val_mse: 1.8996e-05\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.0191e-04 - mse: 4.0382e-04 - val_loss: 1.2193e-05 - val_mse: 2.4386e-05\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.0316e-04 - mse: 4.0632e-04 - val_loss: 1.0075e-05 - val_mse: 2.0150e-05\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 2.1577e-04 - mse: 4.3153e-04 - val_loss: 8.6533e-06 - val_mse: 1.7307e-05\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.0418e-04 - mse: 4.0836e-04 - val_loss: 8.5375e-06 - val_mse: 1.7075e-05\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.2645e-04 - mse: 4.5290e-04 - val_loss: 9.6351e-06 - val_mse: 1.9270e-05\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.9739e-04 - mse: 3.9478e-04 - val_loss: 2.8047e-05 - val_mse: 5.6095e-05\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.9406e-04 - mse: 3.8811e-04 - val_loss: 1.2787e-05 - val_mse: 2.5575e-05\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.9830e-04 - mse: 3.9660e-04 - val_loss: 1.6981e-05 - val_mse: 3.3962e-05\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.8708e-04 - mse: 3.7416e-04 - val_loss: 8.0044e-06 - val_mse: 1.6009e-05\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.9800e-04 - mse: 3.9599e-04 - val_loss: 8.1187e-06 - val_mse: 1.6237e-05\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.8412e-04 - mse: 3.6825e-04 - val_loss: 1.5906e-05 - val_mse: 3.1812e-05\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.9748e-04 - mse: 3.9497e-04 - val_loss: 8.7844e-06 - val_mse: 1.7569e-05\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.9026e-04 - mse: 3.8051e-04 - val_loss: 1.8961e-05 - val_mse: 3.7923e-05\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.9090e-04 - mse: 3.8181e-04 - val_loss: 7.7028e-06 - val_mse: 1.5406e-05\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.9735e-04 - mse: 3.9471e-04 - val_loss: 1.2994e-05 - val_mse: 2.5987e-05\n",
      "HMM_운수창고업.csv\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:1414.627238226131\n",
      "[4637.910037047648, 1545.7214371684267, 1649.5571988962656, 1414.627238226131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 6s 22ms/step - loss: 0.0056 - mse: 0.0112 - val_loss: 5.3380e-05 - val_mse: 1.0676e-04\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.2562e-04 - mse: 0.0011 - val_loss: 3.1675e-05 - val_mse: 6.3350e-05\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 4.8496e-04 - mse: 9.6991e-04 - val_loss: 2.8417e-05 - val_mse: 5.6833e-05\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 4.7563e-04 - mse: 9.5127e-04 - val_loss: 2.9096e-05 - val_mse: 5.8192e-05\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.2126e-04 - mse: 8.4251e-04 - val_loss: 2.2743e-05 - val_mse: 4.5486e-05\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 3.8054e-04 - mse: 7.6107e-04 - val_loss: 2.5807e-05 - val_mse: 5.1613e-05\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 3.3242e-04 - mse: 6.6485e-04 - val_loss: 2.0489e-05 - val_mse: 4.0977e-05\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 2.8942e-04 - mse: 5.7884e-04 - val_loss: 1.5812e-05 - val_mse: 3.1623e-05\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.7731e-04 - mse: 5.5461e-04 - val_loss: 3.0183e-05 - val_mse: 6.0366e-05\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.3667e-04 - mse: 4.7334e-04 - val_loss: 1.4348e-05 - val_mse: 2.8696e-05\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.1352e-04 - mse: 4.2705e-04 - val_loss: 1.2571e-05 - val_mse: 2.5142e-05\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.2021e-04 - mse: 4.4041e-04 - val_loss: 1.3742e-05 - val_mse: 2.7485e-05\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 2.0637e-04 - mse: 4.1275e-04 - val_loss: 1.5965e-05 - val_mse: 3.1929e-05\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.9701e-04 - mse: 3.9403e-04 - val_loss: 1.1135e-05 - val_mse: 2.2270e-05\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.8450e-04 - mse: 3.6901e-04 - val_loss: 1.1791e-05 - val_mse: 2.3583e-05\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.9018e-04 - mse: 3.8036e-04 - val_loss: 1.1110e-05 - val_mse: 2.2220e-05\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.7807e-04 - mse: 3.5614e-04 - val_loss: 1.7855e-05 - val_mse: 3.5711e-05\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.7487e-04 - mse: 3.4974e-04 - val_loss: 1.1690e-05 - val_mse: 2.3380e-05\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.9449e-04 - mse: 3.8897e-04 - val_loss: 8.5922e-06 - val_mse: 1.7184e-05\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.8210e-04 - mse: 3.6420e-04 - val_loss: 8.1807e-06 - val_mse: 1.6361e-05\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.7546e-04 - mse: 3.5093e-04 - val_loss: 9.2355e-06 - val_mse: 1.8471e-05\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.7097e-04 - mse: 3.4194e-04 - val_loss: 7.3845e-06 - val_mse: 1.4769e-05\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.6537e-04 - mse: 3.3075e-04 - val_loss: 9.2333e-06 - val_mse: 1.8467e-05\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.7360e-04 - mse: 3.4719e-04 - val_loss: 7.8944e-06 - val_mse: 1.5789e-05\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.6388e-04 - mse: 3.2776e-04 - val_loss: 1.0438e-05 - val_mse: 2.0876e-05\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.5995e-04 - mse: 3.1990e-04 - val_loss: 1.0577e-05 - val_mse: 2.1154e-05\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.6256e-04 - mse: 3.2513e-04 - val_loss: 1.1968e-05 - val_mse: 2.3936e-05\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.5266e-04 - mse: 3.0533e-04 - val_loss: 7.9168e-06 - val_mse: 1.5834e-05\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.5430e-04 - mse: 3.0860e-04 - val_loss: 7.1525e-06 - val_mse: 1.4305e-05\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.6061e-04 - mse: 3.2122e-04 - val_loss: 9.7890e-06 - val_mse: 1.9578e-05\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.5474e-04 - mse: 3.0949e-04 - val_loss: 9.2567e-06 - val_mse: 1.8513e-05\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.5085e-04 - mse: 3.0170e-04 - val_loss: 8.7189e-06 - val_mse: 1.7438e-05\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.6267e-04 - mse: 3.2534e-04 - val_loss: 1.1212e-05 - val_mse: 2.2424e-05\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.4468e-04 - mse: 2.8936e-04 - val_loss: 8.4905e-06 - val_mse: 1.6981e-05\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.4263e-04 - mse: 2.8526e-04 - val_loss: 1.0131e-05 - val_mse: 2.0261e-05\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.5293e-04 - mse: 3.0586e-04 - val_loss: 6.2947e-06 - val_mse: 1.2589e-05\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.3892e-04 - mse: 2.7783e-04 - val_loss: 8.4052e-06 - val_mse: 1.6810e-05\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3792e-04 - mse: 2.7584e-04 - val_loss: 7.9650e-06 - val_mse: 1.5930e-05\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.5362e-04 - mse: 3.0724e-04 - val_loss: 7.4498e-06 - val_mse: 1.4900e-05\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 1.3620e-04 - mse: 2.7240e-04 - val_loss: 6.3799e-06 - val_mse: 1.2760e-05\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.4031e-04 - mse: 2.8063e-04 - val_loss: 5.5348e-06 - val_mse: 1.1070e-05\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.3604e-04 - mse: 2.7209e-04 - val_loss: 5.6868e-06 - val_mse: 1.1374e-05\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.3157e-04 - mse: 2.6314e-04 - val_loss: 5.6777e-06 - val_mse: 1.1355e-05\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2818e-04 - mse: 2.5637e-04 - val_loss: 6.7780e-06 - val_mse: 1.3556e-05\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3123e-04 - mse: 2.6246e-04 - val_loss: 6.2110e-06 - val_mse: 1.2422e-05\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2794e-04 - mse: 2.5589e-04 - val_loss: 7.1345e-06 - val_mse: 1.4269e-05\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.3154e-04 - mse: 2.6307e-04 - val_loss: 5.7640e-06 - val_mse: 1.1528e-05\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.3341e-04 - mse: 2.6682e-04 - val_loss: 5.9573e-06 - val_mse: 1.1915e-05\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.2743e-04 - mse: 2.5486e-04 - val_loss: 1.1559e-05 - val_mse: 2.3118e-05\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2137e-04 - mse: 2.4274e-04 - val_loss: 7.0565e-06 - val_mse: 1.4113e-05\n",
      "HMM_운수창고업.csv\n",
      "5000길이의 데이터 적용 완료\n",
      " 길이: 5000, RMSE:1042.4920014210386\n",
      "[4637.910037047648, 1545.7214371684267, 1649.5571988962656, 1414.627238226131, 1042.4920014210386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "137/137 [==============================] - 6s 21ms/step - loss: 7.0367e-04 - mse: 0.0014 - val_loss: 1.9237e-05 - val_mse: 3.8475e-05\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 3.0709e-04 - mse: 6.1418e-04 - val_loss: 3.1967e-05 - val_mse: 6.3933e-05\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.7780e-04 - mse: 5.5561e-04 - val_loss: 1.0454e-05 - val_mse: 2.0908e-05\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.6088e-04 - mse: 5.2176e-04 - val_loss: 8.9496e-06 - val_mse: 1.7899e-05\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 2.4345e-04 - mse: 4.8690e-04 - val_loss: 8.8424e-06 - val_mse: 1.7685e-05\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 2.2141e-04 - mse: 4.4282e-04 - val_loss: 9.1235e-06 - val_mse: 1.8247e-05\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.9735e-04 - mse: 3.9469e-04 - val_loss: 1.1540e-05 - val_mse: 2.3080e-05\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.9175e-04 - mse: 3.8350e-04 - val_loss: 1.2600e-05 - val_mse: 2.5200e-05\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.7779e-04 - mse: 3.5559e-04 - val_loss: 7.9356e-06 - val_mse: 1.5871e-05\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.9000e-04 - mse: 3.7999e-04 - val_loss: 1.0186e-05 - val_mse: 2.0372e-05\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.7850e-04 - mse: 3.5700e-04 - val_loss: 7.5478e-06 - val_mse: 1.5096e-05\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.6149e-04 - mse: 3.2298e-04 - val_loss: 7.6385e-06 - val_mse: 1.5277e-05\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.5280e-04 - mse: 3.0560e-04 - val_loss: 1.0776e-05 - val_mse: 2.1551e-05\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.4666e-04 - mse: 2.9332e-04 - val_loss: 1.6824e-05 - val_mse: 3.3648e-05\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 3s 21ms/step - loss: 1.4966e-04 - mse: 2.9933e-04 - val_loss: 7.2752e-06 - val_mse: 1.4550e-05\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.6311e-04 - mse: 3.2621e-04 - val_loss: 8.6671e-06 - val_mse: 1.7334e-05\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.3889e-04 - mse: 2.7778e-04 - val_loss: 1.1211e-05 - val_mse: 2.2422e-05\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.3615e-04 - mse: 2.7230e-04 - val_loss: 9.4333e-06 - val_mse: 1.8867e-05\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4104e-04 - mse: 2.8209e-04 - val_loss: 1.6348e-05 - val_mse: 3.2695e-05\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3653e-04 - mse: 2.7306e-04 - val_loss: 6.8488e-06 - val_mse: 1.3698e-05\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4140e-04 - mse: 2.8279e-04 - val_loss: 7.4817e-06 - val_mse: 1.4963e-05\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.2831e-04 - mse: 2.5661e-04 - val_loss: 7.0358e-06 - val_mse: 1.4072e-05\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.4267e-04 - mse: 2.8535e-04 - val_loss: 6.4308e-06 - val_mse: 1.2862e-05\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 3s 23ms/step - loss: 1.3663e-04 - mse: 2.7326e-04 - val_loss: 8.0190e-06 - val_mse: 1.6038e-05\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 4s 24ms/step - loss: 1.2812e-04 - mse: 2.5624e-04 - val_loss: 1.3170e-05 - val_mse: 2.6341e-05\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 3s 22ms/step - loss: 1.4217e-04 - mse: 2.8434e-04 - val_loss: 2.1704e-05 - val_mse: 4.3408e-05\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.2693e-04 - mse: 2.5386e-04 - val_loss: 7.5034e-06 - val_mse: 1.5007e-05\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.2950e-04 - mse: 2.5900e-04 - val_loss: 7.4515e-06 - val_mse: 1.4903e-05\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 1.2554e-04 - mse: 2.5108e-04 - val_loss: 1.1129e-05 - val_mse: 2.2257e-05\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 1.2859e-04 - mse: 2.5718e-04 - val_loss: 2.0078e-05 - val_mse: 4.0157e-05\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 1.2592e-04 - mse: 2.5184e-04 - val_loss: 1.1996e-05 - val_mse: 2.3991e-05\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 1.1500e-04 - mse: 2.3000e-04 - val_loss: 7.8836e-06 - val_mse: 1.5767e-05\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 1.2065e-04 - mse: 2.4129e-04 - val_loss: 8.0336e-06 - val_mse: 1.6067e-05\n",
      "HMM_운수창고업.csv\n",
      "6000길이의 데이터 적용 완료\n",
      " 길이: 6000, RMSE:1112.328230050794\n",
      "[4637.910037047648, 1545.7214371684267, 1649.5571988962656, 1414.627238226131, 1042.4920014210386, 1112.328230050794]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 5s 51ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 6.1655e-06 - val_mse: 1.2331e-05\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0044 - mse: 0.0087 - val_loss: 8.2823e-06 - val_mse: 1.6565e-05\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0040 - mse: 0.0080 - val_loss: 4.0636e-05 - val_mse: 8.1271e-05\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0037 - mse: 0.0075 - val_loss: 1.6843e-05 - val_mse: 3.3686e-05\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 8.5262e-07 - val_mse: 1.7052e-06\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0031 - mse: 0.0061 - val_loss: 8.0153e-05 - val_mse: 1.6031e-04\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 2.1533e-06 - val_mse: 4.3066e-06\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 1.1552e-05 - val_mse: 2.3104e-05\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 9.3521e-07 - val_mse: 1.8704e-06\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 1.7039e-05 - val_mse: 3.4078e-05\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 5.1835e-06 - val_mse: 1.0367e-05\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 6.2105e-07 - val_mse: 1.2421e-06\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 2.5975e-06 - val_mse: 5.1950e-06\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 1.2338e-05 - val_mse: 2.4676e-05\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 3.8633e-06 - val_mse: 7.7266e-06\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 8.2900e-05 - val_mse: 1.6580e-04\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 2.6024e-06 - val_mse: 5.2049e-06\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 2.4718e-05 - val_mse: 4.9436e-05\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 6.5875e-05 - val_mse: 1.3175e-04\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 8.3536e-06 - val_mse: 1.6707e-05\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 1.3673e-06 - val_mse: 2.7345e-06\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 2.0440e-05 - val_mse: 4.0881e-05\n",
      "KB금융_기타금융.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:19309.38883580023\n",
      "[19309.38883580023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 5s 33ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 3.2857e-06 - val_mse: 6.5714e-06\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0022 - mse: 0.0045 - val_loss: 2.5166e-06 - val_mse: 5.0331e-06\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 1.6622e-06 - val_mse: 3.3244e-06\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 4.5408e-05 - val_mse: 9.0815e-05\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 9.5477e-07 - val_mse: 1.9095e-06\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 2.9264e-06 - val_mse: 5.8528e-06\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 6.9166e-06 - val_mse: 1.3833e-05\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 5.1581e-05 - val_mse: 1.0316e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 6.1724e-07 - val_mse: 1.2345e-06\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 9.6666e-04 - mse: 0.0019 - val_loss: 6.3035e-07 - val_mse: 1.2607e-06\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 8.5177e-04 - mse: 0.0017 - val_loss: 1.2505e-05 - val_mse: 2.5010e-05\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 7.5734e-04 - mse: 0.0015 - val_loss: 5.4597e-06 - val_mse: 1.0919e-05\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 7.4538e-04 - mse: 0.0015 - val_loss: 3.0058e-05 - val_mse: 6.0116e-05\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 7.4466e-04 - mse: 0.0015 - val_loss: 8.9913e-06 - val_mse: 1.7983e-05\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 6.8496e-04 - mse: 0.0014 - val_loss: 2.3286e-06 - val_mse: 4.6572e-06\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 7.0629e-04 - mse: 0.0014 - val_loss: 5.8121e-05 - val_mse: 1.1624e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.7353e-04 - mse: 0.0013 - val_loss: 1.5674e-06 - val_mse: 3.1348e-06\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.6848e-04 - mse: 0.0013 - val_loss: 1.6142e-06 - val_mse: 3.2283e-06\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.2959e-04 - mse: 0.0013 - val_loss: 2.7644e-05 - val_mse: 5.5287e-05\n",
      "KB금융_기타금융.csv\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:22466.35284127896\n",
      "[19309.38883580023, 22466.35284127896]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 5s 26ms/step - loss: 2.1612e-06 - mse: 4.3225e-06 - val_loss: 0.0075 - val_mse: 0.0150\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 8.8175e-07 - mse: 1.7635e-06 - val_loss: 0.0069 - val_mse: 0.0139\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.9043e-07 - mse: 3.8086e-07 - val_loss: 0.0068 - val_mse: 0.0136\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0076e-07 - mse: 2.0152e-07 - val_loss: 0.0068 - val_mse: 0.0135\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 1.0658e-07 - mse: 2.1316e-07 - val_loss: 0.0067 - val_mse: 0.0135\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.2483e-07 - mse: 2.4966e-07 - val_loss: 0.0067 - val_mse: 0.0134\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.2682e-07 - mse: 2.5364e-07 - val_loss: 0.0067 - val_mse: 0.0133\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.0948e-07 - mse: 2.1896e-07 - val_loss: 0.0066 - val_mse: 0.0132\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.2518e-07 - mse: 2.5035e-07 - val_loss: 0.0066 - val_mse: 0.0132\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.3782e-07 - mse: 2.7565e-07 - val_loss: 0.0065 - val_mse: 0.0131\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0566e-07 - mse: 2.1132e-07 - val_loss: 0.0065 - val_mse: 0.0130\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 1.0636e-07 - mse: 2.1272e-07 - val_loss: 0.0064 - val_mse: 0.0129\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 1.1742e-07 - mse: 2.3484e-07 - val_loss: 0.0064 - val_mse: 0.0128\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.1855e-07 - mse: 2.3709e-07 - val_loss: 0.0064 - val_mse: 0.0127\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 1.0415e-07 - mse: 2.0830e-07 - val_loss: 0.0063 - val_mse: 0.0126\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0396e-07 - mse: 2.0792e-07 - val_loss: 0.0063 - val_mse: 0.0126\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9.9987e-08 - mse: 1.9997e-07 - val_loss: 0.0062 - val_mse: 0.0125\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.3640e-07 - mse: 2.7280e-07 - val_loss: 0.0062 - val_mse: 0.0124\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9.2645e-08 - mse: 1.8529e-07 - val_loss: 0.0062 - val_mse: 0.0123\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.0280e-07 - mse: 2.0561e-07 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9.7010e-08 - mse: 1.9402e-07 - val_loss: 0.0061 - val_mse: 0.0122\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.1495e-07 - mse: 2.2991e-07 - val_loss: 0.0060 - val_mse: 0.0121\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9.1908e-08 - mse: 1.8382e-07 - val_loss: 0.0060 - val_mse: 0.0120\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0104e-07 - mse: 2.0208e-07 - val_loss: 0.0060 - val_mse: 0.0119\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9.5541e-08 - mse: 1.9108e-07 - val_loss: 0.0059 - val_mse: 0.0118\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 8.4974e-08 - mse: 1.6995e-07 - val_loss: 0.0059 - val_mse: 0.0118\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9.0869e-08 - mse: 1.8174e-07 - val_loss: 0.0058 - val_mse: 0.0117\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.0235e-07 - mse: 2.0470e-07 - val_loss: 0.0058 - val_mse: 0.0116\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 9.5458e-08 - mse: 1.9092e-07 - val_loss: 0.0058 - val_mse: 0.0115\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.1241e-07 - mse: 2.2482e-07 - val_loss: 0.0057 - val_mse: 0.0115\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.0377e-07 - mse: 2.0754e-07 - val_loss: 0.0057 - val_mse: 0.0114\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 7.7847e-08 - mse: 1.5569e-07 - val_loss: 0.0057 - val_mse: 0.0113\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 1.0218e-07 - mse: 2.0436e-07 - val_loss: 0.0056 - val_mse: 0.0113\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 8.6604e-08 - mse: 1.7321e-07 - val_loss: 0.0056 - val_mse: 0.0112\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 8.9057e-08 - mse: 1.7811e-07 - val_loss: 0.0056 - val_mse: 0.0112\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 8.0637e-08 - mse: 1.6127e-07 - val_loss: 0.0055 - val_mse: 0.0111\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9.0880e-08 - mse: 1.8176e-07 - val_loss: 0.0055 - val_mse: 0.0110\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 7.2395e-08 - mse: 1.4479e-07 - val_loss: 0.0055 - val_mse: 0.0110\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9.1750e-08 - mse: 1.8350e-07 - val_loss: 0.0055 - val_mse: 0.0109\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 8.0159e-08 - mse: 1.6032e-07 - val_loss: 0.0054 - val_mse: 0.0109\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 7.7723e-08 - mse: 1.5545e-07 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9.5464e-08 - mse: 1.9093e-07 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 6.8354e-08 - mse: 1.3671e-07 - val_loss: 0.0054 - val_mse: 0.0107\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.0316e-07 - mse: 2.0632e-07 - val_loss: 0.0053 - val_mse: 0.0107\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 8.4019e-08 - mse: 1.6804e-07 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 6.9425e-08 - mse: 1.3885e-07 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 7.4007e-08 - mse: 1.4801e-07 - val_loss: 0.0052 - val_mse: 0.0105\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0776e-07 - mse: 2.1552e-07 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9.0127e-08 - mse: 1.8025e-07 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9.3289e-08 - mse: 1.8658e-07 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "KB금융_기타금융.csv\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:307448.84161771997\n",
      "[19309.38883580023, 22466.35284127896, 307448.84161771997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 7s 26ms/step - loss: 1.7122e-06 - mse: 3.4244e-06 - val_loss: 0.0059 - val_mse: 0.0118\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 3.4425e-07 - mse: 6.8849e-07 - val_loss: 0.0055 - val_mse: 0.0111\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.1138e-07 - mse: 2.2277e-07 - val_loss: 0.0055 - val_mse: 0.0109\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0805e-07 - mse: 2.1609e-07 - val_loss: 0.0054 - val_mse: 0.0109\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.0601e-07 - mse: 2.1203e-07 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.1961e-07 - mse: 2.3923e-07 - val_loss: 0.0054 - val_mse: 0.0108\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.1259e-07 - mse: 2.2519e-07 - val_loss: 0.0054 - val_mse: 0.0107\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 1.0586e-07 - mse: 2.1172e-07 - val_loss: 0.0053 - val_mse: 0.0107\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.1426e-07 - mse: 2.2851e-07 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.2288e-07 - mse: 2.4577e-07 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0468e-07 - mse: 2.0936e-07 - val_loss: 0.0053 - val_mse: 0.0105\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 1.1410e-07 - mse: 2.2820e-07 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.1879e-07 - mse: 2.3757e-07 - val_loss: 0.0052 - val_mse: 0.0104\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 9.6284e-08 - mse: 1.9257e-07 - val_loss: 0.0052 - val_mse: 0.0103\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 1.1963e-07 - mse: 2.3925e-07 - val_loss: 0.0051 - val_mse: 0.0103\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.1711e-07 - mse: 2.3423e-07 - val_loss: 0.0051 - val_mse: 0.0102\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 9.3162e-08 - mse: 1.8632e-07 - val_loss: 0.0051 - val_mse: 0.0102\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 2s 16ms/step - loss: 1.0713e-07 - mse: 2.1426e-07 - val_loss: 0.0051 - val_mse: 0.0101\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 1.0303e-07 - mse: 2.0605e-07 - val_loss: 0.0050 - val_mse: 0.0101\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 9.1105e-08 - mse: 1.8221e-07 - val_loss: 0.0050 - val_mse: 0.0100\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 9.8927e-08 - mse: 1.9785e-07 - val_loss: 0.0050 - val_mse: 0.0100\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0084e-07 - mse: 2.0169e-07 - val_loss: 0.0050 - val_mse: 0.0099\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 1.2323e-07 - mse: 2.4646e-07 - val_loss: 0.0049 - val_mse: 0.0099\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 9.8197e-08 - mse: 1.9639e-07 - val_loss: 0.0049 - val_mse: 0.0098\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 9.3387e-08 - mse: 1.8677e-07 - val_loss: 0.0049 - val_mse: 0.0098\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.0504e-07 - mse: 2.1008e-07 - val_loss: 0.0049 - val_mse: 0.0097\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 9.7972e-08 - mse: 1.9594e-07 - val_loss: 0.0048 - val_mse: 0.0097\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 9.4686e-08 - mse: 1.8937e-07 - val_loss: 0.0048 - val_mse: 0.0096\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 9.9890e-08 - mse: 1.9978e-07 - val_loss: 0.0048 - val_mse: 0.0096\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 9.7577e-08 - mse: 1.9515e-07 - val_loss: 0.0048 - val_mse: 0.0095\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 9.1399e-08 - mse: 1.8280e-07 - val_loss: 0.0048 - val_mse: 0.0095\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 7.7575e-08 - mse: 1.5515e-07 - val_loss: 0.0047 - val_mse: 0.0095\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 9.3616e-08 - mse: 1.8723e-07 - val_loss: 0.0047 - val_mse: 0.0094\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 9.2069e-08 - mse: 1.8414e-07 - val_loss: 0.0047 - val_mse: 0.0094\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 9.0694e-08 - mse: 1.8139e-07 - val_loss: 0.0047 - val_mse: 0.0093\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 8.3435e-08 - mse: 1.6687e-07 - val_loss: 0.0046 - val_mse: 0.0093\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 8.7649e-08 - mse: 1.7530e-07 - val_loss: 0.0046 - val_mse: 0.0093\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 9.8410e-08 - mse: 1.9682e-07 - val_loss: 0.0046 - val_mse: 0.0092\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0559e-07 - mse: 2.1118e-07 - val_loss: 0.0046 - val_mse: 0.0092\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.1074e-07 - mse: 2.2148e-07 - val_loss: 0.0046 - val_mse: 0.0092\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 8.3780e-08 - mse: 1.6756e-07 - val_loss: 0.0046 - val_mse: 0.0091\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 7.6916e-08 - mse: 1.5383e-07 - val_loss: 0.0045 - val_mse: 0.0091\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 9.1102e-08 - mse: 1.8220e-07 - val_loss: 0.0045 - val_mse: 0.0090\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 8.1823e-08 - mse: 1.6365e-07 - val_loss: 0.0045 - val_mse: 0.0090\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 8.0836e-08 - mse: 1.6167e-07 - val_loss: 0.0045 - val_mse: 0.0090\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 7.9793e-08 - mse: 1.5959e-07 - val_loss: 0.0045 - val_mse: 0.0089\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 8.0809e-08 - mse: 1.6162e-07 - val_loss: 0.0044 - val_mse: 0.0089\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0190e-07 - mse: 2.0380e-07 - val_loss: 0.0044 - val_mse: 0.0089\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 7.6365e-08 - mse: 1.5273e-07 - val_loss: 0.0044 - val_mse: 0.0088\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.0463e-07 - mse: 2.0926e-07 - val_loss: 0.0044 - val_mse: 0.0088\n",
      "KB금융_기타금융.csv\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:284356.9515850287\n",
      "[19309.38883580023, 22466.35284127896, 307448.84161771997, 284356.9515850287]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 5s 52ms/step - loss: 0.1561 - mse: 0.3121 - val_loss: 0.0489 - val_mse: 0.0977\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0174 - mse: 0.0347 - val_loss: 0.0017 - val_mse: 0.0035\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 5.0883e-04 - val_mse: 0.0010\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 5.2474e-04 - val_mse: 0.0010\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 4.3058e-04 - val_mse: 8.6115e-04\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 4.9982e-04 - val_mse: 9.9963e-04\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 4.0774e-04 - val_mse: 8.1548e-04\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 3.9090e-04 - val_mse: 7.8181e-04\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 3.5626e-04 - val_mse: 7.1252e-04\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 3.1629e-04 - val_mse: 6.3257e-04\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 3.1094e-04 - val_mse: 6.2187e-04\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 3.2571e-04 - val_mse: 6.5142e-04\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 2.8703e-04 - val_mse: 5.7405e-04\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 2.7591e-04 - val_mse: 5.5182e-04\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 9.7019e-04 - mse: 0.0019 - val_loss: 2.7166e-04 - val_mse: 5.4332e-04\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 9.3138e-04 - mse: 0.0019 - val_loss: 2.5786e-04 - val_mse: 5.1571e-04\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 8.9996e-04 - mse: 0.0018 - val_loss: 2.4871e-04 - val_mse: 4.9743e-04\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 8.9882e-04 - mse: 0.0018 - val_loss: 2.4464e-04 - val_mse: 4.8927e-04\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 8.5964e-04 - mse: 0.0017 - val_loss: 2.9600e-04 - val_mse: 5.9200e-04\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 8.3109e-04 - mse: 0.0017 - val_loss: 2.2570e-04 - val_mse: 4.5139e-04\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 8.1237e-04 - mse: 0.0016 - val_loss: 2.4327e-04 - val_mse: 4.8653e-04\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 16ms/step - loss: 7.9121e-04 - mse: 0.0016 - val_loss: 2.6815e-04 - val_mse: 5.3630e-04\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 8.0162e-04 - mse: 0.0016 - val_loss: 2.5188e-04 - val_mse: 5.0376e-04\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 7.3980e-04 - mse: 0.0015 - val_loss: 2.1075e-04 - val_mse: 4.2150e-04\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 7.1350e-04 - mse: 0.0014 - val_loss: 2.1265e-04 - val_mse: 4.2529e-04\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 7.1787e-04 - mse: 0.0014 - val_loss: 2.0186e-04 - val_mse: 4.0372e-04\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 6.9353e-04 - mse: 0.0014 - val_loss: 2.0144e-04 - val_mse: 4.0289e-04\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 6.9605e-04 - mse: 0.0014 - val_loss: 2.7313e-04 - val_mse: 5.4626e-04\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 6.9703e-04 - mse: 0.0014 - val_loss: 1.9599e-04 - val_mse: 3.9198e-04\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 6.4434e-04 - mse: 0.0013 - val_loss: 2.0961e-04 - val_mse: 4.1922e-04\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 6.9896e-04 - mse: 0.0014 - val_loss: 1.9851e-04 - val_mse: 3.9702e-04\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 6.4052e-04 - mse: 0.0013 - val_loss: 2.6255e-04 - val_mse: 5.2510e-04\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 6.3679e-04 - mse: 0.0013 - val_loss: 1.8936e-04 - val_mse: 3.7871e-04\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 6.5491e-04 - mse: 0.0013 - val_loss: 2.4000e-04 - val_mse: 4.8000e-04\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 6.5931e-04 - mse: 0.0013 - val_loss: 1.9613e-04 - val_mse: 3.9226e-04\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 6.0905e-04 - mse: 0.0012 - val_loss: 1.8534e-04 - val_mse: 3.7069e-04\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 6.1380e-04 - mse: 0.0012 - val_loss: 1.8597e-04 - val_mse: 3.7194e-04\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 6.1093e-04 - mse: 0.0012 - val_loss: 2.0412e-04 - val_mse: 4.0823e-04\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 5.9403e-04 - mse: 0.0012 - val_loss: 1.9639e-04 - val_mse: 3.9278e-04\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 5.7737e-04 - mse: 0.0012 - val_loss: 2.2713e-04 - val_mse: 4.5427e-04\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 5.7524e-04 - mse: 0.0012 - val_loss: 1.8387e-04 - val_mse: 3.6774e-04\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 5.7092e-04 - mse: 0.0011 - val_loss: 1.7650e-04 - val_mse: 3.5299e-04\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 5.9297e-04 - mse: 0.0012 - val_loss: 2.0294e-04 - val_mse: 4.0589e-04\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 5.9398e-04 - mse: 0.0012 - val_loss: 1.8824e-04 - val_mse: 3.7648e-04\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 5.6109e-04 - mse: 0.0011 - val_loss: 1.7474e-04 - val_mse: 3.4948e-04\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 5.7147e-04 - mse: 0.0011 - val_loss: 1.7428e-04 - val_mse: 3.4855e-04\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 6.0828e-04 - mse: 0.0012 - val_loss: 1.7101e-04 - val_mse: 3.4202e-04\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 5.3943e-04 - mse: 0.0011 - val_loss: 1.7473e-04 - val_mse: 3.4946e-04\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 5.5758e-04 - mse: 0.0011 - val_loss: 1.7165e-04 - val_mse: 3.4331e-04\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 5.5319e-04 - mse: 0.0011 - val_loss: 1.6987e-04 - val_mse: 3.3974e-04\n",
      "KT&G_기타제조업.csv\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:673.2830724100673\n",
      "[673.2830724100673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 5s 32ms/step - loss: 0.0807 - mse: 0.1613 - val_loss: 0.0125 - val_mse: 0.0250\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0035 - mse: 0.0069 - val_loss: 6.8834e-04 - val_mse: 0.0014\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 6.0465e-04 - val_mse: 0.0012\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 2.5795e-04 - val_mse: 5.1591e-04\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 2.4741e-04 - val_mse: 4.9483e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 2.4771e-04 - val_mse: 4.9543e-04\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 1.9636e-04 - val_mse: 3.9273e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 1.8864e-04 - val_mse: 3.7728e-04\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 1.8203e-04 - val_mse: 3.6405e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 9.8171e-04 - mse: 0.0020 - val_loss: 2.1361e-04 - val_mse: 4.2722e-04\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 9.4197e-04 - mse: 0.0019 - val_loss: 2.1331e-04 - val_mse: 4.2662e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 8.8315e-04 - mse: 0.0018 - val_loss: 1.6041e-04 - val_mse: 3.2082e-04\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 8.1249e-04 - mse: 0.0016 - val_loss: 1.3964e-04 - val_mse: 2.7928e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 7.3127e-04 - mse: 0.0015 - val_loss: 1.5186e-04 - val_mse: 3.0372e-04\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 7.1782e-04 - mse: 0.0014 - val_loss: 1.4730e-04 - val_mse: 2.9459e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.8809e-04 - mse: 0.0014 - val_loss: 1.3758e-04 - val_mse: 2.7516e-04\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 6.6236e-04 - mse: 0.0013 - val_loss: 1.2803e-04 - val_mse: 2.5606e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.4972e-04 - mse: 0.0013 - val_loss: 1.2292e-04 - val_mse: 2.4584e-04\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.1648e-04 - mse: 0.0012 - val_loss: 1.3548e-04 - val_mse: 2.7095e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 6.0710e-04 - mse: 0.0012 - val_loss: 1.1684e-04 - val_mse: 2.3368e-04\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.7547e-04 - mse: 0.0012 - val_loss: 1.7922e-04 - val_mse: 3.5844e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.9781e-04 - mse: 0.0012 - val_loss: 2.0574e-04 - val_mse: 4.1147e-04\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.8851e-04 - mse: 0.0012 - val_loss: 1.0925e-04 - val_mse: 2.1850e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.6193e-04 - mse: 0.0011 - val_loss: 1.1140e-04 - val_mse: 2.2281e-04\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 5.4572e-04 - mse: 0.0011 - val_loss: 2.4654e-04 - val_mse: 4.9307e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.4681e-04 - mse: 0.0011 - val_loss: 1.2159e-04 - val_mse: 2.4318e-04\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.3778e-04 - mse: 0.0011 - val_loss: 1.9200e-04 - val_mse: 3.8400e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 5.3632e-04 - mse: 0.0011 - val_loss: 1.3866e-04 - val_mse: 2.7732e-04\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 5.0779e-04 - mse: 0.0010 - val_loss: 1.7419e-04 - val_mse: 3.4838e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 5.0396e-04 - mse: 0.0010 - val_loss: 1.1679e-04 - val_mse: 2.3358e-04\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.9203e-04 - mse: 9.8407e-04 - val_loss: 9.8458e-05 - val_mse: 1.9692e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 5.0025e-04 - mse: 0.0010 - val_loss: 1.0869e-04 - val_mse: 2.1737e-04\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.8052e-04 - mse: 9.6104e-04 - val_loss: 1.3287e-04 - val_mse: 2.6574e-04\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.9194e-04 - mse: 9.8388e-04 - val_loss: 9.9250e-05 - val_mse: 1.9850e-04\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.6008e-04 - mse: 9.2016e-04 - val_loss: 9.5470e-05 - val_mse: 1.9094e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.5998e-04 - mse: 9.1995e-04 - val_loss: 1.1793e-04 - val_mse: 2.3586e-04\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.6732e-04 - mse: 9.3463e-04 - val_loss: 1.4458e-04 - val_mse: 2.8916e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.7248e-04 - mse: 9.4495e-04 - val_loss: 2.1101e-04 - val_mse: 4.2202e-04\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 4.4690e-04 - mse: 8.9379e-04 - val_loss: 9.0254e-05 - val_mse: 1.8051e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.4154e-04 - mse: 8.8307e-04 - val_loss: 8.7568e-05 - val_mse: 1.7514e-04\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.3005e-04 - mse: 8.6010e-04 - val_loss: 1.6376e-04 - val_mse: 3.2751e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.4769e-04 - mse: 8.9537e-04 - val_loss: 9.0229e-05 - val_mse: 1.8046e-04\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 4.2961e-04 - mse: 8.5922e-04 - val_loss: 8.9634e-05 - val_mse: 1.7927e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.3511e-04 - mse: 8.7023e-04 - val_loss: 1.1148e-04 - val_mse: 2.2296e-04\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.1981e-04 - mse: 8.3961e-04 - val_loss: 9.3964e-05 - val_mse: 1.8793e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 4.3408e-04 - mse: 8.6817e-04 - val_loss: 8.4329e-05 - val_mse: 1.6866e-04\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 4.0943e-04 - mse: 8.1887e-04 - val_loss: 1.0145e-04 - val_mse: 2.0290e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.1028e-04 - mse: 8.2057e-04 - val_loss: 9.8995e-05 - val_mse: 1.9799e-04\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 4.3137e-04 - mse: 8.6274e-04 - val_loss: 1.0241e-04 - val_mse: 2.0483e-04\n",
      "KT&G_기타제조업.csv\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:705.373706484437\n",
      "[673.2830724100673, 705.373706484437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 6s 28ms/step - loss: 0.0291 - mse: 0.0581 - val_loss: 0.0018 - val_mse: 0.0036\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 4.8607e-04 - val_mse: 9.7215e-04\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 4.9242e-04 - mse: 9.8483e-04 - val_loss: 4.3414e-04 - val_mse: 8.6828e-04\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 3.7825e-04 - mse: 7.5651e-04 - val_loss: 4.3073e-04 - val_mse: 8.6145e-04\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 2s 18ms/step - loss: 3.5411e-04 - mse: 7.0821e-04 - val_loss: 4.1325e-04 - val_mse: 8.2649e-04\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 3.3405e-04 - mse: 6.6811e-04 - val_loss: 3.2779e-04 - val_mse: 6.5559e-04\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 3.2262e-04 - mse: 6.4525e-04 - val_loss: 3.5283e-04 - val_mse: 7.0566e-04\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 3.1692e-04 - mse: 6.3384e-04 - val_loss: 4.2207e-04 - val_mse: 8.4414e-04\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 3.1445e-04 - mse: 6.2889e-04 - val_loss: 3.4517e-04 - val_mse: 6.9035e-04\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.9775e-04 - mse: 5.9551e-04 - val_loss: 2.9607e-04 - val_mse: 5.9213e-04\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.9713e-04 - mse: 5.9426e-04 - val_loss: 2.9374e-04 - val_mse: 5.8748e-04\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.9322e-04 - mse: 5.8643e-04 - val_loss: 3.1427e-04 - val_mse: 6.2854e-04\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.9076e-04 - mse: 5.8152e-04 - val_loss: 2.7929e-04 - val_mse: 5.5858e-04\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 2.7817e-04 - mse: 5.5633e-04 - val_loss: 2.7153e-04 - val_mse: 5.4306e-04\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 2.7754e-04 - mse: 5.5508e-04 - val_loss: 2.7283e-04 - val_mse: 5.4567e-04\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.6931e-04 - mse: 5.3861e-04 - val_loss: 2.8576e-04 - val_mse: 5.7153e-04\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.7108e-04 - mse: 5.4215e-04 - val_loss: 3.0975e-04 - val_mse: 6.1951e-04\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.5437e-04 - mse: 5.0875e-04 - val_loss: 2.5782e-04 - val_mse: 5.1564e-04\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4862e-04 - mse: 4.9724e-04 - val_loss: 2.5559e-04 - val_mse: 5.1118e-04\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.5883e-04 - mse: 5.1766e-04 - val_loss: 2.3305e-04 - val_mse: 4.6609e-04\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.4252e-04 - mse: 4.8503e-04 - val_loss: 2.1206e-04 - val_mse: 4.2413e-04\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 2.3760e-04 - mse: 4.7520e-04 - val_loss: 2.2353e-04 - val_mse: 4.4707e-04\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.4539e-04 - mse: 4.9078e-04 - val_loss: 2.2757e-04 - val_mse: 4.5515e-04\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.2872e-04 - mse: 4.5744e-04 - val_loss: 2.2821e-04 - val_mse: 4.5641e-04\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.1509e-04 - mse: 4.3017e-04 - val_loss: 1.9299e-04 - val_mse: 3.8597e-04\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 2.1528e-04 - mse: 4.3056e-04 - val_loss: 2.3421e-04 - val_mse: 4.6841e-04\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 2.1497e-04 - mse: 4.2994e-04 - val_loss: 1.8326e-04 - val_mse: 3.6651e-04\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 2.0217e-04 - mse: 4.0434e-04 - val_loss: 2.0945e-04 - val_mse: 4.1891e-04\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 2.0072e-04 - mse: 4.0144e-04 - val_loss: 1.7636e-04 - val_mse: 3.5273e-04\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 1.9736e-04 - mse: 3.9473e-04 - val_loss: 1.7484e-04 - val_mse: 3.4967e-04\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 1.9679e-04 - mse: 3.9358e-04 - val_loss: 1.7907e-04 - val_mse: 3.5814e-04\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 1.8952e-04 - mse: 3.7903e-04 - val_loss: 1.9156e-04 - val_mse: 3.8313e-04\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.9060e-04 - mse: 3.8119e-04 - val_loss: 1.7109e-04 - val_mse: 3.4217e-04\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 1.9872e-04 - mse: 3.9745e-04 - val_loss: 2.1517e-04 - val_mse: 4.3034e-04\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 2.0609e-04 - mse: 4.1218e-04 - val_loss: 1.5492e-04 - val_mse: 3.0984e-04\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.8216e-04 - mse: 3.6432e-04 - val_loss: 1.5585e-04 - val_mse: 3.1170e-04\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.7376e-04 - mse: 3.4753e-04 - val_loss: 1.5202e-04 - val_mse: 3.0404e-04\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.8680e-04 - mse: 3.7360e-04 - val_loss: 1.5987e-04 - val_mse: 3.1973e-04\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.8764e-04 - mse: 3.7528e-04 - val_loss: 1.9903e-04 - val_mse: 3.9805e-04\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.7054e-04 - mse: 3.4108e-04 - val_loss: 1.4979e-04 - val_mse: 2.9957e-04\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.7460e-04 - mse: 3.4920e-04 - val_loss: 1.6876e-04 - val_mse: 3.3752e-04\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.6401e-04 - mse: 3.2803e-04 - val_loss: 1.5090e-04 - val_mse: 3.0181e-04\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.7527e-04 - mse: 3.5053e-04 - val_loss: 2.1282e-04 - val_mse: 4.2564e-04\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.6694e-04 - mse: 3.3387e-04 - val_loss: 1.3649e-04 - val_mse: 2.7297e-04\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.7074e-04 - mse: 3.4148e-04 - val_loss: 1.3682e-04 - val_mse: 2.7364e-04\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.5559e-04 - mse: 3.1117e-04 - val_loss: 1.3267e-04 - val_mse: 2.6534e-04\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.5788e-04 - mse: 3.1577e-04 - val_loss: 1.3138e-04 - val_mse: 2.6276e-04\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 1.6209e-04 - mse: 3.2419e-04 - val_loss: 1.3352e-04 - val_mse: 2.6705e-04\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 1.7843e-04 - mse: 3.5686e-04 - val_loss: 1.5980e-04 - val_mse: 3.1960e-04\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 1.6082e-04 - mse: 3.2163e-04 - val_loss: 1.4245e-04 - val_mse: 2.8490e-04\n",
      "KT&G_기타제조업.csv\n",
      "3000길이의 데이터 적용 완료\n",
      " 길이: 3000, RMSE:1200.0776741025338\n",
      "[673.2830724100673, 705.373706484437, 1200.0776741025338]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 8s 31ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 2.8571e-04 - val_mse: 5.7142e-04\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.7657e-04 - mse: 5.5313e-04 - val_loss: 2.7530e-04 - val_mse: 5.5060e-04\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.6285e-04 - mse: 5.2570e-04 - val_loss: 2.4270e-04 - val_mse: 4.8540e-04\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.4438e-04 - mse: 4.8876e-04 - val_loss: 2.6254e-04 - val_mse: 5.2508e-04\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.3176e-04 - mse: 4.6352e-04 - val_loss: 2.3253e-04 - val_mse: 4.6506e-04\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.2134e-04 - mse: 4.4267e-04 - val_loss: 2.2313e-04 - val_mse: 4.4625e-04\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 2.3206e-04 - mse: 4.6411e-04 - val_loss: 2.2338e-04 - val_mse: 4.4675e-04\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.0365e-04 - mse: 4.0730e-04 - val_loss: 1.9543e-04 - val_mse: 3.9086e-04\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.0444e-04 - mse: 4.0888e-04 - val_loss: 3.4649e-04 - val_mse: 6.9298e-04\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.9729e-04 - mse: 3.9458e-04 - val_loss: 1.7445e-04 - val_mse: 3.4891e-04\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.7898e-04 - mse: 3.5797e-04 - val_loss: 1.9813e-04 - val_mse: 3.9627e-04\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.7076e-04 - mse: 3.4152e-04 - val_loss: 2.1054e-04 - val_mse: 4.2107e-04\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.7306e-04 - mse: 3.4612e-04 - val_loss: 1.4594e-04 - val_mse: 2.9189e-04\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.6155e-04 - mse: 3.2311e-04 - val_loss: 1.4013e-04 - val_mse: 2.8025e-04\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.5158e-04 - mse: 3.0315e-04 - val_loss: 2.2185e-04 - val_mse: 4.4370e-04\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.5822e-04 - mse: 3.1644e-04 - val_loss: 1.3163e-04 - val_mse: 2.6327e-04\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 1.4654e-04 - mse: 2.9308e-04 - val_loss: 1.2635e-04 - val_mse: 2.5270e-04\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.4462e-04 - mse: 2.8924e-04 - val_loss: 1.4745e-04 - val_mse: 2.9489e-04\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.5528e-04 - mse: 3.1055e-04 - val_loss: 1.4180e-04 - val_mse: 2.8359e-04\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.5160e-04 - mse: 3.0321e-04 - val_loss: 1.1859e-04 - val_mse: 2.3719e-04\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.3410e-04 - mse: 2.6821e-04 - val_loss: 1.4383e-04 - val_mse: 2.8766e-04\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 1.4096e-04 - mse: 2.8193e-04 - val_loss: 1.8146e-04 - val_mse: 3.6291e-04\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.4030e-04 - mse: 2.8060e-04 - val_loss: 1.1860e-04 - val_mse: 2.3721e-04\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.2884e-04 - mse: 2.5769e-04 - val_loss: 1.0895e-04 - val_mse: 2.1790e-04\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.3375e-04 - mse: 2.6749e-04 - val_loss: 1.1057e-04 - val_mse: 2.2114e-04\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 1.2912e-04 - mse: 2.5825e-04 - val_loss: 1.0642e-04 - val_mse: 2.1285e-04\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.3423e-04 - mse: 2.6846e-04 - val_loss: 1.6647e-04 - val_mse: 3.3294e-04\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.3141e-04 - mse: 2.6281e-04 - val_loss: 9.9725e-05 - val_mse: 1.9945e-04\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.2334e-04 - mse: 2.4667e-04 - val_loss: 1.4234e-04 - val_mse: 2.8469e-04\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.3389e-04 - mse: 2.6779e-04 - val_loss: 9.6647e-05 - val_mse: 1.9329e-04\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.2551e-04 - mse: 2.5101e-04 - val_loss: 9.8386e-05 - val_mse: 1.9677e-04\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.3846e-04 - mse: 2.7692e-04 - val_loss: 1.3911e-04 - val_mse: 2.7821e-04\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.1365e-04 - mse: 2.2729e-04 - val_loss: 9.2206e-05 - val_mse: 1.8441e-04\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1950e-04 - mse: 2.3900e-04 - val_loss: 9.6486e-05 - val_mse: 1.9297e-04\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.1394e-04 - mse: 2.2788e-04 - val_loss: 8.9717e-05 - val_mse: 1.7943e-04\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1141e-04 - mse: 2.2282e-04 - val_loss: 8.9710e-05 - val_mse: 1.7942e-04\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1841e-04 - mse: 2.3681e-04 - val_loss: 1.1712e-04 - val_mse: 2.3424e-04\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.0613e-04 - mse: 2.1227e-04 - val_loss: 9.4549e-05 - val_mse: 1.8910e-04\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.0968e-04 - mse: 2.1935e-04 - val_loss: 8.5289e-05 - val_mse: 1.7058e-04\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.0487e-04 - mse: 2.0974e-04 - val_loss: 1.0639e-04 - val_mse: 2.1277e-04\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.0395e-04 - mse: 2.0790e-04 - val_loss: 1.8702e-04 - val_mse: 3.7403e-04\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1.1663e-04 - mse: 2.3327e-04 - val_loss: 1.0325e-04 - val_mse: 2.0651e-04\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.1424e-04 - mse: 2.2847e-04 - val_loss: 9.0380e-05 - val_mse: 1.8076e-04\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1023e-04 - mse: 2.2046e-04 - val_loss: 9.7443e-05 - val_mse: 1.9489e-04\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.0211e-04 - mse: 2.0423e-04 - val_loss: 7.9640e-05 - val_mse: 1.5928e-04\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.1087e-04 - mse: 2.2174e-04 - val_loss: 1.0353e-04 - val_mse: 2.0706e-04\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.0639e-04 - mse: 2.1278e-04 - val_loss: 8.7659e-05 - val_mse: 1.7532e-04\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.0192e-04 - mse: 2.0384e-04 - val_loss: 1.4901e-04 - val_mse: 2.9802e-04\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.0645e-04 - mse: 2.1290e-04 - val_loss: 2.4356e-04 - val_mse: 4.8713e-04\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.0721e-04 - mse: 2.1442e-04 - val_loss: 8.0482e-05 - val_mse: 1.6096e-04\n",
      "KT&G_기타제조업.csv\n",
      "4000길이의 데이터 적용 완료\n",
      " 길이: 4000, RMSE:997.7966179088753\n",
      "[673.2830724100673, 705.373706484437, 1200.0776741025338, 997.7966179088753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 7s 21ms/step - loss: 4.4322e-04 - mse: 8.8644e-04 - val_loss: 2.1330e-04 - val_mse: 4.2660e-04\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3431e-04 - mse: 2.6862e-04 - val_loss: 1.5531e-04 - val_mse: 3.1062e-04\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 1.2333e-04 - mse: 2.4666e-04 - val_loss: 2.0870e-04 - val_mse: 4.1740e-04\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.1764e-04 - mse: 2.3527e-04 - val_loss: 1.4093e-04 - val_mse: 2.8186e-04\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0390e-04 - mse: 2.0780e-04 - val_loss: 1.2922e-04 - val_mse: 2.5844e-04\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0113e-04 - mse: 2.0226e-04 - val_loss: 1.6495e-04 - val_mse: 3.2991e-04\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 9.7205e-05 - mse: 1.9441e-04 - val_loss: 1.4117e-04 - val_mse: 2.8234e-04\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 9.3902e-05 - mse: 1.8780e-04 - val_loss: 1.8303e-04 - val_mse: 3.6606e-04\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 8.4777e-05 - mse: 1.6955e-04 - val_loss: 1.2503e-04 - val_mse: 2.5006e-04\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 8.1913e-05 - mse: 1.6383e-04 - val_loss: 1.0745e-04 - val_mse: 2.1489e-04\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 7.8353e-05 - mse: 1.5671e-04 - val_loss: 9.4892e-05 - val_mse: 1.8978e-04\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.2568e-05 - mse: 1.4514e-04 - val_loss: 1.3485e-04 - val_mse: 2.6970e-04\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.3968e-05 - mse: 1.4794e-04 - val_loss: 9.0773e-05 - val_mse: 1.8155e-04\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.1699e-05 - mse: 1.4340e-04 - val_loss: 7.8476e-05 - val_mse: 1.5695e-04\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.7905e-05 - mse: 1.5581e-04 - val_loss: 1.7199e-04 - val_mse: 3.4398e-04\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.8046e-05 - mse: 1.3609e-04 - val_loss: 1.7410e-04 - val_mse: 3.4819e-04\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.5662e-05 - mse: 1.3132e-04 - val_loss: 1.0947e-04 - val_mse: 2.1893e-04\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.1360e-05 - mse: 1.2272e-04 - val_loss: 8.3486e-05 - val_mse: 1.6697e-04\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.4653e-05 - mse: 1.2931e-04 - val_loss: 7.4544e-05 - val_mse: 1.4909e-04\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 7.9869e-05 - mse: 1.5974e-04 - val_loss: 7.7842e-05 - val_mse: 1.5568e-04\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.9985e-05 - mse: 1.1997e-04 - val_loss: 9.9241e-05 - val_mse: 1.9848e-04\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.6168e-05 - mse: 1.3234e-04 - val_loss: 6.6691e-05 - val_mse: 1.3338e-04\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.6294e-05 - mse: 1.1259e-04 - val_loss: 7.7456e-05 - val_mse: 1.5491e-04\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 6.2388e-05 - mse: 1.2478e-04 - val_loss: 1.5433e-04 - val_mse: 3.0865e-04\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.6154e-05 - mse: 1.1231e-04 - val_loss: 8.2562e-05 - val_mse: 1.6512e-04\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.8136e-05 - mse: 1.1627e-04 - val_loss: 6.2176e-05 - val_mse: 1.2435e-04\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.7098e-05 - mse: 1.1420e-04 - val_loss: 1.8718e-04 - val_mse: 3.7436e-04\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 6.2845e-05 - mse: 1.2569e-04 - val_loss: 7.2465e-05 - val_mse: 1.4493e-04\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.4011e-05 - mse: 1.0802e-04 - val_loss: 6.0567e-05 - val_mse: 1.2113e-04\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.3795e-05 - mse: 1.0759e-04 - val_loss: 9.3584e-05 - val_mse: 1.8717e-04\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.9589e-05 - mse: 1.1918e-04 - val_loss: 7.4542e-05 - val_mse: 1.4908e-04\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.1922e-05 - mse: 1.0384e-04 - val_loss: 5.8059e-05 - val_mse: 1.1612e-04\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.5938e-05 - mse: 1.1188e-04 - val_loss: 9.1973e-05 - val_mse: 1.8395e-04\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 6.7654e-05 - mse: 1.3531e-04 - val_loss: 5.8526e-05 - val_mse: 1.1705e-04\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 5.9970e-05 - mse: 1.1994e-04 - val_loss: 6.2807e-05 - val_mse: 1.2561e-04\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.8567e-05 - mse: 1.1713e-04 - val_loss: 1.3563e-04 - val_mse: 2.7126e-04\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.1482e-05 - mse: 1.0296e-04 - val_loss: 6.0443e-05 - val_mse: 1.2089e-04\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.4664e-05 - mse: 1.0933e-04 - val_loss: 1.7877e-04 - val_mse: 3.5754e-04\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.4900e-05 - mse: 1.0980e-04 - val_loss: 1.1731e-04 - val_mse: 2.3463e-04\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.1462e-05 - mse: 1.0292e-04 - val_loss: 5.5344e-05 - val_mse: 1.1069e-04\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 5.1242e-05 - mse: 1.0248e-04 - val_loss: 8.5188e-05 - val_mse: 1.7038e-04\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.6886e-05 - mse: 1.1377e-04 - val_loss: 7.8433e-05 - val_mse: 1.5687e-04\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 4.9743e-05 - mse: 9.9486e-05 - val_loss: 5.5177e-05 - val_mse: 1.1035e-04\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 4.8791e-05 - mse: 9.7581e-05 - val_loss: 1.3067e-04 - val_mse: 2.6134e-04\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.2157e-05 - mse: 1.0431e-04 - val_loss: 5.5407e-05 - val_mse: 1.1081e-04\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 4.9778e-05 - mse: 9.9556e-05 - val_loss: 6.0320e-05 - val_mse: 1.2064e-04\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 5.3668e-05 - mse: 1.0734e-04 - val_loss: 7.9097e-05 - val_mse: 1.5819e-04\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 4.8866e-05 - mse: 9.7732e-05 - val_loss: 7.0728e-05 - val_mse: 1.4146e-04\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 4.8928e-05 - mse: 9.7855e-05 - val_loss: 5.3061e-05 - val_mse: 1.0612e-04\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 5.2267e-05 - mse: 1.0453e-04 - val_loss: 1.0679e-04 - val_mse: 2.1358e-04\n",
      "KT&G_기타제조업.csv\n",
      "5000길이의 데이터 적용 완료\n",
      " 길이: 5000, RMSE:1441.4227459589304\n",
      "[673.2830724100673, 705.373706484437, 1200.0776741025338, 997.7966179088753, 1441.4227459589304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgyu\\AppData\\Local\\Temp\\ipykernel_23124\\2978139252.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "138/138 [==============================] - 6s 22ms/step - loss: 3.4378e-04 - mse: 6.8757e-04 - val_loss: 2.3451e-04 - val_mse: 4.6902e-04\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 3s 18ms/step - loss: 1.2744e-04 - mse: 2.5487e-04 - val_loss: 2.4043e-04 - val_mse: 4.8086e-04\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 3s 19ms/step - loss: 1.3736e-04 - mse: 2.7471e-04 - val_loss: 2.6350e-04 - val_mse: 5.2700e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 1.0811e-04 - mse: 2.1622e-04 - val_loss: 3.4361e-04 - val_mse: 6.8722e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 1.2589e-04 - mse: 2.5178e-04 - val_loss: 2.9550e-04 - val_mse: 5.9100e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 1.1027e-04 - mse: 2.2054e-04 - val_loss: 3.9094e-04 - val_mse: 7.8188e-04\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 1.0112e-04 - mse: 2.0223e-04 - val_loss: 1.8154e-04 - val_mse: 3.6308e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 9.6599e-05 - mse: 1.9320e-04 - val_loss: 1.4134e-04 - val_mse: 2.8269e-04\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 4s 30ms/step - loss: 9.5510e-05 - mse: 1.9102e-04 - val_loss: 1.5532e-04 - val_mse: 3.1064e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 4s 25ms/step - loss: 8.4473e-05 - mse: 1.6895e-04 - val_loss: 1.3834e-04 - val_mse: 2.7669e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 8.3655e-05 - mse: 1.6731e-04 - val_loss: 2.8872e-04 - val_mse: 5.7744e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 3s 19ms/step - loss: 8.7656e-05 - mse: 1.7531e-04 - val_loss: 1.2203e-04 - val_mse: 2.4406e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 8.6794e-05 - mse: 1.7359e-04 - val_loss: 3.2289e-04 - val_mse: 6.4579e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 3s 20ms/step - loss: 8.4371e-05 - mse: 1.6874e-04 - val_loss: 1.2970e-04 - val_mse: 2.5941e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 8.3361e-05 - mse: 1.6672e-04 - val_loss: 1.1546e-04 - val_mse: 2.3093e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 4s 25ms/step - loss: 7.4607e-05 - mse: 1.4921e-04 - val_loss: 1.0670e-04 - val_mse: 2.1340e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 7.3368e-05 - mse: 1.4674e-04 - val_loss: 1.1325e-04 - val_mse: 2.2649e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.3836e-05 - mse: 1.4767e-04 - val_loss: 1.8713e-04 - val_mse: 3.7426e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.1124e-05 - mse: 1.4225e-04 - val_loss: 9.7536e-05 - val_mse: 1.9507e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 3s 18ms/step - loss: 6.8116e-05 - mse: 1.3623e-04 - val_loss: 1.4024e-04 - val_mse: 2.8048e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 4s 30ms/step - loss: 7.5139e-05 - mse: 1.5028e-04 - val_loss: 2.3948e-04 - val_mse: 4.7896e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 6.5984e-05 - mse: 1.3197e-04 - val_loss: 1.3757e-04 - val_mse: 2.7514e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 6.6088e-05 - mse: 1.3218e-04 - val_loss: 3.3673e-04 - val_mse: 6.7346e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.3345e-05 - mse: 1.4669e-04 - val_loss: 1.3253e-04 - val_mse: 2.6506e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.7626e-05 - mse: 1.5525e-04 - val_loss: 2.6997e-04 - val_mse: 5.3993e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 3s 17ms/step - loss: 6.8251e-05 - mse: 1.3650e-04 - val_loss: 8.8330e-05 - val_mse: 1.7666e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 7.4607e-05 - mse: 1.4921e-04 - val_loss: 1.2934e-04 - val_mse: 2.5869e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 3s 18ms/step - loss: 5.9204e-05 - mse: 1.1841e-04 - val_loss: 8.5018e-05 - val_mse: 1.7004e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 5.9678e-05 - mse: 1.1936e-04 - val_loss: 3.5488e-04 - val_mse: 7.0976e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.3198e-05 - mse: 1.4640e-04 - val_loss: 1.0345e-04 - val_mse: 2.0690e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.3239e-05 - mse: 1.2648e-04 - val_loss: 1.1171e-04 - val_mse: 2.2341e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.6444e-05 - mse: 1.1289e-04 - val_loss: 7.5352e-05 - val_mse: 1.5070e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 5.9524e-05 - mse: 1.1905e-04 - val_loss: 1.2423e-04 - val_mse: 2.4845e-04\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 6.0142e-05 - mse: 1.2028e-04 - val_loss: 8.1942e-05 - val_mse: 1.6388e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 3s 19ms/step - loss: 5.7418e-05 - mse: 1.1484e-04 - val_loss: 2.3949e-04 - val_mse: 4.7898e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 3s 18ms/step - loss: 5.6306e-05 - mse: 1.1261e-04 - val_loss: 7.6468e-05 - val_mse: 1.5294e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 5.2414e-05 - mse: 1.0483e-04 - val_loss: 1.5999e-04 - val_mse: 3.1999e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 5.4189e-05 - mse: 1.0838e-04 - val_loss: 1.4968e-04 - val_mse: 2.9936e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 5.8056e-05 - mse: 1.1611e-04 - val_loss: 1.0596e-04 - val_mse: 2.1193e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 5.4883e-05 - mse: 1.0977e-04 - val_loss: 8.7848e-05 - val_mse: 1.7570e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 3s 24ms/step - loss: 5.1540e-05 - mse: 1.0308e-04 - val_loss: 6.7475e-05 - val_mse: 1.3495e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 4s 28ms/step - loss: 7.1857e-05 - mse: 1.4371e-04 - val_loss: 1.2588e-04 - val_mse: 2.5177e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 3s 18ms/step - loss: 6.5928e-05 - mse: 1.3186e-04 - val_loss: 1.0272e-04 - val_mse: 2.0543e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 3s 20ms/step - loss: 4.8240e-05 - mse: 9.6480e-05 - val_loss: 8.8463e-05 - val_mse: 1.7693e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 5.2727e-05 - mse: 1.0545e-04 - val_loss: 6.8278e-05 - val_mse: 1.3656e-04\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 4s 25ms/step - loss: 6.5722e-05 - mse: 1.3144e-04 - val_loss: 7.9375e-05 - val_mse: 1.5875e-04\n",
      "Epoch 47/50\n",
      "120/138 [=========================>....] - ETA: 0s - loss: 4.3983e-05 - mse: 8.7965e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [215]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m earlystopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# lstm 적용                                        \u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# rescaleing 작업\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\py_397\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)\n",
    "import os\n",
    "file_list = os.listdir('leader_stocks_data')\n",
    "\n",
    "\n",
    "WINDOW_SIZE=20\n",
    "BATCH_SIZE=32\n",
    "for file_name in file_list:\n",
    "    result = []\n",
    "    df_origin = pd.read_csv(f'leader_stocks_data/{file_name}')\n",
    "    # 결측치(0인 값) 있는 행 제거\n",
    "    for column in df_origin.columns:\n",
    "        df_origin= df_origin[df_origin[f'{column}'] != 0]\n",
    "    for i in range(1, len(df_origin)//1000+2):\n",
    "        # 데이터 불러오기\n",
    "        df = df_origin\n",
    "        df = df.set_index(keys=['Date'], inplace=False, drop=True)\n",
    "        df = df.drop('Close', axis = 1)\n",
    "        df.rename(columns ={'Adj Close':'Close'}, inplace = True)\n",
    "        # 원하는 크기로 데이터 자르기\n",
    "        df = df[-i*1000:]\n",
    "        # 피처값, 타켓 스케일링\n",
    "        scaler = MinMaxScaler()\n",
    "        df[['High','Low','Open', 'Volume']] = scaler.fit_transform(df[['High','Low','Open', 'Volume']])\n",
    "        df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1,1))\n",
    "        # train, test set 분리\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df.drop('Close', 1), df['Close'], test_size=0.2, shuffle=False)\n",
    "        train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "        test_data = windowed_dataset(y_test, WINDOW_SIZE, BATCH_SIZE, False) \n",
    "        # lstm 모델링\n",
    "        model = Sequential([\n",
    "            Conv1D(filters=32, kernel_size=5,\n",
    "                   padding=\"causal\",\n",
    "                   activation=\"relu\",\n",
    "                   input_shape=[WINDOW_SIZE, 1]),\n",
    "            LSTM(16, activation='tanh'),\n",
    "            Dense(16, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ])\n",
    "        loss = Huber()\n",
    "        optimizer = Adam(0.0005)\n",
    "        model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse']) \n",
    "        earlystopping = EarlyStopping(monitor='val_loss', patience=10) \n",
    "        # lstm 적용                                        \n",
    "        history = model.fit(train_data, \n",
    "                            validation_data=(test_data), \n",
    "                            epochs=50, \n",
    "                            callbacks=[earlystopping])\n",
    "        pred = model.predict(test_data)\n",
    "        # rescaleing 작업\n",
    "        rescaled_y_test = scaler.inverse_transform(np.array(y_test).reshape(-1, 1))\n",
    "        rescaled_pred = scaler.inverse_transform(np.array(pred).reshape(-1,1))\n",
    "        # 평가지표(RMSE) 계산\n",
    "        RMSE = np.sqrt(mean_squared_error(rescaled_y_test[20:], rescaled_pred))\n",
    "        result.append(RMSE)\n",
    "        print(f\"{file_name}\")\n",
    "        print(f\"{i * 1000}길이의 데이터 적용 완료\\n 길이: {i * 1000}, RMSE:{RMSE}\")\n",
    "        print(result)\n",
    "    data_size = list(range(1000, len(df_origin), 1000))\n",
    "    data_size.append(len(df_origin))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    data_size = list(range(1000, len(df_origin), 1000))\n",
    "    data_size.append(len(df_origin))\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.plot(data_size, result)\n",
    "    plt.tick_params(axis='x')\n",
    "    plt.tick_params(axis='y')\n",
    "    plt.title(f'{file_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터:  (443, 4)\n",
      "검증 데이터: (191, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LinearRegression()\n",
    "X = df[['High','Low','Open', 'Volume']]\n",
    "Y = df['Close']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=10)\n",
    "print('훈련 데이터: ', X_train.shape)\n",
    "print('검증 데이터:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035778758992044"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)\n",
    "r_square = lr.score(X_test, y_test)\n",
    "r_square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 4))\n",
    "#axes.plot(y_train, label='Train')        # 훈련 데이터\n",
    "axes.plot(y_test, label='Test')          # 테스트 데이터\n",
    "axes.plot(y_test.index, y_hat, label='Prediction')  # 예측 데이터\n",
    "axes.xaxis.set_major_locator(plt.MultipleLocator(100))\n",
    "plt.tick_params(axis='x', labelcolor='white')\n",
    "plt.tick_params(axis='y', labelcolor='white')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis = 'x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 2.866\n",
      "MPE: -0.264\n",
      "MAE: 2177.710\n",
      "MSE: 8166861.082\n",
      "RMSE: 2857.772\n"
     ]
    }
   ],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "print(f\"MAPE: {MAPE(y_test, y_hat):.3f}\")\n",
    "\n",
    "def MPE(y_test, y_pred): \n",
    "    return np.mean((y_test - y_pred) / y_test) * 100\n",
    "print(f\"MPE: {MPE(y_test, y_hat):.3f}\")\n",
    "\n",
    "def MAE(y_test, y_pred):\n",
    "    return np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "print(f\"MAE: {MAE(y_test, y_hat):.3f}\")\n",
    "\n",
    "def MSE(y_test, y_pred):\n",
    "    return np.mean(np.square((y_test - y_pred)))\n",
    "\n",
    "print(f\"MSE: {MSE(y_test, y_hat):.3f}\")\n",
    "\n",
    "print(f\"RMSE: {np.sqrt(MSE(y_test, y_hat)):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0754b623110a23d22c6e43eca41331837ac6bcbe836a2bdf13571a3f97720831"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
